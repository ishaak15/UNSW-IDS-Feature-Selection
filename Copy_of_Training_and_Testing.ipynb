{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Copy of Training_and_Testing.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ishaak15/UNSW-IDS-Feature-Selection/blob/main/Copy_of_Training_and_Testing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RupDMUtc2mgK",
        "outputId": "e9487306-3711-4353-ffc3-800fdb77bb99"
      },
      "source": [
        "import numpy as np \n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import math\n",
        "import pandas as pd\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.model_selection import cross_validate\n",
        "from sklearn import datasets, preprocessing, feature_extraction, neighbors\n",
        "from sklearn import linear_model, svm, metrics, ensemble, tree, ensemble\n",
        "from sklearn.model_selection import train_test_split\n",
        "from copy import copy\n",
        "import urllib\n",
        "import csv\n",
        "\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import matplotlib.pyplot as plt\n",
        "import plotly.graph_objs as go\n",
        "\n",
        "from sklearn.tree import DecisionTreeClassifier # Import Decision Tree Classifier\n",
        "from sklearn.model_selection import train_test_split # Import train_test_split function\n",
        "from sklearn import metrics #Import scikit-learn metrics module for accuracy calculation\n",
        "\n",
        "from sklearn.metrics import confusion_matrix \n",
        "from sklearn.metrics import accuracy_score \n",
        "from sklearn.metrics import classification_report \n",
        "\n",
        "\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from yellowbrick.classifier import ClassificationReport\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split \n",
        "from sklearn.naive_bayes import GaussianNB \n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC # \"Support Vector Classifier\" \n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "\n",
        "from sklearn.feature_selection import SelectKBest\n",
        "from sklearn.feature_selection import chi2\n",
        "\n",
        "from zipfile import ZipFile\n",
        "import collections\n",
        "\n",
        "from sklearn.feature_selection import RFE\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "from sklearn.metrics import confusion_matrix \n",
        "from sklearn.metrics import accuracy_score \n",
        "from sklearn.metrics import classification_report \n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import f1_score\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning:\n",
            "\n",
            "The sklearn.metrics.classification module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.metrics. Anything that cannot be imported from sklearn.metrics is now part of the private API.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FUKlYohz7Ge3",
        "outputId": "25f03d7a-ce72-4e07-d529-7c84fa4a8325"
      },
      "source": [
        "!git clone https://github.com/ishaak15/UNSW-IDS-Feature-Selection.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'UNSW-IDS-Feature-Selection'...\n",
            "remote: Enumerating objects: 64, done.\u001b[K\n",
            "remote: Counting objects: 100% (27/27), done.\u001b[K\n",
            "remote: Compressing objects: 100% (27/27), done.\u001b[K\n",
            "remote: Total 64 (delta 9), reused 0 (delta 0), pack-reused 37\u001b[K\n",
            "Unpacking objects: 100% (64/64), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zVKdVCIQIVl8",
        "outputId": "053bcb65-4ee4-47e0-f5f6-812b0f980307"
      },
      "source": [
        "cd UNSW-IDS-Feature-Selection/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/UNSW-IDS-Feature-Selection\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6CrTS2MAIetl",
        "outputId": "3d7882d5-675a-4287-cbe6-d13cdbbe03a4"
      },
      "source": [
        "ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "bayes_10.sav   clfKNN20.sav                        README.md\n",
            "bayes_20.sav   clfKNN_all.sav                      Testset1.csv\n",
            "bayes_all.sav  Copy_of_Training_and_Testing.ipynb  Testset2.csv\n",
            "clfDT_10.sav   Dataset1.csv                        Testset3.csv\n",
            "clfDT_20.sav   Dataset2.csv                        Training_and_Testing.ipynb\n",
            "clfDT_all.sav  Dataset3.csv                        UNSW_IDS_analysis.ipynb\n",
            "clfKNN10.sav   LICENSE                             UNSW_NB15_testing-set.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PR7ddO_b-TYh"
      },
      "source": [
        "df1 = pd.read_csv('Dataset1.csv',index_col=0)\n",
        "df2 = pd.read_csv('Dataset2.csv',index_col=0)\n",
        "df3 = pd.read_csv('Dataset3.csv',index_col=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sK7zk_s0-2Go"
      },
      "source": [
        "tf1 = pd.read_csv('Testset1.csv',index_col=0)\n",
        "tf2 = pd.read_csv('Testset2.csv',index_col=0)\n",
        "tf3 = pd.read_csv('Testset3.csv',index_col=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DVJCwCx5DkD6"
      },
      "source": [
        "df1_xtrain=df1.iloc[: , :-1]\n",
        "df1_ytrain=df1.iloc[:,-1]\n",
        "df2_xtrain=df2.iloc[: , :-1]\n",
        "df2_ytrain=df2.iloc[:,-1]\n",
        "df3_xtrain=df3.iloc[: , :-1]\n",
        "df3_ytrain=df3.iloc[:,-1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N2Q5ICJvIsgs"
      },
      "source": [
        "df1_xtest=tf1.iloc[: , :-1]\n",
        "df1_ytest=tf1.iloc[:,-1]\n",
        "df2_xtest=tf2.iloc[: , :-1]\n",
        "df2_ytest=tf2.iloc[:,-1]\n",
        "df3_xtest=tf3.iloc[: , :-1]\n",
        "df3_ytest=tf3.iloc[:,-1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w-ZMD59m4V2o"
      },
      "source": [
        "#KNN"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9eg-WFEcsYCS",
        "outputId": "e9594e0a-f5d4-475c-f06d-c089c1e72c50"
      },
      "source": [
        "clfKNN10=neighbors.KNeighborsClassifier()\n",
        "clfKNN10.fit(df1_xtrain,df1_ytrain)\n",
        "#clfKNN10.fit(df1_xtrain,df1_ytrain)\n",
        "\n",
        "print (\"\\t\\tKNN Classification of UNSW-NB15\\n\\n\\t\\tTop 10 Features \")\n",
        "\n",
        "yt_pred_10 = clfKNN10.predict(df1_xtest)\n",
        "results = confusion_matrix(df1_ytest, yt_pred_10) \n",
        "print ('Confusion Matrix :')\n",
        "print(results) \n",
        "\n",
        "\n",
        "accKNN10=accuracy_score(df1_ytest,yt_pred_10)\n",
        "print(\"Accuracy: \",accKNN10)\n",
        "preKNN10=precision_score(df1_ytest, yt_pred_10, average='macro')\n",
        "print(\"Precision Score: \",preKNN10)\n",
        "f1KNN10=f1_score(df1_ytest, yt_pred_10, average='macro')\n",
        "print(\"F1 Score: \",f1KNN10)\n",
        "reKNN10=recall_score(df1_ytest, yt_pred_10, average='macro')  \n",
        "print(\"Recall: \",reKNN10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\t\tKNN Classification of UNSW-NB15\n",
            "\n",
            "\t\tTop 10 Features \n",
            "Confusion Matrix :\n",
            "[[  208   131    42    58   129    16    32    61     0     0]\n",
            " [  198   121    13    49   134    18    16    33     1     0]\n",
            " [  822   758   472   913   502    21   202   372    27     0]\n",
            " [  955   835   503  6664   944    39   616   540    33     3]\n",
            " [  444   315    97   469  3357    54  1111   164    50     1]\n",
            " [   17    11    34   375   168 18078   140    44     4     0]\n",
            " [  496    52   218  1986  7076    20 26822   233    93     4]\n",
            " [   82   102    51   324   117     5    71  2737     5     2]\n",
            " [    5     7    12    50   161     6    51    32    54     0]\n",
            " [    0     1     2    26    11     0     3     0     0     1]]\n",
            "Accuracy:  0.7107078657144246\n",
            "Precision Score:  0.41756373950870634\n",
            "F1 Score:  0.4023931552335053\n",
            "Recall:  0.44140047486900985\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gxUUKcyegAMb"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kBj8htUIsYM0",
        "outputId": "19b7358f-d9e9-4b17-a32f-830b0951e67c"
      },
      "source": [
        "clfKNN20=neighbors.KNeighborsClassifier()\n",
        "clfKNN20.fit(df2_xtrain,df2_ytrain)\n",
        "\n",
        "print (\"\\t\\tKNN Analysis of UNSW-NB15\\n\\n\\t\\tTop 20 Features \")\n",
        "\n",
        "y_pred_20 = clfKNN20.predict(df2_xtest)\n",
        "results = confusion_matrix(df2_ytest, y_pred_20) \n",
        "print ('Confusion Matrix :')\n",
        "print(results) \n",
        "\n",
        "\n",
        "accKNN20=accuracy_score(df2_ytest,y_pred_20)\n",
        "print(\"Accuracy: \",accKNN20)\n",
        "preKNN20=precision_score(df2_ytest, y_pred_20, average='macro')\n",
        "print(\"Precision Score: \",preKNN20)\n",
        "f1KNN20=f1_score(df2_ytest, y_pred_20, average='macro')\n",
        "print(\"F1 Score: \",f1KNN20)\n",
        "reKNN20=recall_score(df2_ytest, y_pred_20, average='macro')  \n",
        "print(\"Recall: \",reKNN20)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\t\tKNN Analysis of UNSW-NB15\n",
            "\n",
            "\t\tTop 20 Features \n",
            "Confusion Matrix :\n",
            "[[  267   167    15    69   117    16    17     9     0     0]\n",
            " [  251   109     6    65   118    18    11     5     0     0]\n",
            " [ 1150  1136   184   646   494    22   307   129    21     0]\n",
            " [ 1321  1139   396  4316  1854    39  1749   290    28     0]\n",
            " [  599   332   140  2053  1702    56  1023   122    35     0]\n",
            " [   30    22    26   304   220 18083   132    51     3     0]\n",
            " [  132    71   537  7955  4981    21 22760   473    69     1]\n",
            " [  126   152    91   985   400     7   405  1325     5     0]\n",
            " [    7     6    13   109   126     5    52    17    43     0]\n",
            " [    0     0     1    22     8     0    13     0     0     0]]\n",
            "Accuracy:  0.5925885439440315\n",
            "Precision Score:  0.3273066113090913\n",
            "F1 Score:  0.3053129978339978\n",
            "Recall:  0.336096541715301\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "amTNhuAbsYSP",
        "outputId": "67c59f22-b3e4-4a0e-967d-29d0a186972a"
      },
      "source": [
        "clfKNN20=neighbors.KNeighborsClassifier()\n",
        "clfKNN20.fit(df3_xtrain,df3_ytrain)\n",
        "\n",
        "print (\"\\t\\tKNN Analysis of UNSW-NB15\\n\\n\\t\\tAll Features \")\n",
        "\n",
        "y_pred_all = clfKNN20.predict(df3_xtest)\n",
        "results = confusion_matrix(df3_ytest, y_pred_all) \n",
        "print ('Confusion Matrix :')\n",
        "print(results) \n",
        "\n",
        "\n",
        "accKNNall=accuracy_score(df3_ytest, y_pred_all)\n",
        "print(\"Accuracy: \",accKNNall)\n",
        "preKNNall=precision_score(df3_ytest, y_pred_all, average='macro')\n",
        "print(\"Precision Score: \",preKNNall)\n",
        "f1KNNall=f1_score(df3_ytest, y_pred_all, average='macro')\n",
        "print(\"F1 Score: \",f1KNNall)\n",
        "reKNNall=recall_score(df3_ytest, y_pred_all, average='macro')  \n",
        "print(\"Recall: \",reKNNall)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\t\tKNN Analysis of UNSW-NB15\n",
            "\n",
            "\t\tAll Features \n",
            "Confusion Matrix :\n",
            "[[  336   161     1    44   101    16    17     1     0     0]\n",
            " [  304    98     1    44   105    18    11     2     0     0]\n",
            " [ 1491  1070   101   581   437    22   305    61    21     0]\n",
            " [ 1671  1073   319  4245  1794    39  1743   220    28     0]\n",
            " [  726   307   123  2007  1672    56  1024   112    35     0]\n",
            " [   37    21    26   301   219 18083   130    51     3     0]\n",
            " [  115    55   537  7955  5009    21 22765   473    69     1]\n",
            " [  164   146    81   981   392     7   405  1315     5     0]\n",
            " [    6     3    13   109   132     5    50    16    44     0]\n",
            " [    0     0     1    22     8     0    13     0     0     0]]\n",
            "Accuracy:  0.5910095710051985\n",
            "Precision Score:  0.3265665197965294\n",
            "F1 Score:  0.3034833731074776\n",
            "Recall:  0.34123127222810123\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RKy3aGMusYXi"
      },
      "source": [
        "#Decision TREE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8A2BPc0ksky-",
        "outputId": "84a76614-3267-4699-cc1f-64d7724cce70"
      },
      "source": [
        "clfDT_10 = DecisionTreeClassifier()\n",
        "print (\"\\t\\tDecision Tree Analysis of UNSW-NB15\\n\\n\\t\\tTop 10 Features \")\n",
        "\n",
        "# Train Decision Tree Classifer\n",
        "clfDT_10 = clfDT_10.fit(df1_xtrain,df1_ytrain)\n",
        "\n",
        "#Predict the response for test dataset\n",
        "y_pred_DT10 = clfDT_10.predict(df1_xtest)\n",
        "\n",
        "\n",
        "#print (\"\\t\\tMajor Verifcation\")\n",
        "results_DT10 = confusion_matrix(df1_ytest, y_pred_DT10) \n",
        "print ('Confusion Matrix :')\n",
        "print(results_DT10) \n",
        "\n",
        "accDT10=accuracy_score(df1_ytest, y_pred_DT10)\n",
        "preDT10=precision_score(df1_ytest, y_pred_DT10, average='macro')\n",
        "f1DT10=f1_score(df1_ytest, y_pred_DT10, average='macro')\n",
        "reDT10=recall_score(df1_ytest, y_pred_DT10, average='macro')\n",
        "\n",
        "print ('Accuracy Score :',accDT10 )\n",
        "print(\"Precision Score: \",preDT10)\n",
        "print(\"F1 Score: \",f1DT10)\n",
        "print(\"Recall: \",reDT10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\t\tDecision Tree Analysis of UNSW-NB15\n",
            "\n",
            "\t\tTop 10 Features \n",
            "Confusion Matrix :\n",
            "[[  374    82     1     3   188     0    27     2     0     0]\n",
            " [  317    55     3    10   189     1     4     0     4     0]\n",
            " [ 1482  1019   519   529   389    39    48    24    38     2]\n",
            " [ 1704   953   587  6503   636   119   239   237   140    14]\n",
            " [  720   148   131   531  2955    44  1304     1   225     3]\n",
            " [   19    23    64   229    53 18443    14     2    18     6]\n",
            " [  581    12   939  1173  7354    89 26684    26   141     1]\n",
            " [  158   145    36   276    43     6    31  2758    41     2]\n",
            " [    1     5    13    45    26     4    13     3   268     0]\n",
            " [    0     1     0    15     0     1     1     0     1    25]]\n",
            "Accuracy Score : 0.7115580819122577\n",
            "Precision Score:  0.48721854717159363\n",
            "F1 Score:  0.4871546636251587\n",
            "Recall:  0.5609924400156328\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZfSSpwm2sk1Y",
        "outputId": "e6e485f5-6488-49aa-f6e4-4ad459e65cfd"
      },
      "source": [
        "clfDT_20 = DecisionTreeClassifier()\n",
        "print (\"\\t\\tDecision Tree Analysis of UNSW-NB15\\n\\n\\t\\tTop 20 Features \")\n",
        "\n",
        "# Train Decision Tree Classifer\n",
        "clfDT_20 = clfDT_20.fit(df2_xtrain,df2_ytrain)\n",
        "\n",
        "#Predict the response for test dataset\n",
        "y_pred_DT20 = clfDT_20.predict(df2_xtest)\n",
        "\n",
        "\n",
        "#print (\"\\t\\tMajor Verifcation\")\n",
        "results_DT20 = confusion_matrix(df2_ytest, y_pred_DT20) \n",
        "print ('Confusion Matrix :')\n",
        "print(results_DT20)\n",
        "\n",
        "accDT20=accuracy_score(df2_ytest, y_pred_DT20)\n",
        "preDT20=precision_score(df2_ytest, y_pred_DT20, average='macro')\n",
        "f1DT20=f1_score(df2_ytest, y_pred_DT20, average='macro')\n",
        "reDT20=recall_score(df2_ytest, y_pred_DT20, average='macro')\n",
        "\n",
        "print ('Accuracy Score :',accDT20 )\n",
        "print(\"Precision Score: \",preDT20)\n",
        "print(\"F1 Score: \",f1DT20)\n",
        "print(\"Recall: \",reDT20)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\t\tDecision Tree Analysis of UNSW-NB15\n",
            "\n",
            "\t\tTop 20 Features \n",
            "Confusion Matrix :\n",
            "[[  507   115     1    35     1     3    12     0     3     0]\n",
            " [  491    51     5    11    10     0    11     0     4     0]\n",
            " [ 1735  1039   535   506    96    33    75    29    41     0]\n",
            " [ 2085   974   573  6416   178   107   287   403   100     9]\n",
            " [ 1069   151    76   373  2692    17  1502    15   167     0]\n",
            " [   26    24    60   198    42 18482    10     8    16     5]\n",
            " [  684     9   165   802  7428    51 27664    38   158     1]\n",
            " [  165   150    25   279    32     3    39  2756    46     1]\n",
            " [    2     5    18    51    30     2    13     4   253     0]\n",
            " [    0     0     1    17     0     1     0     1     1    23]]\n",
            "Accuracy Score : 0.7212141087305057\n",
            "Precision Score:  0.5136490242244997\n",
            "F1 Score:  0.49532173062432416\n",
            "Recall:  0.5695074875577226\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MQrDjJUosk4b",
        "outputId": "fb51541b-6729-4ad3-8fec-241389231c12"
      },
      "source": [
        "clfDT_all = DecisionTreeClassifier()\n",
        "print (\"\\t\\tDecision Tree Analysis of UNSW-NB15\\n\\n\\t\\tAll Features \")\n",
        "\n",
        "# Train Decision Tree Classifer\n",
        "clfDT_all = clfDT_all.fit(df3_xtrain,df3_ytrain)\n",
        "\n",
        "#Predict the response for test dataset\n",
        "y_pred_DTall = clfDT_all.predict(df3_xtest)\n",
        "\n",
        "#print (\"\\t\\tMajor Verifcation\")\n",
        "results_DTall = confusion_matrix(df3_ytest, y_pred_DTall) \n",
        "print ('Confusion Matrix :')\n",
        "print(results_DTall)\n",
        "\n",
        "accDTall=accuracy_score(df3_ytest, y_pred_DTall)\n",
        "preDTall=precision_score(df3_ytest, y_pred_DTall, average='macro')\n",
        "f1DTall=f1_score(df3_ytest, y_pred_DTall, average='macro')\n",
        "reDTall=recall_score(df3_ytest, y_pred_DTall, average='macro')\n",
        "\n",
        "print ('Accuracy Score :', accDTall)\n",
        "print(\"Precision Score: \",preDTall)\n",
        "print(\"F1 Score: \",f1DTall)\n",
        "print(\"Recall: \",reDTall)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\t\tDecision Tree Analysis of UNSW-NB15\n",
            "\n",
            "\t\tAll Features \n",
            "Confusion Matrix :\n",
            "[[  504   113     0    52     1     1     5     0     1     0]\n",
            " [  494    59     2     8     4     0    13     0     3     0]\n",
            " [ 1736  1095   547   494    72    38    50    25    32     0]\n",
            " [ 2101  1025   540  6507   168   126   344   229    80    12]\n",
            " [ 1059   173    79   338  2699    26  1535     4   149     0]\n",
            " [   26    26    68   243    33 18426    21     5    17     6]\n",
            " [  669     7   149   785  7437    37 27721    55   137     3]\n",
            " [  169   150    31   284    26    16    35  2745    39     1]\n",
            " [    0     5     9    57    32     2    16     4   253     0]\n",
            " [    0     1     5    14     1     1     0     1     0    21]]\n",
            "Accuracy Score : 0.7224651411358889\n",
            "Precision Score:  0.5135796659402336\n",
            "F1 Score:  0.4946291771876262\n",
            "Recall:  0.5666601782550308\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aUZpsNG4LJ_y"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0gTs5TBjslQj"
      },
      "source": [
        "#Gaussian Naive Bayes Classifier\n",
        "from sklearn.naive_bayes import MultinomialNB"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AYLJ7YcaopnF",
        "outputId": "7da3befb-7454-4751-eeb2-65f43b328495"
      },
      "source": [
        "print(df1_ytrain.unique())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[6 1 0 4 8 7 3 2 9 5]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_e-LXX4Ls2Sk",
        "outputId": "0dcbecbe-258f-45e5-950e-dd92b2c1bd47"
      },
      "source": [
        "bayes_10 = MultinomialNB()\n",
        "#bayes_10.partial_fit(df1_xtrain,df1_ytrain,df1_ytrain.unique())\n",
        "bayes_10.fit(df1_xtrain,df1_ytrain)\n",
        "\n",
        "print (\"\\t\\tGaussain Naive Bayes Analysis of UNSW-NB15\\n\\n\\t\\tTop 10 Features \")\n",
        "y_pred_gnb10 = bayes_10.predict(df1_xtest)\n",
        "\n",
        "#print (\"\\t\\tMajor Verifcation KDD99 10% GNB\")\n",
        "results = confusion_matrix(df1_ytest, y_pred_gnb10) \n",
        "print ('Confusion Matrix :')\n",
        "print(results) \n",
        "\n",
        "accbayes_10=accuracy_score(df1_ytest, y_pred_gnb10) \n",
        "prebayes_10=precision_score(df1_ytest, y_pred_gnb10, average='macro')\n",
        "f1bayes_10=f1_score(df1_ytest, y_pred_gnb10, average='macro')\n",
        "rebayes_10=recall_score(df1_ytest, y_pred_gnb10, average='macro')\n",
        "\n",
        "print ('Accuracy Score :',accbayes_10)\n",
        "print(\"Precision Score: \",prebayes_10)\n",
        "print(\"F1 Score: \",f1bayes_10)\n",
        "print(\"Recall: \",rebayes_10)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\t\tGaussain Naive Bayes Analysis of UNSW-NB15\n",
            "\n",
            "\t\tTop 10 Features \n",
            "Confusion Matrix :\n",
            "[[  601     0     0    14     0     1    61     0     0     0]\n",
            " [  483     0     0    38     1     2    59     0     0     0]\n",
            " [ 2473     0     0   510    72    78   934    10    12     0]\n",
            " [ 2697     0     0  1738   125    56  6494     2    20     0]\n",
            " [ 1222     0     0   752   550   374  3111     7    46     0]\n",
            " [   28     0     0   109    95 18159   475     1     4     0]\n",
            " [  193     0     1  4062  1501  2792 28284    18   149     0]\n",
            " [ 1541     0     0    68     8    15  1858     6     0     0]\n",
            " [   75     0     0     1    36     9   192     6    59     0]\n",
            " [    0     0     0     2     4     2    36     0     0     0]]\n",
            "Accuracy Score : 0.5999732789194967\n",
            "Precision Score:  0.23827456767032631\n",
            "F1 Score:  0.2239561902839405\n",
            "Recall:  0.30190991296773395\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning:\n",
            "\n",
            "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nZUmRijOs2VE",
        "outputId": "c47f4b60-ca05-413c-ae8f-917f1bfa483b"
      },
      "source": [
        "bayes_20 = MultinomialNB()\n",
        "bayes_20.fit(df2_xtrain,df2_ytrain)\n",
        "\n",
        "print (\"\\t\\tGaussian Naive Bayes Analysis of UNSW-NB15\\n\\n\\t\\tTop 20 Features \")\n",
        "\n",
        "y_pred_gnb20 = bayes_20.predict(df2_xtest)\n",
        "\n",
        "#print (\"\\t\\tMajor Verifcation KDD99 10% GNB\")\n",
        "results = confusion_matrix(df2_ytest, y_pred_gnb20) \n",
        "print ('Confusion Matrix :')\n",
        "print(results)\n",
        "\n",
        "accbayes_20=accuracy_score(df2_ytest, y_pred_gnb20) \n",
        "prebayes_20=precision_score(df2_ytest, y_pred_gnb20, average='macro')\n",
        "f1bayes_20=f1_score(df2_ytest, y_pred_gnb20, average='macro')\n",
        "rebayes_20=recall_score(df2_ytest, y_pred_gnb20, average='macro')\n",
        "\n",
        "print ('Accuracy Score :',accbayes_20)\n",
        "print(\"Precision Score: \",prebayes_20)\n",
        "print(\"F1 Score: \",f1bayes_20)\n",
        "print(\"Recall: \",rebayes_20)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\t\tGaussian Naive Bayes Analysis of UNSW-NB15\n",
            "\n",
            "\t\tTop 20 Features \n",
            "Confusion Matrix :\n",
            "[[    3     0     2    40     0   614     0     0     0    18]\n",
            " [    3     0    10    36     0   515     4     0     0    15]\n",
            " [   31     0    87   677     0  2903    17     0     0   374]\n",
            " [   36     0   128  5200     0  3163    76     0     0  2529]\n",
            " [   45     0    54  2445     0  2250     0     0     0  1268]\n",
            " [    4     0     4   345     0 18343     4     0     0   171]\n",
            " [  585     0    73 14651     0  5965  7847     1     1  7877]\n",
            " [    8     0    22  1262     0  1601     0     0     0   603]\n",
            " [    0     0     0   130     0   185     0     0     0    63]\n",
            " [    0     0     0    24     0     6     0     0     0    14]]\n",
            "Accuracy Score : 0.3825244133508235\n",
            "Precision Score:  0.1947161142507347\n",
            "F1 Score:  0.135809387243145\n",
            "Recall:  0.19951131812748615\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning:\n",
            "\n",
            "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VcEkvsRBs2YC",
        "outputId": "b04471f8-bf02-472a-c818-ea2075394a0a"
      },
      "source": [
        "bayes_all = MultinomialNB()\n",
        "bayes_all.fit(df3_xtrain,df3_ytrain)\n",
        "\n",
        "print (\"\\t\\tGaussian Naive Bayes Analysis of UNSW-NB15\\n\\n\\t\\tAll Features \")\n",
        "y_pred_gnball = bayes_all.predict(df3_xtest)\n",
        "\n",
        "#print (\"\\t\\tMajor Verifcation KDD99 10% GNB\")\n",
        "results = confusion_matrix(df3_ytest, y_pred_gnball) \n",
        "print ('Confusion Matrix :')\n",
        "print(results)\n",
        "\n",
        "accbayes_all=accuracy_score(df3_ytest, y_pred_gnball)\n",
        "prebayes_all=precision_score(df3_ytest, y_pred_gnball, average='macro')\n",
        "f1bayes_all=f1_score(df3_ytest, y_pred_gnball, average='macro')\n",
        "rebayes_all=recall_score(df3_ytest, y_pred_gnball, average='macro')\n",
        "\n",
        "print ('Accuracy Score :', accbayes_all)\n",
        "print(\"Precision Score: \",prebayes_all)\n",
        "print(\"F1 Score: \",f1bayes_all)\n",
        "print(\"Recall: \",rebayes_all)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\t\tGaussian Naive Bayes Analysis of UNSW-NB15\n",
            "\n",
            "\t\tAll Features \n",
            "Confusion Matrix :\n",
            "[[    3     0     2    40     0   614     0     0     0    18]\n",
            " [    3     0    10    36     0   515     4     0     0    15]\n",
            " [   31     0    87   677     0  2903    17     0     0   374]\n",
            " [   36     0   128  5200     0  3163    76     0     0  2529]\n",
            " [   45     0    54  2445     0  2250     0     0     0  1268]\n",
            " [    4     0     4   345     0 18343     4     0     0   171]\n",
            " [  615     0    14 14654     0  6027  7813     1     1  7875]\n",
            " [    8     0    22  1262     0  1601     0     0     0   603]\n",
            " [    0     0     0   130     0   185     0     0     0    63]\n",
            " [    0     0     0    24     0     6     0     0     0    14]]\n",
            "Accuracy Score : 0.38211145119759027\n",
            "Precision Score:  0.1988094523267321\n",
            "F1 Score:  0.13564830638485165\n",
            "Recall:  0.19941942623559425\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning:\n",
            "\n",
            "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D1DehUCas2bP"
      },
      "source": [
        "#Random Forest Classifier \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5eCGklXTuKYb",
        "outputId": "63914395-1f09-4e15-fe2a-c059152f6d43"
      },
      "source": [
        "print (\"\\t\\tRandom Forest Analysis of UNSW-NB15\\n\\n\\t\\tTop 10 Features \")\n",
        "\n",
        "#Create a Gaussian Classifier\n",
        "clfRF_10=RandomForestClassifier()\n",
        "\n",
        "#Train the model using the training sets y_pred=clf.predict(X_test)\n",
        "clfRF_10.fit(df1_xtrain,df1_ytrain)\n",
        "\n",
        "y_pred_RF10=clfRF_10.predict(df1_xtest)\n",
        "#print(\"Accuracy Random Forest:\",metrics.accuracy_score(y_test, y_pred_RF))\n",
        "\n",
        "results_10 = confusion_matrix(df1_ytest, y_pred_RF10) \n",
        "print ('Confusion Matrix :')\n",
        "print(results_10) \n",
        "\n",
        "accclfRF_10=accuracy_score(df1_ytest, y_pred_RF10)\n",
        "preclfRF_10=precision_score(df1_ytest, y_pred_RF10, average='macro')\n",
        "f1clfRF_10=f1_score(df1_ytest, y_pred_RF10, average='macro')\n",
        "reclfRF_10=recall_score(df1_ytest, y_pred_RF10, average='macro')\n",
        "\n",
        "print ('Accuracy Score :',accclfRF_10 )\n",
        "print(\"Precision Score: \",preclfRF_10)\n",
        "print(\"F1 Score: \",f1clfRF_10)\n",
        "print(\"Recall: \",reclfRF_10)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\t\tRandom Forest Analysis of UNSW-NB15\n",
            "\n",
            "\t\tTop 10 Features \n",
            "Confusion Matrix :\n",
            "[[   71   110    12    66   364     0    25    26     3     0]\n",
            " [   63    60     9    20   375     1    22    23    10     0]\n",
            " [  502  1185   516   820   812    12    52   141    47     2]\n",
            " [  535  1078   214  7542  1216    14   163   283    83     4]\n",
            " [  170   197    21   408  3952     4  1014    51   245     0]\n",
            " [    3    11    48   388    63 18320    10     5    21     2]\n",
            " [  317     0    54   731  7523     5 28233    10   126     1]\n",
            " [   60   151    27   318    97     0    15  2805    23     0]\n",
            " [    1     3    11    47    29     0    10     2   274     1]\n",
            " [    0     0     0    19     1     1     2     0     0    21]]\n",
            "Accuracy Score : 0.7505465675557499\n",
            "Precision Score:  0.5428991903650504\n",
            "F1 Score:  0.5054182617822229\n",
            "Recall:  0.5401760768626145\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jYQ8JD5ruKl8",
        "outputId": "75781aa9-52b0-4337-ee18-2eb9d7eb2c8a"
      },
      "source": [
        "print (\"\\t\\tRandom Forest Analysis of UNSW-NB15\\n\\n\\t\\tTop 20 Features \")\n",
        "\n",
        "#Create a Gaussian Classifier\n",
        "clfRF_20=RandomForestClassifier()\n",
        "\n",
        "#Train the model using the training sets y_pred=clf.predict(X_test)\n",
        "clfRF_20.fit(df2_xtrain,df2_ytrain)\n",
        "\n",
        "y_pred_RF20=clfRF_20.predict(df2_xtest)\n",
        "#print(\"Accuracy Random Forest:\",metrics.accuracy_score(y_test, y_pred_RF))\n",
        "\n",
        "results_20 = confusion_matrix(df2_ytest, y_pred_RF20) \n",
        "print ('Confusion Matrix :')\n",
        "print(results_20) \n",
        "\n",
        "accclfRF_20=accuracy_score(df2_ytest, y_pred_RF20) \n",
        "preclfRF_20=precision_score(df2_ytest, y_pred_RF20, average='macro')\n",
        "f1clfRF_20=f1_score(df2_ytest, y_pred_RF20, average='macro')\n",
        "reclfRF_20=recall_score(df2_ytest, y_pred_RF20, average='macro')\n",
        "\n",
        "print ('Accuracy Score :',accclfRF_20)\n",
        "print(\"Precision Score: \",preclfRF_20)\n",
        "print(\"F1 Score: \",f1clfRF_20)\n",
        "print(\"Recall: \",reclfRF_20)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\t\tRandom Forest Analysis of UNSW-NB15\n",
            "\n",
            "\t\tTop 20 Features \n",
            "Confusion Matrix :\n",
            "[[   38   219    17    68   226     1     9    96     3     0]\n",
            " [   34   150    14    37   238     1     9    94     6     0]\n",
            " [  434  1472   527   803   540    15    27   226    45     0]\n",
            " [  428  1441   179  7595   844    20    99   451    72     3]\n",
            " [  112   392    38   384  3836     4   874   191   231     0]\n",
            " [    6     9    36   381    49 18349    10     9    19     3]\n",
            " [  434     1    36   749  7543     6 28103     6   121     1]\n",
            " [   50   177    26   302    69     1     5  2836    30     0]\n",
            " [    0     1    11    52    43     0     9     3   258     1]\n",
            " [    0     0     0    31     2     1     1     0     0     9]]\n",
            "Accuracy Score : 0.7494169946072001\n",
            "Precision Score:  0.5220938277705522\n",
            "F1 Score:  0.4752407618578462\n",
            "Recall:  0.5187541028261868\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EpJHXBBTuKvd",
        "outputId": "bc6ace09-72f6-454a-faca-f805cf0ff999"
      },
      "source": [
        "print (\"\\t\\tRandom Forest Analysis of UNSW-NB15\\n\\n\\t\\tTop 30 Features \")\n",
        "\n",
        "#Create a Random Forest Classifier\n",
        "clfRF_all=RandomForestClassifier()\n",
        "\n",
        "#Train the model using the training sets y_pred=clf.predict(X_test)\n",
        "clfRF_all.fit(df3_xtrain,df3_ytrain)\n",
        "\n",
        "y_pred_RFall=clfRF_all.predict(df3_xtest)\n",
        "#print(\"Accuracy Random Forest:\",metrics.accuracy_score(y_test, y_pred_RF))\n",
        "\n",
        "results_all = confusion_matrix(df3_ytest, y_pred_RFall) \n",
        "print ('Confusion Matrix :')\n",
        "print(results_all) \n",
        "\n",
        "accclfRF_all=accuracy_score(df3_ytest, y_pred_RFall) \n",
        "preclfRF_all=precision_score(df3_ytest, y_pred_RFall, average='macro')\n",
        "f1clfRF_all=f1_score(df3_ytest, y_pred_RFall, average='macro')\n",
        "reclfRF_all=recall_score(df3_ytest, y_pred_RFall, average='macro')\n",
        "\n",
        "print ('Accuracy Score :',accclfRF_all)\n",
        "print(\"Precision Score: \",preclfRF_all)\n",
        "print(\"F1 Score: \",f1clfRF_all)\n",
        "print(\"Recall: \",reclfRF_all)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\t\tRandom Forest Analysis of UNSW-NB15\n",
            "\n",
            "\t\tTop 30 Features \n",
            "Confusion Matrix :\n",
            "[[   30   271     7    71   238     0     3    54     3     0]\n",
            " [   29   189    11    33   257     0     1    57     6     0]\n",
            " [  222  1814   442   785   580     8    16   178    44     0]\n",
            " [  258  1790    99  7603   864    17    98   335    67     1]\n",
            " [   77   494    17   391  3867     4   905   106   201     0]\n",
            " [    1     6    37   401    62 18323     7    10    22     2]\n",
            " [  478     0    21   725  7342     5 28294    11   124     0]\n",
            " [   27   217    18   323    75     1     7  2810    18     0]\n",
            " [    0     0    11    51    41     1     8     1   264     1]\n",
            " [    0     0     0    32     3     1     1     0     0     7]]\n",
            "Accuracy Score : 0.7509716756546665\n",
            "Precision Score:  0.5493110210438574\n",
            "F1 Score:  0.4750998961874088\n",
            "Recall:  0.519443033842766\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v6N3Y69QuLDL"
      },
      "source": [
        "#Logistic Regression Classifier \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 540
        },
        "id": "GJHJebbCuSZr",
        "outputId": "4ccd205d-ae8c-440b-d2d1-3059f9d2ad44"
      },
      "source": [
        "print (\"\\t\\tLogistic Regression Analysis of UNSW-NB15\\n\\n\\t\\tTop 10 Features \")\n",
        "\n",
        "logisticRegr_10 = LogisticRegression(C=1e5, solver='newton-cg',max_iter=1000, multi_class='multinomial')\n",
        "\n",
        "logisticRegr_10.fit(df1_xtrain,df1_ytrain)\n",
        "\n",
        "y_pred_LR10 = logisticRegr_10.predict(df1_xtest)\n",
        "\n",
        "results_LR10 = confusion_matrix(df1_ytest, y_pred_LR10) \n",
        "print ('Confusion Matrix :')\n",
        "print(results_LR10) \n",
        "\n",
        "acclogisticRegr_10=accuracy_score(df1_ytest, y_pred_LR10)\n",
        "prelogisticRegr_10=precision_score(df1_ytest, y_pred_LR10, average='macro')\n",
        "f1logisticRegr_10=f1_score(df1_ytest, y_pred_LR10, average='macro')\n",
        "relogisticRegr_10=recall_score(df1_ytest, y_pred_LR10, average='macro')\n",
        "\n",
        "print ('Accuracy Score :',acclogisticRegr_10 )\n",
        "print(\"Precision Score: \",prelogisticRegr_10)\n",
        "print(\"F1 Score: \",f1logisticRegr_10)\n",
        "print(\"Recall: \",relogisticRegr_10)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\t\tLogistic Regression Analysis of UNSW-NB15\n",
            "\n",
            "\t\tTop 10 Features \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/scipy/optimize/linesearch.py:466: LineSearchWarning:\n",
            "\n",
            "The line search algorithm did not converge\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/scipy/optimize/linesearch.py:314: LineSearchWarning:\n",
            "\n",
            "The line search algorithm did not converge\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-187a8e851665>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mlogisticRegr_10\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mC\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msolver\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'newton-cg'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmulti_class\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'multinomial'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mlogisticRegr_10\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf1_xtrain\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdf1_ytrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0my_pred_LR10\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogisticRegr_10\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf1_xtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1599\u001b[0m                       \u001b[0mpenalty\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpenalty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_squared_sum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_squared_sum\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1600\u001b[0m                       sample_weight=sample_weight)\n\u001b[0;32m-> 1601\u001b[0;31m             for class_, warm_start_coef_ in zip(classes_, warm_start_coef))\n\u001b[0m\u001b[1;32m   1602\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1603\u001b[0m         \u001b[0mfold_coefs_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_iter_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfold_coefs_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1039\u001b[0m             \u001b[0;31m# remaining jobs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1040\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1041\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1042\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1043\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    857\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    860\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    775\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    776\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 777\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    778\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 263\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 263\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py\u001b[0m in \u001b[0;36m_logistic_regression_path\u001b[0;34m(X, y, pos_class, Cs, fit_intercept, max_iter, tol, verbose, solver, coef, class_weight, dual, penalty, intercept_scaling, multi_class, random_state, check_input, max_squared_sum, sample_weight, l1_ratio)\u001b[0m\n\u001b[1;32m    943\u001b[0m             \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m             w0, n_iter_i = _newton_cg(hess, func, grad, w0, args=args,\n\u001b[0;32m--> 945\u001b[0;31m                                       maxiter=max_iter, tol=tol)\n\u001b[0m\u001b[1;32m    946\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0msolver\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'liblinear'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m             coef_, intercept_, n_iter_i, = _fit_liblinear(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/optimize.py\u001b[0m in \u001b[0;36m_newton_cg\u001b[0;34m(grad_hess, func, grad, x0, args, tol, maxiter, maxinner, line_search, warn)\u001b[0m\n\u001b[1;32m    200\u001b[0m                 \u001b[0malphak\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mold_fval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mold_old_fval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgfkp1\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                     _line_search_wolfe12(func, grad, xk, xsupi, fgrad,\n\u001b[0;32m--> 202\u001b[0;31m                                          old_fval, old_old_fval, args=args)\n\u001b[0m\u001b[1;32m    203\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0m_LineSearchError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Line Search failed'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/optimize.py\u001b[0m in \u001b[0;36m_line_search_wolfe12\u001b[0;34m(f, fprime, xk, pk, gfk, old_fval, old_old_fval, **kwargs)\u001b[0m\n\u001b[1;32m     41\u001b[0m     ret = line_search_wolfe1(f, fprime, xk, pk, gfk,\n\u001b[1;32m     42\u001b[0m                              \u001b[0mold_fval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mold_old_fval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m                              **kwargs)\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/scipy/optimize/linesearch.py\u001b[0m in \u001b[0;36mline_search_wolfe1\u001b[0;34m(f, fprime, xk, pk, gfk, old_fval, old_old_fval, args, c1, c2, amax, amin, xtol)\u001b[0m\n\u001b[1;32m     99\u001b[0m     stp, fval, old_fval = scalar_search_wolfe1(\n\u001b[1;32m    100\u001b[0m             \u001b[0mphi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mderphi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mold_fval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mold_old_fval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mderphi0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m             c1=c1, c2=c2, amax=amax, amin=amin, xtol=xtol)\n\u001b[0m\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mstp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mold_fval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgval\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/scipy/optimize/linesearch.py\u001b[0m in \u001b[0;36mscalar_search_wolfe1\u001b[0;34m(phi, derphi, phi0, old_phi0, derphi0, c1, c2, amax, amin, xtol)\u001b[0m\n\u001b[1;32m    173\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34mb'FG'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m             \u001b[0malpha1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m             \u001b[0mphi1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mphi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    176\u001b[0m             \u001b[0mderphi1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mderphi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/scipy/optimize/linesearch.py\u001b[0m in \u001b[0;36mphi\u001b[0;34m(s)\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mphi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0mfc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxk\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mpk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mderphi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x, *args)\u001b[0m\n\u001b[1;32m    911\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_multinomial_loss_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    912\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0msolver\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'newton-cg'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 913\u001b[0;31m             \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_multinomial_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    914\u001b[0m             \u001b[0mgrad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_multinomial_loss_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    915\u001b[0m             \u001b[0mhess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_multinomial_grad_hess\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py\u001b[0m in \u001b[0;36m_multinomial_loss\u001b[0;34m(w, X, Y, alpha, sample_weight)\u001b[0m\n\u001b[1;32m    297\u001b[0m     \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msafe_sparse_dot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m     \u001b[0mp\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mintercept\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 299\u001b[0;31m     \u001b[0mp\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0mlogsumexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    300\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_weight\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mY\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m0.5\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0malpha\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0msquared_norm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 410
        },
        "id": "_xO1WIT4uScz",
        "outputId": "f67b672e-cb84-4c81-f9d5-aee525edaf38"
      },
      "source": [
        "print (\"\\t\\tLogistic Regression Analysis of UNSW NB15\\n\\n\\t\\tTop 20 Features \")\n",
        "\n",
        "logisticRegr_20 = LogisticRegression(C=1e5, solver='newton-cg',max_iter=1000, multi_class='multinomial')\n",
        "\n",
        "logisticRegr_20.fit(df2_xtrain,df2_ytrain)\n",
        "\n",
        "y_pred_LR20 = logisticRegr_20.predict(df2_xtest)\n",
        "\n",
        "results_LR20 = confusion_matrix(df2_ytest, y_pred_LR20) \n",
        "print ('Confusion Matrix :')\n",
        "print(results_LR20) \n",
        "\n",
        "acclogisticRegr_20=accuracy_score(df2_ytest, y_pred_LR20)\n",
        "prelogisticRegr_20=precision_score(df2_ytest, y_pred_LR20, average='macro')\n",
        "f1logisticRegr_20=f1_score(df2_ytest, y_pred_LR20, average='macro')\n",
        "relogisticRegr_20=recall_score(df2_ytest, y_pred_LR20, average='macro')\n",
        "\n",
        "print ('Accuracy Score :',acclogisticRegr_20 )\n",
        "print(\"Precision Score: \",prelogisticRegr_20)\n",
        "print(\"F1 Score: \",f1logisticRegr_20)\n",
        "print(\"Recall: \",relogisticRegr_20)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\t\tLogistic Regression Analysis of UNSW NB15\n",
            "\n",
            "\t\tTop 20 Features \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-30-1923c723dd65>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mlogisticRegr_20\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mC\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msolver\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'newton-cg'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmulti_class\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'multinomial'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mlogisticRegr_20\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf2_xtrain\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdf2_ytrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0my_pred_LR20\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogisticRegr_20\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf2_xtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1599\u001b[0m                       \u001b[0mpenalty\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpenalty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_squared_sum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_squared_sum\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1600\u001b[0m                       sample_weight=sample_weight)\n\u001b[0;32m-> 1601\u001b[0;31m             for class_, warm_start_coef_ in zip(classes_, warm_start_coef))\n\u001b[0m\u001b[1;32m   1602\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1603\u001b[0m         \u001b[0mfold_coefs_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_iter_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfold_coefs_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1039\u001b[0m             \u001b[0;31m# remaining jobs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1040\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1041\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1042\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1043\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    857\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    860\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    775\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    776\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 777\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    778\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 263\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 263\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py\u001b[0m in \u001b[0;36m_logistic_regression_path\u001b[0;34m(X, y, pos_class, Cs, fit_intercept, max_iter, tol, verbose, solver, coef, class_weight, dual, penalty, intercept_scaling, multi_class, random_state, check_input, max_squared_sum, sample_weight, l1_ratio)\u001b[0m\n\u001b[1;32m    943\u001b[0m             \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m             w0, n_iter_i = _newton_cg(hess, func, grad, w0, args=args,\n\u001b[0;32m--> 945\u001b[0;31m                                       maxiter=max_iter, tol=tol)\n\u001b[0m\u001b[1;32m    946\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0msolver\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'liblinear'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m             coef_, intercept_, n_iter_i, = _fit_liblinear(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/optimize.py\u001b[0m in \u001b[0;36m_newton_cg\u001b[0;34m(grad_hess, func, grad, x0, args, tol, maxiter, maxinner, line_search, warn)\u001b[0m\n\u001b[1;32m    200\u001b[0m                 \u001b[0malphak\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mold_fval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mold_old_fval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgfkp1\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                     _line_search_wolfe12(func, grad, xk, xsupi, fgrad,\n\u001b[0;32m--> 202\u001b[0;31m                                          old_fval, old_old_fval, args=args)\n\u001b[0m\u001b[1;32m    203\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0m_LineSearchError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Line Search failed'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/optimize.py\u001b[0m in \u001b[0;36m_line_search_wolfe12\u001b[0;34m(f, fprime, xk, pk, gfk, old_fval, old_old_fval, **kwargs)\u001b[0m\n\u001b[1;32m     41\u001b[0m     ret = line_search_wolfe1(f, fprime, xk, pk, gfk,\n\u001b[1;32m     42\u001b[0m                              \u001b[0mold_fval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mold_old_fval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m                              **kwargs)\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/scipy/optimize/linesearch.py\u001b[0m in \u001b[0;36mline_search_wolfe1\u001b[0;34m(f, fprime, xk, pk, gfk, old_fval, old_old_fval, args, c1, c2, amax, amin, xtol)\u001b[0m\n\u001b[1;32m     99\u001b[0m     stp, fval, old_fval = scalar_search_wolfe1(\n\u001b[1;32m    100\u001b[0m             \u001b[0mphi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mderphi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mold_fval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mold_old_fval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mderphi0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m             c1=c1, c2=c2, amax=amax, amin=amin, xtol=xtol)\n\u001b[0m\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mstp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mold_fval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgval\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/scipy/optimize/linesearch.py\u001b[0m in \u001b[0;36mscalar_search_wolfe1\u001b[0;34m(phi, derphi, phi0, old_phi0, derphi0, c1, c2, amax, amin, xtol)\u001b[0m\n\u001b[1;32m    173\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34mb'FG'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m             \u001b[0malpha1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m             \u001b[0mphi1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mphi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    176\u001b[0m             \u001b[0mderphi1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mderphi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/scipy/optimize/linesearch.py\u001b[0m in \u001b[0;36mphi\u001b[0;34m(s)\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mphi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0mfc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxk\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mpk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mderphi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x, *args)\u001b[0m\n\u001b[1;32m    911\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_multinomial_loss_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    912\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0msolver\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'newton-cg'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 913\u001b[0;31m             \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_multinomial_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    914\u001b[0m             \u001b[0mgrad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_multinomial_loss_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    915\u001b[0m             \u001b[0mhess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_multinomial_grad_hess\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py\u001b[0m in \u001b[0;36m_multinomial_loss\u001b[0;34m(w, X, Y, alpha, sample_weight)\u001b[0m\n\u001b[1;32m    297\u001b[0m     \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msafe_sparse_dot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m     \u001b[0mp\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mintercept\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 299\u001b[0;31m     \u001b[0mp\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0mlogsumexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    300\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_weight\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mY\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m0.5\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0malpha\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0msquared_norm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/scipy/special/_logsumexp.py\u001b[0m in \u001b[0;36mlogsumexp\u001b[0;34m(a, axis, b, keepdims, return_sign)\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0mtmp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0ma_max\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m         \u001b[0mtmp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0ma_max\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0;31m# suppress warnings about log of zero\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lp-GI4YS4kUT"
      },
      "source": [
        "print (\"\\t\\tLogistic Regression Analysis of UNSW-NB15\\n\\n\\t\\tTop 30 Features \")\n",
        "\n",
        "logisticRegr_all = LogisticRegression(C=1e5, solver='Newton-cg', multi_class='multinomial')\n",
        "\n",
        "logisticRegr_all.fit(df3_xtrain,df3_ytrain)\n",
        "\n",
        "y_pred_LRall = logisticRegr_all.predict(df3_xtest)\n",
        "\n",
        "results_LRall = confusion_matrix(df3_ytest, y_pred_LRall) \n",
        "print ('Confusion Matrix :')\n",
        "print(results_LRall) \n",
        "\n",
        "acclogisticRegr_all=accuracy_score(df3_ytest, y_pred_LRall)\n",
        "prelogisticRegr_all=precision_score(df3_ytest, y_pred_LRall, average='macro')\n",
        "f1logisticRegr_all=f1_score(df3_ytest, y_pred_LRall, average='macro')\n",
        "relogisticRegr_all=recall_score(df3_ytest, y_pred_LRall, average='macro')\n",
        "\n",
        "print ('Accuracy Score :', acclogisticRegr_all)\n",
        "print(\"Precision Score: \",prelogisticRegr_all)\n",
        "print(\"F1 Score: \",f1logisticRegr_all)\n",
        "print(\"Recall: \",relogisticRegr_all)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bb4K050wkqgQ"
      },
      "source": [
        "from __future__ import print_function\n",
        "import numpy as np\n",
        "np.random.seed(1337)  # for reproducibility\n",
        "\n",
        "from keras.preprocessing import sequence\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Lambda\n",
        "from keras.layers import Embedding\n",
        "from keras.layers import Convolution1D,MaxPooling1D, Flatten\n",
        "from keras.datasets import imdb\n",
        "from keras import backend as K\n",
        "#from sklearn.cross_validation import train_test_split\n",
        "import pandas as pd\n",
        "from keras.utils.np_utils import to_categorical\n",
        "\n",
        "from sklearn.preprocessing import Normalizer\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Convolution1D, Dense, Dropout, Flatten, MaxPooling1D\n",
        "from keras.utils import np_utils\n",
        "import numpy as np\n",
        "import h5py\n",
        "from keras import callbacks\n",
        "from keras.layers import LSTM, GRU, SimpleRNN\n",
        "from keras.callbacks import CSVLogger\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, CSVLogger"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nTDUTMLgtmpg",
        "outputId": "f798d479-1eac-4ddb-a6ea-f620ad05a4d0"
      },
      "source": [
        "#DNN\n",
        "X = df1_xtrain\n",
        "Y = df1_ytrain\n",
        "C = df3_ytest\n",
        "T = df1_xtest\n",
        "scaler = Normalizer().fit(X)\n",
        "trainX = scaler.transform(X)\n",
        "\n",
        "scaler = Normalizer().fit(T)\n",
        "testT = scaler.transform(T)\n",
        "\n",
        "y_train1 = np.array(Y)\n",
        "y_test1 = np.array(C)\n",
        "\n",
        "y_train= to_categorical(y_train1)\n",
        "y_test= to_categorical(y_test1)\n",
        "\n",
        "\n",
        "# reshape input to be [samples, time steps, features]\n",
        "X_train = np.reshape(trainX, (trainX.shape[0],trainX.shape[1],1))\n",
        "X_test = np.reshape(testT, (testT.shape[0],testT.shape[1],1))\n",
        "\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras import layers\n",
        "\n",
        "input_dim = df1_xtrain.shape[1]  # Number of features\n",
        "\n",
        "model = Sequential()\n",
        "model.add(layers.Dense(10, input_shape=(15, 1), activation='relu'))\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(32, activation='relu'))\n",
        "model.add(layers.Dense(10, activation='softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', \n",
        "              optimizer='adam', \n",
        "              metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 15, 10)            20        \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 150)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 32)                4832      \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 10)                330       \n",
            "=================================================================\n",
            "Total params: 5,182\n",
            "Trainable params: 5,182\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mAvwB1CKtx2X",
        "outputId": "19728493-9a88-4211-f679-1afd22504b7a"
      },
      "source": [
        "historyNN10 = model.fit(X_train, y_train,\n",
        "                    epochs=100 #,\n",
        "                    #verbose=False\n",
        "                    )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "3367/3367 [==============================] - 11s 2ms/step - loss: 1.4270 - accuracy: 0.4867\n",
            "Epoch 2/100\n",
            "3367/3367 [==============================] - 8s 2ms/step - loss: 1.1978 - accuracy: 0.5175\n",
            "Epoch 3/100\n",
            "3367/3367 [==============================] - 8s 2ms/step - loss: 1.1149 - accuracy: 0.5655\n",
            "Epoch 4/100\n",
            "3367/3367 [==============================] - 8s 2ms/step - loss: 1.0647 - accuracy: 0.5997\n",
            "Epoch 5/100\n",
            "3367/3367 [==============================] - 8s 2ms/step - loss: 1.0318 - accuracy: 0.6137\n",
            "Epoch 6/100\n",
            "3367/3367 [==============================] - 8s 2ms/step - loss: 1.0075 - accuracy: 0.6244\n",
            "Epoch 7/100\n",
            "3367/3367 [==============================] - 8s 2ms/step - loss: 0.9946 - accuracy: 0.6368\n",
            "Epoch 8/100\n",
            "3367/3367 [==============================] - 8s 2ms/step - loss: 0.9796 - accuracy: 0.6417\n",
            "Epoch 9/100\n",
            "3367/3367 [==============================] - 8s 2ms/step - loss: 0.9664 - accuracy: 0.6472\n",
            "Epoch 10/100\n",
            "3367/3367 [==============================] - 8s 2ms/step - loss: 0.9560 - accuracy: 0.6539\n",
            "Epoch 11/100\n",
            "3367/3367 [==============================] - 8s 2ms/step - loss: 0.9464 - accuracy: 0.6570\n",
            "Epoch 12/100\n",
            "3367/3367 [==============================] - 8s 2ms/step - loss: 0.9360 - accuracy: 0.6606\n",
            "Epoch 13/100\n",
            "3367/3367 [==============================] - 8s 2ms/step - loss: 0.9277 - accuracy: 0.6656\n",
            "Epoch 14/100\n",
            "3367/3367 [==============================] - 8s 2ms/step - loss: 0.9165 - accuracy: 0.6687\n",
            "Epoch 15/100\n",
            "3367/3367 [==============================] - 8s 2ms/step - loss: 0.9143 - accuracy: 0.6686\n",
            "Epoch 16/100\n",
            "3367/3367 [==============================] - 8s 2ms/step - loss: 0.9066 - accuracy: 0.6705\n",
            "Epoch 17/100\n",
            "3367/3367 [==============================] - 8s 2ms/step - loss: 0.8980 - accuracy: 0.6719\n",
            "Epoch 18/100\n",
            "3367/3367 [==============================] - 8s 2ms/step - loss: 0.8962 - accuracy: 0.6765\n",
            "Epoch 19/100\n",
            "3367/3367 [==============================] - 8s 2ms/step - loss: 0.8912 - accuracy: 0.6768\n",
            "Epoch 20/100\n",
            "3367/3367 [==============================] - 8s 2ms/step - loss: 0.8836 - accuracy: 0.6794\n",
            "Epoch 21/100\n",
            "3367/3367 [==============================] - 8s 2ms/step - loss: 0.8805 - accuracy: 0.6820\n",
            "Epoch 22/100\n",
            "3367/3367 [==============================] - 8s 2ms/step - loss: 0.8782 - accuracy: 0.6859\n",
            "Epoch 23/100\n",
            "3367/3367 [==============================] - 8s 2ms/step - loss: 0.8782 - accuracy: 0.6839\n",
            "Epoch 24/100\n",
            "3367/3367 [==============================] - 8s 2ms/step - loss: 0.8757 - accuracy: 0.6834\n",
            "Epoch 25/100\n",
            "3367/3367 [==============================] - 8s 2ms/step - loss: 0.8668 - accuracy: 0.6886\n",
            "Epoch 26/100\n",
            "3367/3367 [==============================] - 8s 2ms/step - loss: 0.8678 - accuracy: 0.6891\n",
            "Epoch 27/100\n",
            "3367/3367 [==============================] - 8s 2ms/step - loss: 0.8730 - accuracy: 0.6870\n",
            "Epoch 28/100\n",
            "3367/3367 [==============================] - 8s 2ms/step - loss: 0.8621 - accuracy: 0.6921\n",
            "Epoch 29/100\n",
            "3367/3367 [==============================] - 8s 2ms/step - loss: 0.8567 - accuracy: 0.6939\n",
            "Epoch 30/100\n",
            "3367/3367 [==============================] - 8s 2ms/step - loss: 0.8545 - accuracy: 0.6938\n",
            "Epoch 31/100\n",
            "3367/3367 [==============================] - 8s 2ms/step - loss: 0.8528 - accuracy: 0.6958\n",
            "Epoch 32/100\n",
            "3367/3367 [==============================] - 8s 2ms/step - loss: 0.8509 - accuracy: 0.6964\n",
            "Epoch 33/100\n",
            "3367/3367 [==============================] - 8s 2ms/step - loss: 0.8478 - accuracy: 0.6985\n",
            "Epoch 34/100\n",
            "3367/3367 [==============================] - 8s 2ms/step - loss: 0.8427 - accuracy: 0.7024\n",
            "Epoch 35/100\n",
            "3367/3367 [==============================] - 8s 2ms/step - loss: 0.8456 - accuracy: 0.7012\n",
            "Epoch 36/100\n",
            "3367/3367 [==============================] - 8s 2ms/step - loss: 0.8416 - accuracy: 0.7013\n",
            "Epoch 37/100\n",
            "3367/3367 [==============================] - 8s 2ms/step - loss: 0.8388 - accuracy: 0.7014\n",
            "Epoch 38/100\n",
            "3367/3367 [==============================] - 8s 2ms/step - loss: 0.8355 - accuracy: 0.7031\n",
            "Epoch 39/100\n",
            "3367/3367 [==============================] - 8s 2ms/step - loss: 0.8409 - accuracy: 0.6996\n",
            "Epoch 40/100\n",
            "3367/3367 [==============================] - 8s 2ms/step - loss: 0.8387 - accuracy: 0.7053\n",
            "Epoch 41/100\n",
            "3367/3367 [==============================] - 8s 2ms/step - loss: 0.8313 - accuracy: 0.7044\n",
            "Epoch 42/100\n",
            "3367/3367 [==============================] - 8s 2ms/step - loss: 0.8318 - accuracy: 0.7065\n",
            "Epoch 43/100\n",
            "3367/3367 [==============================] - 8s 2ms/step - loss: 0.8204 - accuracy: 0.7092\n",
            "Epoch 44/100\n",
            "3367/3367 [==============================] - 8s 2ms/step - loss: 0.8235 - accuracy: 0.7076\n",
            "Epoch 45/100\n",
            "3367/3367 [==============================] - 8s 2ms/step - loss: 0.8157 - accuracy: 0.7096\n",
            "Epoch 46/100\n",
            "3367/3367 [==============================] - 8s 2ms/step - loss: 0.8189 - accuracy: 0.7090\n",
            "Epoch 47/100\n",
            "3367/3367 [==============================] - 8s 2ms/step - loss: 0.8238 - accuracy: 0.7064\n",
            "Epoch 48/100\n",
            "3367/3367 [==============================] - 8s 2ms/step - loss: 0.8207 - accuracy: 0.7091\n",
            "Epoch 49/100\n",
            "3367/3367 [==============================] - 8s 2ms/step - loss: 0.8121 - accuracy: 0.7114\n",
            "Epoch 50/100\n",
            "3367/3367 [==============================] - 8s 2ms/step - loss: 0.8133 - accuracy: 0.7097\n",
            "Epoch 51/100\n",
            "3367/3367 [==============================] - 8s 2ms/step - loss: 0.8186 - accuracy: 0.7071\n",
            "Epoch 52/100\n",
            "3367/3367 [==============================] - 8s 2ms/step - loss: 0.8145 - accuracy: 0.7107\n",
            "Epoch 53/100\n",
            "3367/3367 [==============================] - 8s 2ms/step - loss: 0.8061 - accuracy: 0.7123\n",
            "Epoch 54/100\n",
            "3367/3367 [==============================] - 8s 2ms/step - loss: 0.8113 - accuracy: 0.7103\n",
            "Epoch 55/100\n",
            "3367/3367 [==============================] - 8s 2ms/step - loss: 0.8065 - accuracy: 0.7130\n",
            "Epoch 56/100\n",
            "3367/3367 [==============================] - 8s 2ms/step - loss: 0.8071 - accuracy: 0.7112\n",
            "Epoch 57/100\n",
            "3367/3367 [==============================] - 8s 2ms/step - loss: 0.8086 - accuracy: 0.7120\n",
            "Epoch 58/100\n",
            "3367/3367 [==============================] - 8s 2ms/step - loss: 0.8041 - accuracy: 0.7122\n",
            "Epoch 59/100\n",
            "3367/3367 [==============================] - 8s 2ms/step - loss: 0.8042 - accuracy: 0.7134\n",
            "Epoch 60/100\n",
            "3367/3367 [==============================] - 8s 2ms/step - loss: 0.8069 - accuracy: 0.7106\n",
            "Epoch 61/100\n",
            "3367/3367 [==============================] - 8s 2ms/step - loss: 0.8035 - accuracy: 0.7141\n",
            "Epoch 62/100\n",
            "3367/3367 [==============================] - 8s 2ms/step - loss: 0.7960 - accuracy: 0.7156\n",
            "Epoch 63/100\n",
            "3367/3367 [==============================] - 8s 2ms/step - loss: 0.7968 - accuracy: 0.7147\n",
            "Epoch 64/100\n",
            "3367/3367 [==============================] - 8s 2ms/step - loss: 0.7875 - accuracy: 0.7177\n",
            "Epoch 65/100\n",
            "3367/3367 [==============================] - 8s 2ms/step - loss: 0.7943 - accuracy: 0.7162\n",
            "Epoch 66/100\n",
            "3367/3367 [==============================] - 8s 2ms/step - loss: 0.7889 - accuracy: 0.7147\n",
            "Epoch 67/100\n",
            "3367/3367 [==============================] - 8s 2ms/step - loss: 0.7878 - accuracy: 0.7166\n",
            "Epoch 68/100\n",
            "3367/3367 [==============================] - 8s 2ms/step - loss: 0.7881 - accuracy: 0.7174\n",
            "Epoch 69/100\n",
            "3367/3367 [==============================] - 8s 2ms/step - loss: 0.7897 - accuracy: 0.7160\n",
            "Epoch 70/100\n",
            "3367/3367 [==============================] - 8s 2ms/step - loss: 0.7952 - accuracy: 0.7149\n",
            "Epoch 71/100\n",
            "3367/3367 [==============================] - 8s 2ms/step - loss: 0.7923 - accuracy: 0.7170\n",
            "Epoch 72/100\n",
            "3367/3367 [==============================] - 8s 2ms/step - loss: 0.7826 - accuracy: 0.7176\n",
            "Epoch 74/100\n",
            "3367/3367 [==============================] - 8s 2ms/step - loss: 0.7800 - accuracy: 0.7181\n",
            "Epoch 75/100\n",
            "3367/3367 [==============================] - 8s 2ms/step - loss: 0.7858 - accuracy: 0.7177\n",
            "Epoch 76/100\n",
            "3367/3367 [==============================] - 8s 2ms/step - loss: 0.7787 - accuracy: 0.7201\n",
            "Epoch 77/100\n",
            "3367/3367 [==============================] - 8s 2ms/step - loss: 0.7812 - accuracy: 0.7199\n",
            "Epoch 78/100\n",
            "3367/3367 [==============================] - 8s 2ms/step - loss: 0.7783 - accuracy: 0.7187\n",
            "Epoch 79/100\n",
            "3367/3367 [==============================] - 8s 2ms/step - loss: 0.7776 - accuracy: 0.7201\n",
            "Epoch 80/100\n",
            "3367/3367 [==============================] - 8s 2ms/step - loss: 0.7772 - accuracy: 0.7219\n",
            "Epoch 81/100\n",
            "3367/3367 [==============================] - 8s 2ms/step - loss: 0.7773 - accuracy: 0.7197\n",
            "Epoch 82/100\n",
            "3367/3367 [==============================] - 8s 2ms/step - loss: 0.7742 - accuracy: 0.7219\n",
            "Epoch 83/100\n",
            "3367/3367 [==============================] - 8s 2ms/step - loss: 0.7699 - accuracy: 0.7229\n",
            "Epoch 84/100\n",
            "3367/3367 [==============================] - 8s 2ms/step - loss: 0.7690 - accuracy: 0.7230\n",
            "Epoch 85/100\n",
            "3367/3367 [==============================] - 8s 2ms/step - loss: 0.7756 - accuracy: 0.7210\n",
            "Epoch 86/100\n",
            "3367/3367 [==============================] - 8s 2ms/step - loss: 0.7729 - accuracy: 0.7214\n",
            "Epoch 87/100\n",
            "3367/3367 [==============================] - 8s 2ms/step - loss: 0.7710 - accuracy: 0.7238\n",
            "Epoch 88/100\n",
            "3367/3367 [==============================] - 8s 2ms/step - loss: 0.7668 - accuracy: 0.7243\n",
            "Epoch 89/100\n",
            "3367/3367 [==============================] - 8s 2ms/step - loss: 0.7612 - accuracy: 0.7249\n",
            "Epoch 90/100\n",
            "3367/3367 [==============================] - 8s 2ms/step - loss: 0.7582 - accuracy: 0.7241\n",
            "Epoch 91/100\n",
            "3367/3367 [==============================] - 8s 2ms/step - loss: 0.7627 - accuracy: 0.7247\n",
            "Epoch 92/100\n",
            "3367/3367 [==============================] - 8s 2ms/step - loss: 0.7573 - accuracy: 0.7274\n",
            "Epoch 93/100\n",
            "3367/3367 [==============================] - 8s 2ms/step - loss: 0.7636 - accuracy: 0.7223\n",
            "Epoch 94/100\n",
            "3367/3367 [==============================] - 8s 2ms/step - loss: 0.7614 - accuracy: 0.7265\n",
            "Epoch 95/100\n",
            "3367/3367 [==============================] - 8s 2ms/step - loss: 0.7559 - accuracy: 0.7268\n",
            "Epoch 96/100\n",
            "3367/3367 [==============================] - 8s 2ms/step - loss: 0.7614 - accuracy: 0.7254\n",
            "Epoch 97/100\n",
            "3367/3367 [==============================] - 8s 2ms/step - loss: 0.7584 - accuracy: 0.7247\n",
            "Epoch 98/100\n",
            "3367/3367 [==============================] - 8s 2ms/step - loss: 0.7612 - accuracy: 0.7270\n",
            "Epoch 99/100\n",
            "3367/3367 [==============================] - 8s 2ms/step - loss: 0.7583 - accuracy: 0.7248\n",
            "Epoch 100/100\n",
            "3367/3367 [==============================] - 8s 2ms/step - loss: 0.7516 - accuracy: 0.7291\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223
        },
        "id": "R8Qt9oVSuEc-",
        "outputId": "e7dbc66c-e756-4b91-c109-28c2999911ca"
      },
      "source": [
        "loss, accNN10 = model.evaluate(X_train, y_train, verbose=True)\n",
        "print(\"Training Accuracy: {:.4f}\".format(accNN10))\n",
        "\n",
        "#loss, accuracy = model.evaluate(y_test, X_test, verbose=True)\n",
        "#print(\"Testing Accuracy:  {:.4f}\".format(accuracy))\n"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-55-080488749f3a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccNN10\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Training Accuracy: {:.4f}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccNN10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#loss, accuracy = model.evaluate(y_test, X_test, verbose=True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#print(\"Testing Accuracy:  {:.4f}\".format(accuracy))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'StackingClassifier' object has no attribute 'evaluate'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HxJQVfxJE0eF"
      },
      "source": [
        ""
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DjkKak0CuSwM"
      },
      "source": [
        "#CNN 1D\n",
        "from __future__ import print_function\n",
        "import numpy as np\n",
        "np.random.seed(1337)  # for reproducibility\n",
        "\n",
        "from keras.preprocessing import sequence\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Lambda\n",
        "from keras.layers import Embedding\n",
        "from keras.layers import Convolution1D,MaxPooling1D, Flatten\n",
        "from keras.datasets import imdb\n",
        "from keras import backend as K\n",
        "#from sklearn.cross_validation import train_test_split\n",
        "import pandas as pd\n",
        "from keras.utils.np_utils import to_categorical\n",
        "\n",
        "from sklearn.preprocessing import Normalizer\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Convolution1D, Dense, Dropout, Flatten, MaxPooling1D\n",
        "from keras.utils import np_utils\n",
        "import numpy as np\n",
        "import h5py\n",
        "from keras import callbacks\n",
        "from keras.layers import LSTM, GRU, SimpleRNN\n",
        "from keras.callbacks import CSVLogger\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, CSVLogger"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "THg2erH1rxH1"
      },
      "source": [
        "X = df1_xtrain\n",
        "Y = df1_ytrain\n",
        "C = df3_ytest\n",
        "T = df1_xtest\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KylIZNhHsADu",
        "outputId": "5ada77ef-0b5f-4dc9-f56a-0fb23cc7fb6d"
      },
      "source": [
        "scaler = Normalizer().fit(X)\n",
        "trainX = scaler.transform(X)\n",
        "\n",
        "scaler = Normalizer().fit(T)\n",
        "testT = scaler.transform(T)\n",
        "\n",
        "y_train1 = np.array(Y)\n",
        "y_test1 = np.array(C)\n",
        "\n",
        "y_train= to_categorical(y_train1)\n",
        "y_test= to_categorical(y_test1)\n",
        "\n",
        "\n",
        "# reshape input to be [samples, time steps, features]\n",
        "X_train = np.reshape(trainX, (trainX.shape[0],trainX.shape[1],1))\n",
        "X_test = np.reshape(testT, (testT.shape[0],testT.shape[1],1))\n",
        "\n",
        "\n",
        "cnn = Sequential()\n",
        "cnn.add(Convolution1D(64, 1, activation=\"relu\",input_shape=(15, 1)))\n",
        "#cnn.add(MaxPooling1D(pool_length=(2)))\n",
        "cnn.add(Flatten())\n",
        "cnn.add(Dense(128, activation=\"relu\"))\n",
        "cnn.add(Dropout(0.5))\n",
        "cnn.add(Dense(10, activation=\"softmax\"))\n",
        "\n",
        "# define optimizer and objective, compile cnn\n",
        "\n",
        "cnn.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\",metrics=['accuracy'])\n",
        "\n",
        "# train\n",
        "checkpointer = callbacks.ModelCheckpoint(filepath=\"results/checkpoint-{epoch:02d}.hdf5\", verbose=1, save_best_only=True, monitor='val_acc',mode='max')\n",
        "csv_logger = CSVLogger('results/cnn1results/cnntrainanalysis1.csv',separator=',', append=False)\n",
        "historyCNN10=cnn.fit(X_train, y_train, batch_size=40 ,epochs=100)\n",
        "#cnn.save(\"results/cnn1results/cnn_model.hdf5\")\n",
        "#,validation_data=(X_test, y_test),callbacks=[checkpointer,csv_logger]\n",
        "\n",
        "loss, accCNN10 = cnn.evaluate(X_train, y_train, verbose=True)\n",
        "print(\"Training Accuracy: {:.4f}\".format(accCNN10))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "2694/2694 [==============================] - 36s 2ms/step - loss: 1.3572 - accuracy: 0.5020\n",
            "Epoch 2/100\n",
            "2694/2694 [==============================] - 7s 2ms/step - loss: 1.1507 - accuracy: 0.5470\n",
            "Epoch 3/100\n",
            "2694/2694 [==============================] - 7s 2ms/step - loss: 1.0755 - accuracy: 0.5842\n",
            "Epoch 4/100\n",
            "2694/2694 [==============================] - 7s 2ms/step - loss: 1.0348 - accuracy: 0.6039\n",
            "Epoch 5/100\n",
            "2694/2694 [==============================] - 7s 2ms/step - loss: 1.0041 - accuracy: 0.6220\n",
            "Epoch 6/100\n",
            "2694/2694 [==============================] - 7s 2ms/step - loss: 0.9893 - accuracy: 0.6308\n",
            "Epoch 7/100\n",
            "2694/2694 [==============================] - 7s 2ms/step - loss: 0.9778 - accuracy: 0.6354\n",
            "Epoch 8/100\n",
            "2694/2694 [==============================] - 7s 2ms/step - loss: 0.9659 - accuracy: 0.6443\n",
            "Epoch 9/100\n",
            "2694/2694 [==============================] - 7s 2ms/step - loss: 0.9575 - accuracy: 0.6448\n",
            "Epoch 10/100\n",
            "2694/2694 [==============================] - 7s 2ms/step - loss: 0.9606 - accuracy: 0.6424\n",
            "Epoch 11/100\n",
            "2694/2694 [==============================] - 7s 3ms/step - loss: 0.9439 - accuracy: 0.6490\n",
            "Epoch 12/100\n",
            "2694/2694 [==============================] - 7s 2ms/step - loss: 0.9451 - accuracy: 0.6507\n",
            "Epoch 13/100\n",
            "2694/2694 [==============================] - 7s 2ms/step - loss: 0.9430 - accuracy: 0.6508\n",
            "Epoch 14/100\n",
            "2694/2694 [==============================] - 7s 2ms/step - loss: 0.9321 - accuracy: 0.6548\n",
            "Epoch 15/100\n",
            "2694/2694 [==============================] - 7s 2ms/step - loss: 0.9256 - accuracy: 0.6568\n",
            "Epoch 16/100\n",
            "2694/2694 [==============================] - 7s 2ms/step - loss: 0.9286 - accuracy: 0.6550\n",
            "Epoch 17/100\n",
            "2694/2694 [==============================] - 7s 2ms/step - loss: 0.9308 - accuracy: 0.6560\n",
            "Epoch 18/100\n",
            "2694/2694 [==============================] - 7s 2ms/step - loss: 0.9258 - accuracy: 0.6597\n",
            "Epoch 19/100\n",
            "2694/2694 [==============================] - 7s 2ms/step - loss: 0.9200 - accuracy: 0.6615\n",
            "Epoch 20/100\n",
            "2694/2694 [==============================] - 7s 2ms/step - loss: 0.9185 - accuracy: 0.6615\n",
            "Epoch 21/100\n",
            "2694/2694 [==============================] - 7s 2ms/step - loss: 0.9193 - accuracy: 0.6607\n",
            "Epoch 22/100\n",
            "2694/2694 [==============================] - 7s 2ms/step - loss: 0.9081 - accuracy: 0.6666\n",
            "Epoch 23/100\n",
            "2694/2694 [==============================] - 7s 2ms/step - loss: 0.9126 - accuracy: 0.6641\n",
            "Epoch 24/100\n",
            "2694/2694 [==============================] - 7s 2ms/step - loss: 0.9092 - accuracy: 0.6657\n",
            "Epoch 25/100\n",
            "2694/2694 [==============================] - 7s 3ms/step - loss: 0.9025 - accuracy: 0.6705\n",
            "Epoch 26/100\n",
            "2694/2694 [==============================] - 7s 3ms/step - loss: 0.8974 - accuracy: 0.6694\n",
            "Epoch 27/100\n",
            "2694/2694 [==============================] - 7s 3ms/step - loss: 0.8918 - accuracy: 0.6733\n",
            "Epoch 28/100\n",
            "2694/2694 [==============================] - 7s 3ms/step - loss: 0.8943 - accuracy: 0.6703\n",
            "Epoch 29/100\n",
            "2694/2694 [==============================] - 7s 2ms/step - loss: 0.8952 - accuracy: 0.6711\n",
            "Epoch 30/100\n",
            "2694/2694 [==============================] - 7s 2ms/step - loss: 0.8945 - accuracy: 0.6692\n",
            "Epoch 31/100\n",
            "2694/2694 [==============================] - 7s 3ms/step - loss: 0.8844 - accuracy: 0.6761\n",
            "Epoch 32/100\n",
            "2694/2694 [==============================] - 7s 3ms/step - loss: 0.8842 - accuracy: 0.6727\n",
            "Epoch 33/100\n",
            "2694/2694 [==============================] - 7s 2ms/step - loss: 0.8779 - accuracy: 0.6749\n",
            "Epoch 34/100\n",
            "2694/2694 [==============================] - 7s 2ms/step - loss: 0.8800 - accuracy: 0.6751\n",
            "Epoch 35/100\n",
            "2694/2694 [==============================] - 7s 3ms/step - loss: 0.8756 - accuracy: 0.6752\n",
            "Epoch 36/100\n",
            "2694/2694 [==============================] - 7s 3ms/step - loss: 0.8794 - accuracy: 0.6742\n",
            "Epoch 37/100\n",
            "2694/2694 [==============================] - 7s 3ms/step - loss: 0.8723 - accuracy: 0.6761\n",
            "Epoch 38/100\n",
            "2694/2694 [==============================] - 7s 3ms/step - loss: 0.8660 - accuracy: 0.6773\n",
            "Epoch 39/100\n",
            "2694/2694 [==============================] - 7s 3ms/step - loss: 0.8682 - accuracy: 0.6766\n",
            "Epoch 40/100\n",
            "2694/2694 [==============================] - 7s 3ms/step - loss: 0.8585 - accuracy: 0.6807\n",
            "Epoch 41/100\n",
            "2694/2694 [==============================] - 7s 3ms/step - loss: 0.8678 - accuracy: 0.6774\n",
            "Epoch 42/100\n",
            "2694/2694 [==============================] - 7s 3ms/step - loss: 0.8610 - accuracy: 0.6793\n",
            "Epoch 43/100\n",
            "2694/2694 [==============================] - 7s 3ms/step - loss: 0.8587 - accuracy: 0.6798\n",
            "Epoch 44/100\n",
            "2694/2694 [==============================] - 7s 3ms/step - loss: 0.8519 - accuracy: 0.6829\n",
            "Epoch 45/100\n",
            "2694/2694 [==============================] - 7s 3ms/step - loss: 0.8466 - accuracy: 0.6846\n",
            "Epoch 46/100\n",
            "2694/2694 [==============================] - 7s 3ms/step - loss: 0.8544 - accuracy: 0.6799\n",
            "Epoch 47/100\n",
            "2694/2694 [==============================] - 7s 3ms/step - loss: 0.8440 - accuracy: 0.6849\n",
            "Epoch 48/100\n",
            "2694/2694 [==============================] - 7s 3ms/step - loss: 0.8406 - accuracy: 0.6831\n",
            "Epoch 49/100\n",
            "2694/2694 [==============================] - 7s 2ms/step - loss: 0.8474 - accuracy: 0.6839\n",
            "Epoch 50/100\n",
            "2694/2694 [==============================] - 7s 3ms/step - loss: 0.8383 - accuracy: 0.6871\n",
            "Epoch 51/100\n",
            "2694/2694 [==============================] - 7s 3ms/step - loss: 0.8341 - accuracy: 0.6879\n",
            "Epoch 52/100\n",
            "2694/2694 [==============================] - 7s 2ms/step - loss: 0.8411 - accuracy: 0.6842\n",
            "Epoch 53/100\n",
            "2694/2694 [==============================] - 7s 2ms/step - loss: 0.8330 - accuracy: 0.6868\n",
            "Epoch 54/100\n",
            "2694/2694 [==============================] - 7s 2ms/step - loss: 0.8407 - accuracy: 0.6874\n",
            "Epoch 55/100\n",
            "2694/2694 [==============================] - 7s 2ms/step - loss: 0.8358 - accuracy: 0.6879\n",
            "Epoch 56/100\n",
            "2694/2694 [==============================] - 7s 3ms/step - loss: 0.8364 - accuracy: 0.6861\n",
            "Epoch 57/100\n",
            "2694/2694 [==============================] - 7s 3ms/step - loss: 0.8212 - accuracy: 0.6921\n",
            "Epoch 58/100\n",
            "2694/2694 [==============================] - 7s 3ms/step - loss: 0.8234 - accuracy: 0.6936\n",
            "Epoch 59/100\n",
            "2694/2694 [==============================] - 7s 3ms/step - loss: 0.8245 - accuracy: 0.6904\n",
            "Epoch 60/100\n",
            "2694/2694 [==============================] - 7s 2ms/step - loss: 0.8263 - accuracy: 0.6908\n",
            "Epoch 61/100\n",
            "2694/2694 [==============================] - 7s 3ms/step - loss: 0.8256 - accuracy: 0.6903\n",
            "Epoch 62/100\n",
            "2694/2694 [==============================] - 7s 2ms/step - loss: 0.8266 - accuracy: 0.6897\n",
            "Epoch 63/100\n",
            "2694/2694 [==============================] - 7s 2ms/step - loss: 0.8298 - accuracy: 0.6891\n",
            "Epoch 64/100\n",
            "2694/2694 [==============================] - 7s 3ms/step - loss: 0.8188 - accuracy: 0.6917\n",
            "Epoch 65/100\n",
            "2694/2694 [==============================] - 7s 2ms/step - loss: 0.8242 - accuracy: 0.6902\n",
            "Epoch 66/100\n",
            "2694/2694 [==============================] - 7s 2ms/step - loss: 0.8261 - accuracy: 0.6905\n",
            "Epoch 67/100\n",
            "2694/2694 [==============================] - 7s 2ms/step - loss: 0.8269 - accuracy: 0.6902\n",
            "Epoch 68/100\n",
            "2694/2694 [==============================] - 7s 2ms/step - loss: 0.8265 - accuracy: 0.6878\n",
            "Epoch 69/100\n",
            "2694/2694 [==============================] - 7s 3ms/step - loss: 0.8240 - accuracy: 0.6905\n",
            "Epoch 70/100\n",
            "2694/2694 [==============================] - 7s 3ms/step - loss: 0.8216 - accuracy: 0.6919\n",
            "Epoch 71/100\n",
            "2694/2694 [==============================] - 7s 2ms/step - loss: 0.8238 - accuracy: 0.6912\n",
            "Epoch 72/100\n",
            "2694/2694 [==============================] - 7s 2ms/step - loss: 0.8194 - accuracy: 0.6931\n",
            "Epoch 73/100\n",
            "2694/2694 [==============================] - 7s 3ms/step - loss: 0.8144 - accuracy: 0.6955\n",
            "Epoch 74/100\n",
            "2694/2694 [==============================] - 7s 3ms/step - loss: 0.8186 - accuracy: 0.6943\n",
            "Epoch 75/100\n",
            "2694/2694 [==============================] - 7s 3ms/step - loss: 0.8135 - accuracy: 0.6934\n",
            "Epoch 76/100\n",
            "2694/2694 [==============================] - 7s 3ms/step - loss: 0.8065 - accuracy: 0.6966\n",
            "Epoch 77/100\n",
            "2694/2694 [==============================] - 7s 2ms/step - loss: 0.8175 - accuracy: 0.6946\n",
            "Epoch 78/100\n",
            "2694/2694 [==============================] - 7s 2ms/step - loss: 0.8101 - accuracy: 0.6968\n",
            "Epoch 79/100\n",
            "2694/2694 [==============================] - 7s 3ms/step - loss: 0.8140 - accuracy: 0.6948\n",
            "Epoch 80/100\n",
            "2694/2694 [==============================] - 7s 3ms/step - loss: 0.8176 - accuracy: 0.6968\n",
            "Epoch 81/100\n",
            "2694/2694 [==============================] - 7s 3ms/step - loss: 0.8183 - accuracy: 0.6938\n",
            "Epoch 82/100\n",
            "2694/2694 [==============================] - 7s 2ms/step - loss: 0.8045 - accuracy: 0.6958\n",
            "Epoch 83/100\n",
            "2694/2694 [==============================] - 7s 3ms/step - loss: 0.8081 - accuracy: 0.6993\n",
            "Epoch 84/100\n",
            "2694/2694 [==============================] - 7s 3ms/step - loss: 0.8129 - accuracy: 0.6985\n",
            "Epoch 85/100\n",
            "2694/2694 [==============================] - 7s 3ms/step - loss: 0.8112 - accuracy: 0.6963\n",
            "Epoch 86/100\n",
            "2694/2694 [==============================] - 7s 2ms/step - loss: 0.8073 - accuracy: 0.6977\n",
            "Epoch 87/100\n",
            "2694/2694 [==============================] - 7s 3ms/step - loss: 0.8084 - accuracy: 0.6972\n",
            "Epoch 88/100\n",
            "2694/2694 [==============================] - 7s 3ms/step - loss: 0.8104 - accuracy: 0.6995\n",
            "Epoch 89/100\n",
            "2694/2694 [==============================] - 7s 3ms/step - loss: 0.8102 - accuracy: 0.6980\n",
            "Epoch 90/100\n",
            "2694/2694 [==============================] - 7s 3ms/step - loss: 0.8094 - accuracy: 0.6942\n",
            "Epoch 91/100\n",
            "2694/2694 [==============================] - 7s 3ms/step - loss: 0.7986 - accuracy: 0.6991\n",
            "Epoch 92/100\n",
            "2694/2694 [==============================] - 7s 3ms/step - loss: 0.8065 - accuracy: 0.6970\n",
            "Epoch 93/100\n",
            "2694/2694 [==============================] - 7s 3ms/step - loss: 0.8072 - accuracy: 0.6975\n",
            "Epoch 94/100\n",
            "2694/2694 [==============================] - 7s 3ms/step - loss: 0.7999 - accuracy: 0.7010\n",
            "Epoch 95/100\n",
            "2694/2694 [==============================] - 7s 3ms/step - loss: 0.7994 - accuracy: 0.6951\n",
            "Epoch 96/100\n",
            "2694/2694 [==============================] - 7s 3ms/step - loss: 0.7987 - accuracy: 0.6979\n",
            "Epoch 97/100\n",
            "2694/2694 [==============================] - 7s 3ms/step - loss: 0.8021 - accuracy: 0.6978\n",
            "Epoch 98/100\n",
            "2694/2694 [==============================] - 7s 2ms/step - loss: 0.7995 - accuracy: 0.6997\n",
            "Epoch 99/100\n",
            "2694/2694 [==============================] - 7s 2ms/step - loss: 0.8029 - accuracy: 0.6977\n",
            "Epoch 100/100\n",
            "2694/2694 [==============================] - 7s 3ms/step - loss: 0.8022 - accuracy: 0.6967\n",
            "3367/3367 [==============================] - 7s 2ms/step - loss: 0.7232 - accuracy: 0.6985\n",
            "Training Accuracy: 0.6985\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CS0Gt8XauZ5P"
      },
      "source": [
        "#Ada Boost with DT\n",
        "from sklearn.ensemble import AdaBoostClassifier\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6tc7MPIluZ9m",
        "outputId": "b6903e57-8a75-4434-fa00-f43a59a3a561"
      },
      "source": [
        "print (\"\\t\\tAdaBoost using Decision Tree Analysis of UNSW NB15\\n\\n\\t\\tTop 10 Features \")\n",
        "\n",
        "\n",
        "\n",
        "abc10 = AdaBoostClassifier(DecisionTreeClassifier(max_depth=3), algorithm=\"SAMME\", n_estimators=500)\n",
        "abc10.fit(df1_xtrain, df1_ytrain)\n",
        "\n",
        "#Predict the response for test dataset\n",
        "y_pred_Ada10 = abc10.predict(df1_xtest)\n",
        "\n",
        "\n",
        "results_Ada10 = confusion_matrix(df1_ytest, y_pred_Ada10) \n",
        "print ('Confusion Matrix :')\n",
        "print(results_Ada10) \n",
        "\n",
        "accabc10=accuracy_score(df1_ytest, y_pred_Ada10)\n",
        "preabc10=precision_score(df1_ytest, y_pred_Ada10, average='macro')\n",
        "f1abc10=f1_score(df1_ytest, y_pred_Ada10, average='macro')\n",
        "reabc10=recall_score(df1_ytest, y_pred_Ada10, average='macro')\n",
        "\n",
        "print ('Accuracy Score :', accabc10)\n",
        "print(\"Precision Score: \",preabc10)\n",
        "print(\"F1 Score: \",f1abc10)\n",
        "print(\"Recall: \",reabc10)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\t\tAdaBoost using Decision Tree Analysis of UNSW NB15\n",
            "\n",
            "\t\tTop 10 Features \n",
            "Confusion Matrix :\n",
            "[[  281     4    60    51   206     0    62    13     0     0]\n",
            " [  179     6    61    97   214     1     8    13     4     0]\n",
            " [ 1862   134   237   854   525    69   168   200    38     2]\n",
            " [ 1854   155   390  6189   859   253   868   517    44     3]\n",
            " [  539    12   134   370  1076     2  3825    66    36     2]\n",
            " [   12     2    49   804    41 17849    89    15    10     0]\n",
            " [  440    23   170   908  3039    18 32249    20   127     6]\n",
            " [  216    28    22   196    78     7    87  2842    20     0]\n",
            " [    0     0    25    50    44     0    45    15   199     0]\n",
            " [    0     1     0    31     4     3     1     0     2     2]]\n",
            "Accuracy Score : 0.7400524704853519\n",
            "Precision Score:  0.4258598142157197\n",
            "F1 Score:  0.41227831822646416\n",
            "Recall:  0.4419058463727786\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "qWHpLmjVuaML",
        "outputId": "632c9619-56e0-4526-f275-99c3e94f783c"
      },
      "source": [
        "print (\"\\t\\tAdaBoost using DT Analysis of UNSW-NB15\\n\\n\\t\\tTop 20 Features \")\n",
        "\n",
        "abc20 = AdaBoostClassifier(DecisionTreeClassifier(max_depth=3), algorithm=\"SAMME\",n_estimators=500)\n",
        "abc20.fit(df2_xtrain, df2_ytrain)\n",
        "\n",
        "y_pred_Ada20 = abc20.predict(df2_xtest)\n",
        "\n",
        "\n",
        "\n",
        "results_Ada10 = confusion_matrix(df2_ytest, y_pred_Ada20) \n",
        "print ('Confusion Matrix :')\n",
        "print(results_Ada10) \n",
        "\n",
        "accabc20=accuracy_score(df2_ytest, y_pred_Ada20)\n",
        "preabc20=precision_score(df2_ytest, y_pred_Ada20, average='macro')\n",
        "f1abc20=f1_score(df2_ytest, y_pred_Ada20, average='macro')\n",
        "reabc20=recall_score(df2_ytest, y_pred_Ada20, average='macro')\n",
        "\n",
        "print ('Accuracy Score :', accabc20)\n",
        "print(\"Precision Score: \",preabc20)\n",
        "print(\"F1 Score: \",f1abc20)\n",
        "print(\"Recall: \",reabc20)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\t\tAdaBoost using DT Analysis of UNSW-NB15\n",
            "\n",
            "\t\tTop 20 Features \n",
            "Confusion Matrix :\n",
            "[[  424    57     3    18    44     0    55    76     0     0]\n",
            " [  359    45    15    24    51    11     4    71     3     0]\n",
            " [ 1378   689   331   926   328    32   108   252    39     6]\n",
            " [ 1640   687  1031  6096   478   219   363   553    40    25]\n",
            " [  826   133    82   151  1658    11  2933   194    53    21]\n",
            " [   13     6   260   370    56 18059    87     7    12     1]\n",
            " [  658     6   307   638  5201    27 30030    14   101    18]\n",
            " [  133   110    59   241    86     7    34  2820     5     1]\n",
            " [    0     2    36    54    45     0    36    12   193     0]\n",
            " [    0     0     5    31     2     2     2     0     0     2]]\n",
            "Accuracy Score : 0.7246028275761551\n",
            "Precision Score:  0.42216095049288327\n",
            "F1 Score:  0.42151037141227066\n",
            "Recall:  0.4736811250635452\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0EdgdNfGuaUk"
      },
      "source": [
        "print (\"\\t\\tAdaBoost using DT Analysis of UNSW-NB15\\n\\n\\t\\tAll Features \")\n",
        "\n",
        "abcall = AdaBoostClassifier(DecisionTreeClassifier(max_depth=3),\n",
        "                         algorithm=\"SAMME\",\n",
        "                         n_estimators=500)\n",
        "\n",
        "abcall.fit(df3_xtrain,df3_ytrain)\n",
        "\n",
        "y_pred_Adaall = abcall.predict(df3_xtest)\n",
        "\n",
        "results_Adaall = confusion_matrix(df3_ytest, y_pred_Adaall) \n",
        "print ('Confusion Matrix :')\n",
        "print(results_Adaall)\n",
        "\n",
        "accabcall=accuracy_score(df3_ytest, y_pred_Adaall)\n",
        "preabcall=precision_score(df3_ytest, y_pred_Adaall, average='macro')\n",
        "f1abcall=f1_score(df3_ytest, y_pred_Adaall, average='macro')\n",
        "reabcall=recall_score(df3_ytest, y_pred_Adaall, average='macro')\n",
        "\n",
        "print ('Accuracy Score :', accabcall)\n",
        "print(\"Precision Score: \",preabcall)\n",
        "print(\"F1 Score: \",f1abcall)\n",
        "print(\"Recall: \",reabcall)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fbwdx6KnI4wX"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i_Sou9aPI9np"
      },
      "source": [
        "!pip install vecstack\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from vecstack import stacking"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fqd-w6geI40E"
      },
      "source": [
        "models = [\n",
        "    KNeighborsClassifier(),\n",
        "        \n",
        "    RandomForestClassifier(n_estimators=500, max_depth=3),\n",
        "        \n",
        "    XGBClassifier(random_state=0, n_jobs=-1, learning_rate=0.1, \n",
        "                  n_estimators=100, max_depth=3)\n",
        "]"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yjUmiwr-I43Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e47d7aa2-713f-49a9-8b56-ee7e2b93751d"
      },
      "source": [
        "S_train, S_test = stacking(models, df1_xtrain, df1_ytrain, df1_xtest, regression=False, mode='oof_pred_bag', needs_proba=False, save_dir=None,  metric=accuracy_score, \n",
        "                               n_folds=5, stratified=True, shuffle=True,  random_state=0, verbose=2)"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "task:         [classification]\n",
            "n_classes:    [10]\n",
            "metric:       [accuracy_score]\n",
            "mode:         [oof_pred_bag]\n",
            "n_models:     [3]\n",
            "\n",
            "model  0:     [KNeighborsClassifier]\n",
            "    fold  0:  [0.73357156]\n",
            "    fold  1:  [0.74108966]\n",
            "    fold  2:  [0.73417487]\n",
            "    fold  3:  [0.73937256]\n",
            "    fold  4:  [0.74043995]\n",
            "    ----\n",
            "    MEAN:     [0.73772972] + [0.00320190]\n",
            "    FULL:     [0.73772972]\n",
            "\n",
            "model  1:     [RandomForestClassifier]\n",
            "    fold  0:  [0.72345461]\n",
            "    fold  1:  [0.73292185]\n",
            "    fold  2:  [0.72758493]\n",
            "    fold  3:  [0.73217932]\n",
            "    fold  4:  [0.72730648]\n",
            "    ----\n",
            "    MEAN:     [0.72868944] + [0.00348220]\n",
            "    FULL:     [0.72868944]\n",
            "\n",
            "model  2:     [XGBClassifier]\n",
            "    fold  0:  [0.78893633]\n",
            "    fold  1:  [0.79547986]\n",
            "    fold  2:  [0.79650084]\n",
            "    fold  3:  [0.79961017]\n",
            "    fold  4:  [0.79520141]\n",
            "    ----\n",
            "    MEAN:     [0.79514572] + [0.00347675]\n",
            "    FULL:     [0.79514572]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NQFZA7MAI473",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1488f241-5766-413c-c2b6-5cc87de8d390"
      },
      "source": [
        "XGB10 = XGBClassifier(random_state=1, n_jobs=-1, learning_rate=0.1, \n",
        "                      n_estimators=300, max_depth=3)\n",
        "    \n",
        "XGB10 = XGB10.fit(S_train, df1_ytrain)\n",
        "\n",
        "y_pred_XGB1 = XGB10.predict(S_test)\n",
        "\n",
        "print('Final prediction score: [%.5f]' % accuracy_score(df1_ytest, y_pred_XGB1))\n",
        "\n",
        "results_XGB1 = confusion_matrix(df1_ytest, y_pred_XGB1) \n",
        "print ('Confusion Matrix :')\n",
        "print(results_XGB1) \n",
        "\n",
        "accXGB10=accuracy_score(df1_ytest, y_pred_XGB1)\n",
        "preXGB10=precision_score(df1_ytest, y_pred_XGB1, average='macro')\n",
        "f1XGB10=f1_score(df1_ytest, y_pred_XGB1, average='macro')\n",
        "reXGB10=recall_score(df1_ytest, y_pred_XGB1, average='macro')\n",
        "\n",
        "print ('Accuracy Score :', accXGB10)\n",
        "print(\"Precision Score: \",preXGB10)\n",
        "print(\"F1 Score: \",f1XGB10)\n",
        "print(\"Recall: \",reXGB10)"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Final prediction score: [0.73445]\n",
            "Confusion Matrix :\n",
            "[[    1     0     0     8   613     0    52     3     0     0]\n",
            " [    1    21     1    32   513     0     7     4     4     0]\n",
            " [    9    47    68  1023  2782     2    44    45    69     0]\n",
            " [    7    29    32  7275  3222     0   305   183    78     1]\n",
            " [    1     7     1   136  4807     0   961    54    95     0]\n",
            " [    0     4    12   495   163 18159    19     8    10     1]\n",
            " [    1     0    17  1075  8720     0 27080    33    73     1]\n",
            " [    2     6     2   291   345     0     7  2828    15     0]\n",
            " [    0     1     2    55    64     0    11    30   215     0]\n",
            " [    0     0     1    22     5     0     1     0     0    15]]\n",
            "Accuracy Score : 0.7344531895253364\n",
            "Precision Score:  0.570868266035018\n",
            "F1 Score:  0.47195333459465355\n",
            "Recall:  0.49134003537254217\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8i1KC2CdTWm8"
      },
      "source": [
        "S_train2, S_test2 = stacking(models, df2_xtrain, df2_ytrain, df2_xtest, regression=False, mode='oof_pred_bag', needs_proba=False, save_dir=None,  metric=accuracy_score, \n",
        "                               n_folds=5, stratified=True, shuffle=True,  random_state=0, verbose=2)\n",
        "\n",
        "XGB20 = XGBClassifier(random_state=0, n_jobs=-1, learning_rate=0.1, n_estimators=300, max_depth=3)\n",
        "    \n",
        "XGB20 = XGB20.fit(S_train2, df2_ytrain)\n",
        "\n",
        "y_pred_XGB2 = XGB20.predict(S_test2)\n",
        "\n",
        "print('Final prediction score: [%.5f]' % accuracy_score(df2_ytest, y_pred_XGB2))\n",
        "\n",
        "\n",
        "results_XGB2 = confusion_matrix(df2_ytest, y_pred_XGB2) \n",
        "print ('Confusion Matrix :')\n",
        "print(results_XGB2) \n",
        "\n",
        "accXGB20=accuracy_score(df2_ytest, y_pred_XGB2)\n",
        "preXGB20=precision_score(df2_ytest, y_pred_XGB2, average='macro')\n",
        "f1XGB20=f1_score(df2_ytest, y_pred_XGB2, average='macro')\n",
        "reXGB20=recall_score(df2_ytest, y_pred_XGB2, average='macro')\n",
        "\n",
        "print ('Accuracy Score :',accXGB20 )\n",
        "print(\"Precision Score: \",preXGB20)\n",
        "print(\"F1 Score: \",f1XGB20)\n",
        "print(\"Recall: \",reXGB20)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "dSyC9ob1TWqP",
        "outputId": "4ac19701-c031-4b10-f84b-850f93b5d61a"
      },
      "source": [
        "\n",
        "S_train3, S_test3 = stacking(models, df3_xtrain, df3_ytrain, df3_xtest, regression=False, mode='oof_pred_bag', needs_proba=False, save_dir=None,  metric=accuracy_score, \n",
        "                               n_folds=5, stratified=True, shuffle=True,  random_state=0, verbose=2)\n",
        "\n",
        "\n",
        "XGBall = XGBClassifier(random_state=0, n_jobs=-1, learning_rate=0.1, n_estimators=300, max_depth=3)\n",
        "    \n",
        "XGBall = XGBall.fit(S_train3, df3_ytrain)\n",
        "\n",
        "y_pred_XGB3 = XGBall.predict(S_test)\n",
        "\n",
        "print('Final prediction score: [%.5f]' % accuracy_score(df3_ytest, y_pred_XGB3))\n",
        "\n",
        "results_XGB3 = confusion_matrix(df3_ytest, y_pred_XGB3) \n",
        "print ('Confusion Matrix :')\n",
        "print(results_XGB3) \n",
        "\n",
        "accXGBall=accuracy_score(df3_ytest, y_pred_XGB3)\n",
        "preXGBall=precision_score(df3_ytest, y_pred_XGB3, average='macro')\n",
        "f1XGBall=f1_score(df3_ytest, y_pred_XGB3, average='macro')\n",
        "reXGBall=recall_score(df3_ytest, y_pred_XGB3, average='macro')\n",
        "\n",
        "print ('Accuracy Score :', accXGBall)\n",
        "print(\"Precision Score: \",preXGBall)\n",
        "print(\"F1 Score: \",f1XGBall)\n",
        "print(\"Recall: \",reXGBall)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "task:         [classification]\n",
            "n_classes:    [10]\n",
            "metric:       [accuracy_score]\n",
            "mode:         [oof_pred_bag]\n",
            "n_models:     [3]\n",
            "\n",
            "model  0:     [KNeighborsClassifier]\n",
            "    fold  0:  [0.56682755]\n",
            "    fold  1:  [0.56585298]\n",
            "    fold  2:  [0.56835901]\n",
            "    fold  3:  [0.56283646]\n",
            "    fold  4:  [0.57040097]\n",
            "    ----\n",
            "    MEAN:     [0.56685539] + [0.00252940]\n",
            "    FULL:     [0.56685539]\n",
            "\n",
            "model  1:     [RandomForestClassifier]\n",
            "    fold  0:  [0.69811583]\n",
            "    fold  1:  [0.70405606]\n",
            "    fold  2:  [0.70470577]\n",
            "    fold  3:  [0.70591238]\n",
            "    fold  4:  [0.70572675]\n",
            "    ----\n",
            "    MEAN:     [0.70370336] + [0.00287484]\n",
            "    FULL:     [0.70370336]\n",
            "\n",
            "model  2:     [XGBClassifier]\n",
            "    fold  0:  [0.79227771]\n",
            "    fold  1:  [0.79956376]\n",
            "    fold  2:  [0.79942454]\n",
            "    fold  3:  [0.80517913]\n",
            "    fold  4:  [0.79933172]\n",
            "    ----\n",
            "    MEAN:     [0.79915537] + [0.00409532]\n",
            "    FULL:     [0.79915537]\n",
            "\n",
            "Final prediction score: [0.71095]\n",
            "Confusion Matrix :\n",
            "[[  138     0     0     8   479     0    49     3     0     0]\n",
            " [   91    20     1    31   424     0     8     4     4     0]\n",
            " [  701    67    72  1016  2058     2    78    33    62     0]\n",
            " [  711    39    60  7252  2484     0   336   181    67     2]\n",
            " [  267     8     4   138  4519     0   981    51    94     0]\n",
            " [    9     5     8   496   150 18159    25     8    10     1]\n",
            " [  412    10    33  1057  8596     0 26808    28    55     1]\n",
            " [   83    10     5   288   255     0  1456  1384    15     0]\n",
            " [    2     3    43    40    56     0    43    24   167     0]\n",
            " [    0     1     0    22     5     0     1     0     0    15]]\n",
            "Accuracy Score : 0.7109507846280911\n",
            "Precision Score:  0.5285040219502108\n",
            "F1 Score:  0.4394593195526658\n",
            "Recall:  0.45180725447333814\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hwgf1CnikmZa"
      },
      "source": [
        "from sklearn.datasets import make_classification\n",
        "from sklearn.ensemble import StackingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier,AdaBoostClassifier,GradientBoostingClassifier"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vPtKiX1VTWtA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "38d91952-a8e9-4e5c-a40d-83f02fd6188f"
      },
      "source": [
        "level0 = list()\n",
        "level0.append(('rf', RandomForestClassifier()))\n",
        "#level0.append(('knn', KNeighborsClassifier()))\n",
        "level0.append(('cart', DecisionTreeClassifier()))\n",
        "# define meta learner model\n",
        "print(\"Proceeding with: \",level0)\n",
        "level1 = GradientBoostingClassifier(n_estimators=200)\n",
        "# define the stacking ensemble\n",
        "model = StackingClassifier(estimators=level0, final_estimator=level1, cv=2)\n",
        "# fit the model on all available data\n",
        "model.fit(df1_xtrain, df1_ytrain)\n",
        "# make a prediction for one example\n",
        "\n",
        "yhat = model.predict(df1_xtest)\n",
        "#print('Predicted Class: %d' % (yhat))\n",
        "\n",
        "print('Final prediction score: [%.5f]' % accuracy_score(df1_ytest, yhat))\n",
        "\n",
        "results_sc1 = confusion_matrix(df1_ytest, yhat) \n",
        "print ('Confusion Matrix :')\n",
        "print(results_sc1) \n",
        "\n",
        "accensemble10=accuracy_score(df1_ytest, yhat)\n",
        "preensemble10=precision_score(df1_ytest, yhat, average='macro')\n",
        "f1ensemble10=f1_score(df1_ytest, yhat, average='macro')\n",
        "reensemble10=recall_score(df1_ytest, yhat, average='macro')\n",
        "\n",
        "print ('Accuracy Score :',accensemble10 )\n",
        "print(\"Precision Score: \",preensemble10)\n",
        "print(\"F1 Score: \",f1ensemble10)\n",
        "print(\"Recall: \",reensemble10)\n"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Proceeding with:  [('rf', RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False)), ('cart', DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
            "                       max_depth=None, max_features=None, max_leaf_nodes=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
            "                       random_state=None, splitter='best'))]\n",
            "Final prediction score: [0.68303]\n",
            "Confusion Matrix :\n",
            "[[  101   115   114   163   164     2     7     9     2     0]\n",
            " [   31   157   115   115   136     3     8     8    10     0]\n",
            " [  911   215   856  1033   767    14    62   164    64     3]\n",
            " [  836   330   596  7838   948    29    77   352   110    16]\n",
            " [  133   239   287   677  3956     7   433    32   296     2]\n",
            " [    6    19    54   375    69 18274    22     3    42     7]\n",
            " [ 1579     2    49   874 12386     4 21918    15   169     4]\n",
            " [  112    16    54   320   117     2    13  2818    43     1]\n",
            " [    1     2    14    41    32     0     3     1   283     1]\n",
            " [    0     0     0     7     2     1     0     0     0    34]]\n",
            "Accuracy Score : 0.6830272555021134\n",
            "Precision Score:  0.5043654867154245\n",
            "F1 Score:  0.5071414559194743\n",
            "Recall:  0.5872723803687703\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qQULcI5MJs8o",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "2332fcaa-7ec5-431c-cb34-bb2ffb660270"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "#Accuracy\n",
        "print(\"Accuracy\")\n",
        "fig = plt.figure()\n",
        "ax = fig.add_axes([0,0,2,1])\n",
        "algo = ['accKNN10', 'accDT10', 'accbayes_10', 'accclfRF_10',\"accabc10\",\"accXGB10\",\"accensemble10\",\"accNN10\",\"accCNN10\"]\n",
        "acc = [accKNN10*100,accDT10*100,accbayes_10*100,accclfRF_10*100,accabc10*100,accXGB10*100,accensemble10*100,accNN10*100,accCNN10*100]\n",
        "ax.bar(algo,acc)\n",
        "plt.show()\n",
        "#Precision\n",
        "print(\"Precision\")\n",
        "fig = plt.figure()\n",
        "ax = fig.add_axes([0,0,1,1])\n",
        "algo = ['preKNN10', 'preDT10', 'prebayes_10', 'preclfRF_10',\"preabc10\",\"preXGB10\",\"preensemble10\",]\n",
        "pre = [preKNN10*100,preDT10*100,prebayes_10*100,preclfRF_10*100,preabc10*100,preXGB10*100,preensemble10*100]\n",
        "ax.bar(algo,pre)\n",
        "plt.show()\n",
        "#F1 Score\n",
        "print(\"F1 Score\")\n",
        "fig = plt.figure()\n",
        "ax = fig.add_axes([0,0,2,1])\n",
        "algo = ['f1KNN10', 'f1DT10', 'f1bayes_10', 'f1clfRF_10',\"f1abc10\",\"f1XGB10\",\"f1ensemble10\"]\n",
        "f1 = [f1KNN10*100,f1DT10*100,f1bayes_10*100,f1clfRF_10*100,f1abc10*100,f1XGB10*100,f1ensemble10*100]\n",
        "ax.bar(algo,f1)\n",
        "plt.show()\n",
        "#Recall\n",
        "print(\"Recall\")\n",
        "fig = plt.figure()\n",
        "ax = fig.add_axes([0,0,2,1])\n",
        "algo = ['reKNN10', 'reDT10', 'rebayes_10', 'reclfRF_10',\"reabc10\",\"reXGB10\",\"reensemble10\"]\n",
        "re = [reKNN10*100,reDT10*100,rebayes_10*100,reclfRF_10*100,reabc10*100,reXGB10*100,reensemble10*100]\n",
        "ax.bar(algo,re)\n",
        "plt.show()"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Precision\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "F1 Score\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Recall\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "joLjhR5TJtJ_"
      },
      "source": [
        "[accKNN10,preKNN10,f1KNN10,reKNN10][accDT10,preDT10,f1DT10,reDT10]\n",
        "[accbayes_10,prebayes_10,f1bayes_10,rebayes_10][accclfRF_10,preclfRF_10,f1clfRF_10,reclfRF_10]\n",
        "[acclogisticRegr_10,prelogisticRegr_10,f1logisticRegr_10,relogisticRegr_10]\n",
        "[accabc10,preabc10,f1abc10,reabc10][accXGB10,preXGB10,f1XGB10,reXGB10]\n",
        "[accensemble10,preensemble10,f1ensemble10,reensemble10]\n",
        "[accNN10,historyNN10][accCNN10,historyCNN10]\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kNVCktgNkivi"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}