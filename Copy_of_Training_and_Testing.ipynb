{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "name": "Copy of Training_and_Testing.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ishaak15/UNSW-IDS-Feature-Selection/blob/main/Copy_of_Training_and_Testing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RupDMUtc2mgK"
      },
      "source": [
        "import numpy as np \n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import math\n",
        "import pandas as pd\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.model_selection import cross_validate\n",
        "from sklearn import datasets, preprocessing, feature_extraction, neighbors\n",
        "from sklearn import linear_model, svm, metrics, ensemble, tree, ensemble\n",
        "from sklearn.model_selection import train_test_split\n",
        "from copy import copy\n",
        "import urllib\n",
        "import csv\n",
        "\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import matplotlib.pyplot as plt\n",
        "import plotly.graph_objs as go\n",
        "\n",
        "from sklearn.tree import DecisionTreeClassifier # Import Decision Tree Classifier\n",
        "from sklearn.model_selection import train_test_split # Import train_test_split function\n",
        "from sklearn import metrics #Import scikit-learn metrics module for accuracy calculation\n",
        "\n",
        "from sklearn.metrics import confusion_matrix \n",
        "from sklearn.metrics import accuracy_score \n",
        "from sklearn.metrics import classification_report \n",
        "\n",
        "\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from yellowbrick.classifier import ClassificationReport\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split \n",
        "from sklearn.naive_bayes import GaussianNB \n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC # \"Support Vector Classifier\" \n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "\n",
        "from sklearn.feature_selection import SelectKBest\n",
        "from sklearn.feature_selection import chi2\n",
        "\n",
        "from zipfile import ZipFile\n",
        "import collections\n",
        "\n",
        "from sklearn.feature_selection import RFE\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "from sklearn.metrics import confusion_matrix \n",
        "from sklearn.metrics import accuracy_score \n",
        "from sklearn.metrics import classification_report \n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import f1_score\n"
      ],
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FUKlYohz7Ge3",
        "outputId": "46d2db45-161e-43c2-f38d-b08b7b934f19"
      },
      "source": [
        "!git clone https://github.com/ishaak15/UNSW-IDS-Feature-Selection.git"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'UNSW-IDS-Feature-Selection'...\n",
            "remote: Enumerating objects: 61, done.\u001b[K\n",
            "remote: Counting objects: 100% (24/24), done.\u001b[K\n",
            "remote: Compressing objects: 100% (24/24), done.\u001b[K\n",
            "remote: Total 61 (delta 7), reused 0 (delta 0), pack-reused 37\u001b[K\n",
            "Unpacking objects: 100% (61/61), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zVKdVCIQIVl8",
        "outputId": "c063cd3d-2cda-4c29-b30f-89e9db688ceb"
      },
      "source": [
        "cd UNSW-IDS-Feature-Selection/"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/UNSW-IDS-Feature-Selection/UNSW-IDS-Feature-Selection/UNSW-IDS-Feature-Selection\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6CrTS2MAIetl",
        "outputId": "042d67e1-9904-46ad-876f-91bbd2705eb1"
      },
      "source": [
        "ls"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "bayes_10.sav   clfKNN20.sav                        README.md\n",
            "bayes_20.sav   clfKNN_all.sav                      Testset1.csv\n",
            "bayes_all.sav  Copy_of_Training_and_Testing.ipynb  Testset2.csv\n",
            "clfDT_10.sav   Dataset1.csv                        Testset3.csv\n",
            "clfDT_20.sav   Dataset2.csv                        Training_and_Testing.ipynb\n",
            "clfDT_all.sav  Dataset3.csv                        UNSW_IDS_analysis.ipynb\n",
            "clfKNN10.sav   LICENSE                             UNSW_NB15_testing-set.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PR7ddO_b-TYh"
      },
      "source": [
        "df1 = pd.read_csv('Dataset1.csv',index_col=0)\n",
        "df2 = pd.read_csv('Dataset2.csv',index_col=0)\n",
        "df3 = pd.read_csv('Dataset3.csv',index_col=0)"
      ],
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sK7zk_s0-2Go"
      },
      "source": [
        "tf1 = pd.read_csv('Testset1.csv',index_col=0)\n",
        "tf2 = pd.read_csv('Testset2.csv',index_col=0)\n",
        "tf3 = pd.read_csv('Testset3.csv',index_col=0)"
      ],
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DVJCwCx5DkD6"
      },
      "source": [
        "df1_xtrain=df1.iloc[: , :-1]\n",
        "df1_ytrain=df1.iloc[:,-1]\n",
        "df2_xtrain=df2.iloc[: , :-1]\n",
        "df2_ytrain=df2.iloc[:,-1]\n",
        "df3_xtrain=df3.iloc[: , :-1]\n",
        "df3_ytrain=df3.iloc[:,-1]"
      ],
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N2Q5ICJvIsgs"
      },
      "source": [
        "df1_xtest=tf1.iloc[: , :-1]\n",
        "df1_ytest=tf1.iloc[:,-1]\n",
        "df2_xtest=tf2.iloc[: , :-1]\n",
        "df2_ytest=tf2.iloc[:,-1]\n",
        "df3_xtest=tf3.iloc[: , :-1]\n",
        "df3_ytest=tf3.iloc[:,-1]"
      ],
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w-ZMD59m4V2o"
      },
      "source": [
        "#KNN"
      ],
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9eg-WFEcsYCS",
        "outputId": "9e59a330-4b8e-400d-e43c-b04187b0b3a9"
      },
      "source": [
        "clfKNN10=neighbors.KNeighborsClassifier()\n",
        "clfKNN10.fit(df1_xtrain,df1_ytrain)\n",
        "#clfKNN10.fit(df1_xtrain,df1_ytrain)\n",
        "\n",
        "print (\"\\t\\tKNN Classification of UNSW-NB15\\n\\n\\t\\tTop 10 Features \")\n",
        "\n",
        "yt_pred_10 = clfKNN10.predict(df1_xtest)\n",
        "results = confusion_matrix(df1_ytest, yt_pred_10) \n",
        "print ('Confusion Matrix :')\n",
        "print(results) \n",
        "\n",
        "\n",
        "accKNN10=accuracy_score(df1_ytest,yt_pred_10)\n",
        "print(\"Accuracy: \",accKNN10)\n",
        "preKNN10=precision_score(df1_ytest, yt_pred_10, average='macro')\n",
        "print(\"Precision Score: \",preKNN10)\n",
        "f1KNN10=f1_score(df1_ytest, yt_pred_10, average='macro')\n",
        "print(\"F1 Score: \",f1KNN10)\n",
        "reKNN10=recall_score(df1_ytest, yt_pred_10, average='macro')  \n",
        "print(\"Recall: \",reKNN10)"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\t\tKNN Classification of UNSW-NB15\n",
            "\n",
            "\t\tTop 10 Features \n",
            "Confusion Matrix :\n",
            "[[  208   131    42    58   129    16    32    61     0     0]\n",
            " [  198   121    13    49   134    18    16    33     1     0]\n",
            " [  822   758   472   913   502    21   202   372    27     0]\n",
            " [  955   835   503  6664   944    39   616   540    33     3]\n",
            " [  444   315    97   469  3357    54  1111   164    50     1]\n",
            " [   17    11    34   375   168 18078   140    44     4     0]\n",
            " [  496    52   218  1986  7076    20 26822   233    93     4]\n",
            " [   82   102    51   324   117     5    71  2737     5     2]\n",
            " [    5     7    12    50   161     6    51    32    54     0]\n",
            " [    0     1     2    26    11     0     3     0     0     1]]\n",
            "Accuracy:  0.7107078657144246\n",
            "Precision Score:  0.41756373950870634\n",
            "F1 Score:  0.4023931552335053\n",
            "Recall:  0.44140047486900985\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gxUUKcyegAMb"
      },
      "source": [
        ""
      ],
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kBj8htUIsYM0",
        "outputId": "a5bbdb2b-0480-44eb-d72b-b3657b124a5a"
      },
      "source": [
        "clfKNN20=neighbors.KNeighborsClassifier()\n",
        "clfKNN20.fit(df2_xtrain,df2_ytrain)\n",
        "\n",
        "print (\"\\t\\tKNN Analysis of UNSW-NB15\\n\\n\\t\\tTop 20 Features \")\n",
        "\n",
        "y_pred_20 = clfKNN20.predict(df2_xtest)\n",
        "results = confusion_matrix(df2_ytest, y_pred_20) \n",
        "print ('Confusion Matrix :')\n",
        "print(results) \n",
        "\n",
        "\n",
        "accKNN20=accuracy_score(df2_ytest,y_pred_20)\n",
        "print(\"Accuracy: \",accKNN20)\n",
        "preKNN20=precision_score(df2_ytest, y_pred_20, average='macro')\n",
        "print(\"Precision Score: \",preKNN20)\n",
        "f1KNN20=f1_score(df2_ytest, y_pred_20, average='macro')\n",
        "print(\"F1 Score: \",f1KNN20)\n",
        "reKNN20=recall_score(df2_ytest, y_pred_20, average='macro')  \n",
        "print(\"Recall: \",reKNN20)"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\t\tKNN Analysis of UNSW-NB15\n",
            "\n",
            "\t\tTop 20 Features \n",
            "Confusion Matrix :\n",
            "[[  267   167    15    69   117    16    17     9     0     0]\n",
            " [  251   109     6    65   118    18    11     5     0     0]\n",
            " [ 1150  1136   184   646   494    22   307   129    21     0]\n",
            " [ 1321  1139   396  4316  1854    39  1749   290    28     0]\n",
            " [  599   332   140  2053  1702    56  1023   122    35     0]\n",
            " [   30    22    26   304   220 18083   132    51     3     0]\n",
            " [  132    71   537  7955  4981    21 22760   473    69     1]\n",
            " [  126   152    91   985   400     7   405  1325     5     0]\n",
            " [    7     6    13   109   126     5    52    17    43     0]\n",
            " [    0     0     1    22     8     0    13     0     0     0]]\n",
            "Accuracy:  0.5925885439440315\n",
            "Precision Score:  0.3273066113090913\n",
            "F1 Score:  0.3053129978339978\n",
            "Recall:  0.336096541715301\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "amTNhuAbsYSP",
        "outputId": "46d2e03b-a158-4bc0-fc45-67c46d61f1c8"
      },
      "source": [
        "clfKNN20=neighbors.KNeighborsClassifier()\n",
        "clfKNN20.fit(df3_xtrain,df3_ytrain)\n",
        "\n",
        "print (\"\\t\\tKNN Analysis of UNSW-NB15\\n\\n\\t\\tAll Features \")\n",
        "\n",
        "y_pred_all = clfKNN20.predict(df3_xtest)\n",
        "results = confusion_matrix(df3_ytest, y_pred_all) \n",
        "print ('Confusion Matrix :')\n",
        "print(results) \n",
        "\n",
        "\n",
        "accKNNall=accuracy_score(df3_ytest, y_pred_all)\n",
        "print(\"Accuracy: \",accKNNall)\n",
        "preKNNall=precision_score(df3_ytest, y_pred_all, average='macro')\n",
        "print(\"Precision Score: \",preKNNall)\n",
        "f1KNNall=f1_score(df3_ytest, y_pred_all, average='macro')\n",
        "print(\"F1 Score: \",f1KNNall)\n",
        "reKNNall=recall_score(df3_ytest, y_pred_all, average='macro')  \n",
        "print(\"Recall: \",reKNNall)\n"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\t\tKNN Analysis of UNSW-NB15\n",
            "\n",
            "\t\tAll Features \n",
            "Confusion Matrix :\n",
            "[[  336   161     1    44   101    16    17     1     0     0]\n",
            " [  304    98     1    44   105    18    11     2     0     0]\n",
            " [ 1491  1070   101   581   437    22   305    61    21     0]\n",
            " [ 1671  1073   319  4245  1794    39  1743   220    28     0]\n",
            " [  726   307   123  2007  1672    56  1024   112    35     0]\n",
            " [   37    21    26   301   219 18083   130    51     3     0]\n",
            " [  115    55   537  7955  5009    21 22765   473    69     1]\n",
            " [  164   146    81   981   392     7   405  1315     5     0]\n",
            " [    6     3    13   109   132     5    50    16    44     0]\n",
            " [    0     0     1    22     8     0    13     0     0     0]]\n",
            "Accuracy:  0.5910095710051985\n",
            "Precision Score:  0.3265665197965294\n",
            "F1 Score:  0.3034833731074776\n",
            "Recall:  0.34123127222810123\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RKy3aGMusYXi"
      },
      "source": [
        "#Decision TREE"
      ],
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8A2BPc0ksky-",
        "outputId": "96b70248-a5b2-498a-e6b0-d47185a1f42d"
      },
      "source": [
        "clfDT_10 = DecisionTreeClassifier()\n",
        "print (\"\\t\\tDecision Tree Analysis of UNSW-NB15\\n\\n\\t\\tTop 10 Features \")\n",
        "\n",
        "# Train Decision Tree Classifer\n",
        "clfDT_10 = clfDT_10.fit(df1_xtrain,df1_ytrain)\n",
        "\n",
        "#Predict the response for test dataset\n",
        "y_pred_DT10 = clfDT_10.predict(df1_xtest)\n",
        "\n",
        "\n",
        "#print (\"\\t\\tMajor Verifcation\")\n",
        "results_DT10 = confusion_matrix(df1_ytest, y_pred_DT10) \n",
        "print ('Confusion Matrix :')\n",
        "print(results_DT10) \n",
        "\n",
        "accDT10=accuracy_score(df1_ytest, y_pred_DT10)\n",
        "preDT10=precision_score(df1_ytest, y_pred_DT10, average='macro')\n",
        "f1DT10=f1_score(df1_ytest, y_pred_DT10, average='macro')\n",
        "reDT10=recall_score(df1_ytest, y_pred_DT10, average='macro')\n",
        "\n",
        "print ('Accuracy Score :',accDT10 )\n",
        "print(\"Precision Score: \",preDT10)\n",
        "print(\"F1 Score: \",f1DT10)\n",
        "print(\"Recall: \",reDT10)"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\t\tDecision Tree Analysis of UNSW-NB15\n",
            "\n",
            "\t\tTop 10 Features \n",
            "Confusion Matrix :\n",
            "[[  375    82     1     5   187     0    27     0     0     0]\n",
            " [  319    54     3    11   189     1     3     0     3     0]\n",
            " [ 1490  1020   532   523   372    30    60    23    38     1]\n",
            " [ 1711   958   594  6482   629   149   233   233   129    14]\n",
            " [  722   151   204   498  2876    41  1314     3   250     3]\n",
            " [   20    23    62   227    49 18444    20     3    17     6]\n",
            " [  597     9  1057  1113  7324   188 26556    15   140     1]\n",
            " [  158   142    41   270    46     8    36  2758    35     2]\n",
            " [    1     4    13    43    27     5    11     6   268     0]\n",
            " [    0     0     0    12     0     1     1     0     1    29]]\n",
            "Accuracy Score : 0.7090074333187582\n",
            "Precision Score:  0.49017148697366936\n",
            "F1 Score:  0.4923395380995279\n",
            "Recall:  0.5685449667302843\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZfSSpwm2sk1Y",
        "outputId": "27cc74c3-e686-42bf-c067-e313644ff298"
      },
      "source": [
        "clfDT_20 = DecisionTreeClassifier()\n",
        "print (\"\\t\\tDecision Tree Analysis of UNSW-NB15\\n\\n\\t\\tTop 20 Features \")\n",
        "\n",
        "# Train Decision Tree Classifer\n",
        "clfDT_20 = clfDT_20.fit(df2_xtrain,df2_ytrain)\n",
        "\n",
        "#Predict the response for test dataset\n",
        "y_pred_DT20 = clfDT_20.predict(df2_xtest)\n",
        "\n",
        "\n",
        "#print (\"\\t\\tMajor Verifcation\")\n",
        "results_DT20 = confusion_matrix(df2_ytest, y_pred_DT20) \n",
        "print ('Confusion Matrix :')\n",
        "print(results_DT20)\n",
        "\n",
        "accDT20=accuracy_score(df2_ytest, y_pred_DT20)\n",
        "preDT20=precision_score(df2_ytest, y_pred_DT20, average='macro')\n",
        "f1DT20=f1_score(df2_ytest, y_pred_DT20, average='macro')\n",
        "reDT20=recall_score(df2_ytest, y_pred_DT20, average='macro')\n",
        "\n",
        "print ('Accuracy Score :',accDT20 )\n",
        "print(\"Precision Score: \",preDT20)\n",
        "print(\"F1 Score: \",f1DT20)\n",
        "print(\"Recall: \",reDT20)"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\t\tDecision Tree Analysis of UNSW-NB15\n",
            "\n",
            "\t\tTop 20 Features \n",
            "Confusion Matrix :\n",
            "[[  506   118     0    31     1     3    15     0     3     0]\n",
            " [  491    52     3    12     8     0    13     0     4     0]\n",
            " [ 1735  1045   551   504    92    28    74    26    34     0]\n",
            " [ 2089   985   724  6457   175    83   273   240    97     9]\n",
            " [ 1070   157    90   384  2700    25  1450    15   170     1]\n",
            " [   26    29    66   193    39 18475    15     7    16     5]\n",
            " [  685    11   168   799  7474    56 27610    51   145     1]\n",
            " [  163   145    40   277    25     3    39  2757    46     1]\n",
            " [    1     8    16    45    30     4    15     4   255     0]\n",
            " [    0     0     1    17     0     1     0     1     1    23]]\n",
            "Accuracy Score : 0.721299130350289\n",
            "Precision Score:  0.5143686274709648\n",
            "F1 Score:  0.49783020543757195\n",
            "Recall:  0.5707975393489334\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MQrDjJUosk4b",
        "outputId": "810d5089-c256-40de-8ca4-4eefdb6b0b9a"
      },
      "source": [
        "clfDT_all = DecisionTreeClassifier()\n",
        "print (\"\\t\\tDecision Tree Analysis of UNSW-NB15\\n\\n\\t\\tAll Features \")\n",
        "\n",
        "# Train Decision Tree Classifer\n",
        "clfDT_all = clfDT_all.fit(df3_xtrain,df3_ytrain)\n",
        "\n",
        "#Predict the response for test dataset\n",
        "y_pred_DTall = clfDT_all.predict(df3_xtest)\n",
        "\n",
        "#print (\"\\t\\tMajor Verifcation\")\n",
        "results_DTall = confusion_matrix(df3_ytest, y_pred_DTall) \n",
        "print ('Confusion Matrix :')\n",
        "print(results_DTall)\n",
        "\n",
        "accDTall=accuracy_score(df3_ytest, y_pred_DTall)\n",
        "preDTall=precision_score(df3_ytest, y_pred_DTall, average='macro')\n",
        "f1DTall=f1_score(df3_ytest, y_pred_DTall, average='macro')\n",
        "reDTall=recall_score(df3_ytest, y_pred_DTall, average='macro')\n",
        "\n",
        "print ('Accuracy Score :', accDTall)\n",
        "print(\"Precision Score: \",preDTall)\n",
        "print(\"F1 Score: \",f1DTall)\n",
        "print(\"Recall: \",reDTall)\n"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\t\tDecision Tree Analysis of UNSW-NB15\n",
            "\n",
            "\t\tAll Features \n",
            "Confusion Matrix :\n",
            "[[  495   117     1    53     0     1     8     0     2     0]\n",
            " [  485    66     1    10     5     0    12     0     4     0]\n",
            " [ 1681  1143   555   497    54    34    62    26    37     0]\n",
            " [ 2048  1089   549  6491   147    83   409   224    85     7]\n",
            " [ 1043   190    82   368  2685    21  1525     5   143     0]\n",
            " [   24    25    69   249    31 18427    19     5    16     6]\n",
            " [  691    10   141   808  7422    40 27704    51   132     1]\n",
            " [  162   177    38   284    12     2    30  2748    42     1]\n",
            " [    0     6    14    58    31     3    10     4   252     0]\n",
            " [    0     0     3    15     0     1     0     2     0    23]]\n",
            "Accuracy Score : 0.722027887091289\n",
            "Precision Score:  0.5249027506105863\n",
            "F1 Score:  0.5024805712118786\n",
            "Recall:  0.570678509989761\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aUZpsNG4LJ_y"
      },
      "source": [
        ""
      ],
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0gTs5TBjslQj"
      },
      "source": [
        "#Gaussian Naive Bayes Classifier\n",
        "from sklearn.naive_bayes import MultinomialNB"
      ],
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AYLJ7YcaopnF",
        "outputId": "f59b7193-fff2-4d11-df89-3f3d9323e940"
      },
      "source": [
        "print(df1_ytrain.unique())"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[6 1 0 4 8 7 3 2 9 5]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_e-LXX4Ls2Sk",
        "outputId": "697e7b14-c3be-41e0-c601-4d92e80457ec"
      },
      "source": [
        "bayes_10 = MultinomialNB()\n",
        "#bayes_10.partial_fit(df1_xtrain,df1_ytrain,df1_ytrain.unique())\n",
        "bayes_10.fit(df1_xtrain,df1_ytrain)\n",
        "\n",
        "print (\"\\t\\tGaussain Naive Bayes Analysis of UNSW-NB15\\n\\n\\t\\tTop 10 Features \")\n",
        "y_pred_gnb10 = bayes_10.predict(df1_xtest)\n",
        "\n",
        "#print (\"\\t\\tMajor Verifcation KDD99 10% GNB\")\n",
        "results = confusion_matrix(df1_ytest, y_pred_gnb10) \n",
        "print ('Confusion Matrix :')\n",
        "print(results) \n",
        "\n",
        "accbayes_10=accuracy_score(df1_ytest, y_pred_gnb10) \n",
        "prebayes_10=precision_score(df1_ytest, y_pred_gnb10, average='macro')\n",
        "f1bayes_10=f1_score(df1_ytest, y_pred_gnb10, average='macro')\n",
        "rebayes_10=recall_score(df1_ytest, y_pred_gnb10, average='macro')\n",
        "\n",
        "print ('Accuracy Score :',accbayes_10)\n",
        "print(\"Precision Score: \",prebayes_10)\n",
        "print(\"F1 Score: \",f1bayes_10)\n",
        "print(\"Recall: \",rebayes_10)\n"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\t\tGaussain Naive Bayes Analysis of UNSW-NB15\n",
            "\n",
            "\t\tTop 10 Features \n",
            "Confusion Matrix :\n",
            "[[  601     0     0    14     0     1    61     0     0     0]\n",
            " [  483     0     0    38     1     2    59     0     0     0]\n",
            " [ 2473     0     0   510    72    78   934    10    12     0]\n",
            " [ 2697     0     0  1738   125    56  6494     2    20     0]\n",
            " [ 1222     0     0   752   550   374  3111     7    46     0]\n",
            " [   28     0     0   109    95 18159   475     1     4     0]\n",
            " [  193     0     1  4062  1501  2792 28284    18   149     0]\n",
            " [ 1541     0     0    68     8    15  1858     6     0     0]\n",
            " [   75     0     0     1    36     9   192     6    59     0]\n",
            " [    0     0     0     2     4     2    36     0     0     0]]\n",
            "Accuracy Score : 0.5999732789194967\n",
            "Precision Score:  0.23827456767032631\n",
            "F1 Score:  0.2239561902839405\n",
            "Recall:  0.30190991296773395\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning:\n",
            "\n",
            "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nZUmRijOs2VE",
        "outputId": "c8c51c20-ea9d-4f7f-b520-bcdcf421db6b"
      },
      "source": [
        "bayes_20 = MultinomialNB()\n",
        "bayes_20.fit(df2_xtrain,df2_ytrain)\n",
        "\n",
        "print (\"\\t\\tGaussian Naive Bayes Analysis of UNSW-NB15\\n\\n\\t\\tTop 20 Features \")\n",
        "\n",
        "y_pred_gnb20 = bayes_20.predict(df2_xtest)\n",
        "\n",
        "#print (\"\\t\\tMajor Verifcation KDD99 10% GNB\")\n",
        "results = confusion_matrix(df2_ytest, y_pred_gnb20) \n",
        "print ('Confusion Matrix :')\n",
        "print(results)\n",
        "\n",
        "accbayes_20=accuracy_score(df2_ytest, y_pred_gnb20) \n",
        "prebayes_20=precision_score(df2_ytest, y_pred_gnb20, average='macro')\n",
        "f1bayes_20=f1_score(df2_ytest, y_pred_gnb20, average='macro')\n",
        "rebayes_20=recall_score(df2_ytest, y_pred_gnb20, average='macro')\n",
        "\n",
        "print ('Accuracy Score :',accbayes_20)\n",
        "print(\"Precision Score: \",prebayes_20)\n",
        "print(\"F1 Score: \",f1bayes_20)\n",
        "print(\"Recall: \",rebayes_20)\n"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\t\tGaussian Naive Bayes Analysis of UNSW-NB15\n",
            "\n",
            "\t\tTop 20 Features \n",
            "Confusion Matrix :\n",
            "[[    3     0     2    40     0   614     0     0     0    18]\n",
            " [    3     0    10    36     0   515     4     0     0    15]\n",
            " [   31     0    87   677     0  2903    17     0     0   374]\n",
            " [   36     0   128  5200     0  3163    76     0     0  2529]\n",
            " [   45     0    54  2445     0  2250     0     0     0  1268]\n",
            " [    4     0     4   345     0 18343     4     0     0   171]\n",
            " [  585     0    73 14651     0  5965  7847     1     1  7877]\n",
            " [    8     0    22  1262     0  1601     0     0     0   603]\n",
            " [    0     0     0   130     0   185     0     0     0    63]\n",
            " [    0     0     0    24     0     6     0     0     0    14]]\n",
            "Accuracy Score : 0.3825244133508235\n",
            "Precision Score:  0.1947161142507347\n",
            "F1 Score:  0.135809387243145\n",
            "Recall:  0.19951131812748615\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning:\n",
            "\n",
            "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VcEkvsRBs2YC",
        "outputId": "390d5500-e15c-40e5-81f7-edcd049b7e98"
      },
      "source": [
        "bayes_all = MultinomialNB()\n",
        "bayes_all.fit(df3_xtrain,df3_ytrain)\n",
        "\n",
        "print (\"\\t\\tGaussian Naive Bayes Analysis of UNSW-NB15\\n\\n\\t\\tAll Features \")\n",
        "y_pred_gnball = bayes_all.predict(df3_xtest)\n",
        "\n",
        "#print (\"\\t\\tMajor Verifcation KDD99 10% GNB\")\n",
        "results = confusion_matrix(df3_ytest, y_pred_gnball) \n",
        "print ('Confusion Matrix :')\n",
        "print(results)\n",
        "\n",
        "accbayes_all=accuracy_score(df3_ytest, y_pred_gnball)\n",
        "prebayes_all=precision_score(df3_ytest, y_pred_gnball, average='macro')\n",
        "f1bayes_all=f1_score(df3_ytest, y_pred_gnball, average='macro')\n",
        "rebayes_all=recall_score(df3_ytest, y_pred_gnball, average='macro')\n",
        "\n",
        "print ('Accuracy Score :', accbayes_all)\n",
        "print(\"Precision Score: \",prebayes_all)\n",
        "print(\"F1 Score: \",f1bayes_all)\n",
        "print(\"Recall: \",rebayes_all)\n"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\t\tGaussian Naive Bayes Analysis of UNSW-NB15\n",
            "\n",
            "\t\tAll Features \n",
            "Confusion Matrix :\n",
            "[[    3     0     2    40     0   614     0     0     0    18]\n",
            " [    3     0    10    36     0   515     4     0     0    15]\n",
            " [   31     0    87   677     0  2903    17     0     0   374]\n",
            " [   36     0   128  5200     0  3163    76     0     0  2529]\n",
            " [   45     0    54  2445     0  2250     0     0     0  1268]\n",
            " [    4     0     4   345     0 18343     4     0     0   171]\n",
            " [  615     0    14 14654     0  6027  7813     1     1  7875]\n",
            " [    8     0    22  1262     0  1601     0     0     0   603]\n",
            " [    0     0     0   130     0   185     0     0     0    63]\n",
            " [    0     0     0    24     0     6     0     0     0    14]]\n",
            "Accuracy Score : 0.38211145119759027\n",
            "Precision Score:  0.1988094523267321\n",
            "F1 Score:  0.13564830638485165\n",
            "Recall:  0.19941942623559425\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning:\n",
            "\n",
            "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D1DehUCas2bP"
      },
      "source": [
        "#Random Forest Classifier \n"
      ],
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5eCGklXTuKYb",
        "outputId": "31588386-e113-4ba9-ebfb-438a5d4e08b6"
      },
      "source": [
        "print (\"\\t\\tRandom Forest Analysis of UNSW-NB15\\n\\n\\t\\tTop 10 Features \")\n",
        "\n",
        "#Create a Gaussian Classifier\n",
        "clfRF_10=RandomForestClassifier()\n",
        "\n",
        "#Train the model using the training sets y_pred=clf.predict(X_test)\n",
        "clfRF_10.fit(df1_xtrain,df1_ytrain)\n",
        "\n",
        "y_pred_RF10=clfRF_10.predict(df1_xtest)\n",
        "#print(\"Accuracy Random Forest:\",metrics.accuracy_score(y_test, y_pred_RF))\n",
        "\n",
        "results_10 = confusion_matrix(df1_ytest, y_pred_RF10) \n",
        "print ('Confusion Matrix :')\n",
        "print(results_10) \n",
        "\n",
        "accclfRF_10=accuracy_score(df1_ytest, y_pred_RF10)\n",
        "preclfRF_10=precision_score(df1_ytest, y_pred_RF10, average='macro')\n",
        "f1clfRF_10=f1_score(df1_ytest, y_pred_RF10, average='macro')\n",
        "reclfRF_10=recall_score(df1_ytest, y_pred_RF10, average='macro')\n",
        "\n",
        "print ('Accuracy Score :',accclfRF_10 )\n",
        "print(\"Precision Score: \",preclfRF_10)\n",
        "print(\"F1 Score: \",f1clfRF_10)\n",
        "print(\"Recall: \",reclfRF_10)\n"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\t\tRandom Forest Analysis of UNSW-NB15\n",
            "\n",
            "\t\tTop 10 Features \n",
            "Confusion Matrix :\n",
            "[[   48   110    19    64   383     0    23    27     3     0]\n",
            " [   34    68    14    22   396     0    21    20     8     0]\n",
            " [  351  1357   542   735   807    14    39   197    46     1]\n",
            " [  358  1258   222  7477  1257    14   151   305    85     5]\n",
            " [  103   218    34   408  4021     3  1014    49   212     0]\n",
            " [    4     8    40   396    67 18321     7     6    20     2]\n",
            " [  306     1    56   737  7451     7 28319     7   115     1]\n",
            " [   42   176    30   314    90     0    19  2795    30     0]\n",
            " [    0     1    13    48    33     0     9     3   270     1]\n",
            " [    0     0     0    21     1     1     1     0     0    20]]\n",
            "Accuracy Score : 0.7516032648301997\n",
            "Precision Score:  0.5410475653187922\n",
            "F1 Score:  0.5038844225685519\n",
            "Recall:  0.5359618986202608\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jYQ8JD5ruKl8",
        "outputId": "547d080f-08fe-41dc-9a3a-a1e1e3135773"
      },
      "source": [
        "print (\"\\t\\tRandom Forest Analysis of UNSW-NB15\\n\\n\\t\\tTop 20 Features \")\n",
        "\n",
        "#Create a Gaussian Classifier\n",
        "clfRF_20=RandomForestClassifier()\n",
        "\n",
        "#Train the model using the training sets y_pred=clf.predict(X_test)\n",
        "clfRF_20.fit(df2_xtrain,df2_ytrain)\n",
        "\n",
        "y_pred_RF20=clfRF_20.predict(df2_xtest)\n",
        "#print(\"Accuracy Random Forest:\",metrics.accuracy_score(y_test, y_pred_RF))\n",
        "\n",
        "results_20 = confusion_matrix(df2_ytest, y_pred_RF20) \n",
        "print ('Confusion Matrix :')\n",
        "print(results_20) \n",
        "\n",
        "accclfRF_20=accuracy_score(df2_ytest, y_pred_RF20) \n",
        "preclfRF_20=precision_score(df2_ytest, y_pred_RF20, average='macro')\n",
        "f1clfRF_20=f1_score(df2_ytest, y_pred_RF20, average='macro')\n",
        "reclfRF_20=recall_score(df2_ytest, y_pred_RF20, average='macro')\n",
        "\n",
        "print ('Accuracy Score :',accclfRF_20)\n",
        "print(\"Precision Score: \",preclfRF_20)\n",
        "print(\"F1 Score: \",f1clfRF_20)\n",
        "print(\"Recall: \",reclfRF_20)\n"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\t\tRandom Forest Analysis of UNSW-NB15\n",
            "\n",
            "\t\tTop 20 Features \n",
            "Confusion Matrix :\n",
            "[[   40   234    11    44   252     4    20    69     3     0]\n",
            " [   39   167    10    22   255    10     4    70     6     0]\n",
            " [  518  1382   483   803   638    29    12   183    40     1]\n",
            " [  534  1388   134  7610   934    32    92   345    59     4]\n",
            " [  132   403    22   368  3856    10   912   141   218     0]\n",
            " [    2     7    42   390    51 18345     5     6    18     5]\n",
            " [  402     1    29   732  7584     6 28122     6   118     0]\n",
            " [   63   162    25   324    83     0     8  2804    27     0]\n",
            " [    0     0     8    57    38     1     7     1   265     1]\n",
            " [    0     0     0    29     2     1     1     0     0    11]]\n",
            "Accuracy Score : 0.7494412864985668\n",
            "Precision Score:  0.5298315485436575\n",
            "F1 Score:  0.48297007914773227\n",
            "Recall:  0.5268662182474247\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EpJHXBBTuKvd",
        "outputId": "d00ce31b-3322-4481-efb0-d912cba3401d"
      },
      "source": [
        "print (\"\\t\\tRandom Forest Analysis of UNSW-NB15\\n\\n\\t\\tTop 30 Features \")\n",
        "\n",
        "#Create a Random Forest Classifier\n",
        "clfRF_all=RandomForestClassifier()\n",
        "\n",
        "#Train the model using the training sets y_pred=clf.predict(X_test)\n",
        "clfRF_all.fit(df3_xtrain,df3_ytrain)\n",
        "\n",
        "y_pred_RFall=clfRF_all.predict(df3_xtest)\n",
        "#print(\"Accuracy Random Forest:\",metrics.accuracy_score(y_test, y_pred_RF))\n",
        "\n",
        "results_all = confusion_matrix(df3_ytest, y_pred_RFall) \n",
        "print ('Confusion Matrix :')\n",
        "print(results_all) \n",
        "\n",
        "accclfRF_all=accuracy_score(df3_ytest, y_pred_RFall) \n",
        "preclfRF_all=precision_score(df3_ytest, y_pred_RFall, average='macro')\n",
        "f1clfRF_all=f1_score(df3_ytest, y_pred_RFall, average='macro')\n",
        "reclfRF_all=recall_score(df3_ytest, y_pred_RFall, average='macro')\n",
        "\n",
        "print ('Accuracy Score :',accclfRF_all)\n",
        "print(\"Precision Score: \",preclfRF_all)\n",
        "print(\"F1 Score: \",f1clfRF_all)\n",
        "print(\"Recall: \",reclfRF_all)\n"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\t\tRandom Forest Analysis of UNSW-NB15\n",
            "\n",
            "\t\tTop 30 Features \n",
            "Confusion Matrix :\n",
            "[[   45   264     9    56   218     0    12    70     3     0]\n",
            " [   45   180    13    31   229     6     1    72     6     0]\n",
            " [  397  1711   452   750   533    25    16   164    41     0]\n",
            " [  419  1715   121  7543   794    29    91   343    75     2]\n",
            " [  122   467    30   348  3817     1   957   140   180     0]\n",
            " [    2     8    39   394    53 18342     7     5    19     2]\n",
            " [  478     0    22   730  7529     7 28101     7   125     1]\n",
            " [   47   208    19   314    73     1     6  2803    25     0]\n",
            " [    0     0     9    48    47     0     7     2   264     1]\n",
            " [    0     0     0    29     2     1     2     0     0    10]]\n",
            "Accuracy Score : 0.7476679784288005\n",
            "Precision Score:  0.5443632572389877\n",
            "F1 Score:  0.4827502039330649\n",
            "Recall:  0.5251927284001812\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v6N3Y69QuLDL"
      },
      "source": [
        "#Logistic Regression Classifier \n"
      ],
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 540
        },
        "id": "GJHJebbCuSZr",
        "outputId": "72f3bb07-d29c-424e-9627-72645a32af6b"
      },
      "source": [
        "print (\"\\t\\tLogistic Regression Analysis of UNSW-NB15\\n\\n\\t\\tTop 10 Features \")\n",
        "\n",
        "logisticRegr_10 = LogisticRegression(C=1e5, solver='newton-cg',max_iter=1000, multi_class='multinomial')\n",
        "\n",
        "logisticRegr_10.fit(df1_xtrain,df1_ytrain)\n",
        "\n",
        "y_pred_LR10 = logisticRegr_10.predict(df1_xtest)\n",
        "\n",
        "results_LR10 = confusion_matrix(df1_ytest, y_pred_LR10) \n",
        "print ('Confusion Matrix :')\n",
        "print(results_LR10) \n",
        "\n",
        "acclogisticRegr_10=accuracy_score(df1_ytest, y_pred_LR10)\n",
        "prelogisticRegr_10=precision_score(df1_ytest, y_pred_LR10, average='macro')\n",
        "f1logisticRegr_10=f1_score(df1_ytest, y_pred_LR10, average='macro')\n",
        "relogisticRegr_10=recall_score(df1_ytest, y_pred_LR10, average='macro')\n",
        "\n",
        "print ('Accuracy Score :',acclogisticRegr_10 )\n",
        "print(\"Precision Score: \",prelogisticRegr_10)\n",
        "print(\"F1 Score: \",f1logisticRegr_10)\n",
        "print(\"Recall: \",relogisticRegr_10)\n"
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\t\tLogistic Regression Analysis of UNSW-NB15\n",
            "\n",
            "\t\tTop 10 Features \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/scipy/optimize/linesearch.py:466: LineSearchWarning:\n",
            "\n",
            "The line search algorithm did not converge\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/scipy/optimize/linesearch.py:314: LineSearchWarning:\n",
            "\n",
            "The line search algorithm did not converge\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-105-187a8e851665>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mlogisticRegr_10\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mC\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msolver\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'newton-cg'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmulti_class\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'multinomial'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mlogisticRegr_10\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf1_xtrain\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdf1_ytrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0my_pred_LR10\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogisticRegr_10\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf1_xtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1599\u001b[0m                       \u001b[0mpenalty\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpenalty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_squared_sum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_squared_sum\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1600\u001b[0m                       sample_weight=sample_weight)\n\u001b[0;32m-> 1601\u001b[0;31m             for class_, warm_start_coef_ in zip(classes_, warm_start_coef))\n\u001b[0m\u001b[1;32m   1602\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1603\u001b[0m         \u001b[0mfold_coefs_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_iter_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfold_coefs_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1039\u001b[0m             \u001b[0;31m# remaining jobs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1040\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1041\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1042\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1043\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    857\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    860\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    775\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    776\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 777\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    778\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 263\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 263\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py\u001b[0m in \u001b[0;36m_logistic_regression_path\u001b[0;34m(X, y, pos_class, Cs, fit_intercept, max_iter, tol, verbose, solver, coef, class_weight, dual, penalty, intercept_scaling, multi_class, random_state, check_input, max_squared_sum, sample_weight, l1_ratio)\u001b[0m\n\u001b[1;32m    943\u001b[0m             \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m             w0, n_iter_i = _newton_cg(hess, func, grad, w0, args=args,\n\u001b[0;32m--> 945\u001b[0;31m                                       maxiter=max_iter, tol=tol)\n\u001b[0m\u001b[1;32m    946\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0msolver\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'liblinear'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m             coef_, intercept_, n_iter_i, = _fit_liblinear(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/optimize.py\u001b[0m in \u001b[0;36m_newton_cg\u001b[0;34m(grad_hess, func, grad, x0, args, tol, maxiter, maxinner, line_search, warn)\u001b[0m\n\u001b[1;32m    200\u001b[0m                 \u001b[0malphak\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mold_fval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mold_old_fval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgfkp1\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                     _line_search_wolfe12(func, grad, xk, xsupi, fgrad,\n\u001b[0;32m--> 202\u001b[0;31m                                          old_fval, old_old_fval, args=args)\n\u001b[0m\u001b[1;32m    203\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0m_LineSearchError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Line Search failed'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/optimize.py\u001b[0m in \u001b[0;36m_line_search_wolfe12\u001b[0;34m(f, fprime, xk, pk, gfk, old_fval, old_old_fval, **kwargs)\u001b[0m\n\u001b[1;32m     41\u001b[0m     ret = line_search_wolfe1(f, fprime, xk, pk, gfk,\n\u001b[1;32m     42\u001b[0m                              \u001b[0mold_fval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mold_old_fval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m                              **kwargs)\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/scipy/optimize/linesearch.py\u001b[0m in \u001b[0;36mline_search_wolfe1\u001b[0;34m(f, fprime, xk, pk, gfk, old_fval, old_old_fval, args, c1, c2, amax, amin, xtol)\u001b[0m\n\u001b[1;32m     99\u001b[0m     stp, fval, old_fval = scalar_search_wolfe1(\n\u001b[1;32m    100\u001b[0m             \u001b[0mphi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mderphi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mold_fval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mold_old_fval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mderphi0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m             c1=c1, c2=c2, amax=amax, amin=amin, xtol=xtol)\n\u001b[0m\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mstp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mold_fval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgval\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/scipy/optimize/linesearch.py\u001b[0m in \u001b[0;36mscalar_search_wolfe1\u001b[0;34m(phi, derphi, phi0, old_phi0, derphi0, c1, c2, amax, amin, xtol)\u001b[0m\n\u001b[1;32m    173\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34mb'FG'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m             \u001b[0malpha1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m             \u001b[0mphi1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mphi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    176\u001b[0m             \u001b[0mderphi1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mderphi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/scipy/optimize/linesearch.py\u001b[0m in \u001b[0;36mphi\u001b[0;34m(s)\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mphi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0mfc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxk\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mpk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mderphi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x, *args)\u001b[0m\n\u001b[1;32m    911\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_multinomial_loss_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    912\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0msolver\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'newton-cg'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 913\u001b[0;31m             \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_multinomial_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    914\u001b[0m             \u001b[0mgrad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_multinomial_loss_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    915\u001b[0m             \u001b[0mhess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_multinomial_grad_hess\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py\u001b[0m in \u001b[0;36m_multinomial_loss\u001b[0;34m(w, X, Y, alpha, sample_weight)\u001b[0m\n\u001b[1;32m    298\u001b[0m     \u001b[0mp\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mintercept\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m     \u001b[0mp\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0mlogsumexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 300\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_weight\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mY\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    301\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m0.5\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0malpha\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0msquared_norm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m     \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_xO1WIT4uScz"
      },
      "source": [
        "print (\"\\t\\tLogistic Regression Analysis of UNSW NB15\\n\\n\\t\\tTop 20 Features \")\n",
        "\n",
        "logisticRegr_20 = LogisticRegression(C=1e5, solver='newton-cg',max_iter=1000, multi_class='multinomial')\n",
        "\n",
        "logisticRegr_20.fit(df2_xtrain,df2_ytrain)\n",
        "\n",
        "y_pred_LR20 = logisticRegr_20.predict(df2_xtest)\n",
        "\n",
        "results_LR20 = confusion_matrix(df2_ytest, y_pred_LR20) \n",
        "print ('Confusion Matrix :')\n",
        "print(results_LR20) \n",
        "\n",
        "acclogisticRegr_20=accuracy_score(df2_ytest, y_pred_LR20)\n",
        "prelogisticRegr_20=precision_score(df2_ytest, y_pred_LR20, average='macro')\n",
        "f1logisticRegr_20=f1_score(df2_ytest, y_pred_LR20, average='macro')\n",
        "relogisticRegr_20=recall_score(df2_ytest, y_pred_LR20, average='macro')\n",
        "\n",
        "print ('Accuracy Score :',acclogisticRegr_20 )\n",
        "print(\"Precision Score: \",prelogisticRegr_20)\n",
        "print(\"F1 Score: \",f1logisticRegr_20)\n",
        "print(\"Recall: \",relogisticRegr_20)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lp-GI4YS4kUT"
      },
      "source": [
        "print (\"\\t\\tLogistic Regression Analysis of UNSW-NB15\\n\\n\\t\\tTop 30 Features \")\n",
        "\n",
        "logisticRegr_all = LogisticRegression(C=1e5, solver='Newton-cg', multi_class='multinomial')\n",
        "\n",
        "logisticRegr_all.fit(df3_xtrain,df3_ytrain)\n",
        "\n",
        "y_pred_LRall = logisticRegr_all.predict(df3_xtest)\n",
        "\n",
        "results_LRall = confusion_matrix(df3_ytest, y_pred_LRall) \n",
        "print ('Confusion Matrix :')\n",
        "print(results_LRall) \n",
        "\n",
        "acclogisticRegr_all=accuracy_score(df3_ytest, y_pred_LRall)\n",
        "prelogisticRegr_all=precision_score(df3_ytest, y_pred_LRall, average='macro')\n",
        "f1logisticRegr_all=f1_score(df3_ytest, y_pred_LRall, average='macro')\n",
        "relogisticRegr_all=recall_score(df3_ytest, y_pred_LRall, average='macro')\n",
        "\n",
        "print ('Accuracy Score :', acclogisticRegr_all)\n",
        "print(\"Precision Score: \",prelogisticRegr_all)\n",
        "print(\"F1 Score: \",f1logisticRegr_all)\n",
        "print(\"Recall: \",relogisticRegr_all)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bb4K050wkqgQ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nTDUTMLgtmpg",
        "outputId": "3e69fbda-8b21-49a6-b11f-eb63d417f2b3"
      },
      "source": [
        "X = df1_xtrain\n",
        "Y = df1_ytrain\n",
        "C = df3_ytest\n",
        "T = df1_xtest\n",
        "scaler = Normalizer().fit(X)\n",
        "trainX = scaler.transform(X)\n",
        "\n",
        "scaler = Normalizer().fit(T)\n",
        "testT = scaler.transform(T)\n",
        "\n",
        "y_train1 = np.array(Y)\n",
        "y_test1 = np.array(C)\n",
        "\n",
        "y_train= to_categorical(y_train1)\n",
        "y_test= to_categorical(y_test1)\n",
        "\n",
        "\n",
        "# reshape input to be [samples, time steps, features]\n",
        "X_train = np.reshape(trainX, (trainX.shape[0],trainX.shape[1],1))\n",
        "X_test = np.reshape(testT, (testT.shape[0],testT.shape[1],1))\n",
        "\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras import layers\n",
        "\n",
        "input_dim = df1_xtrain.shape[1]  # Number of features\n",
        "\n",
        "model = Sequential()\n",
        "model.add(layers.Dense(10, input_shape=(15, 1), activation='relu'))\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(32, activation='relu'))\n",
        "model.add(layers.Dense(10, activation='softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', \n",
        "              optimizer='adam', \n",
        "              metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_20\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_52 (Dense)             (None, 15, 10)            20        \n",
            "_________________________________________________________________\n",
            "flatten_6 (Flatten)          (None, 150)               0         \n",
            "_________________________________________________________________\n",
            "dense_53 (Dense)             (None, 32)                4832      \n",
            "_________________________________________________________________\n",
            "dense_54 (Dense)             (None, 10)                330       \n",
            "=================================================================\n",
            "Total params: 5,182\n",
            "Trainable params: 5,182\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mAvwB1CKtx2X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed59edd9-e1e3-4649-b434-1494f625c68f"
      },
      "source": [
        "historyNN10 = model.fit(X_train, y_train,\n",
        "                    epochs=100 #,\n",
        "                    #verbose=False\n",
        "                    )"
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "3367/3367 [==============================] - 5s 1ms/step - loss: 1.4607 - accuracy: 0.4795\n",
            "Epoch 2/100\n",
            "3367/3367 [==============================] - 5s 1ms/step - loss: 1.2223 - accuracy: 0.5120\n",
            "Epoch 3/100\n",
            "3367/3367 [==============================] - 4s 1ms/step - loss: 1.1439 - accuracy: 0.5491\n",
            "Epoch 4/100\n",
            "3367/3367 [==============================] - 5s 1ms/step - loss: 1.1026 - accuracy: 0.5686\n",
            "Epoch 5/100\n",
            "3367/3367 [==============================] - 4s 1ms/step - loss: 1.0732 - accuracy: 0.5836\n",
            "Epoch 6/100\n",
            "3367/3367 [==============================] - 5s 1ms/step - loss: 1.0490 - accuracy: 0.5952\n",
            "Epoch 7/100\n",
            "3367/3367 [==============================] - 4s 1ms/step - loss: 1.0302 - accuracy: 0.6058\n",
            "Epoch 8/100\n",
            "3367/3367 [==============================] - 5s 1ms/step - loss: 1.0106 - accuracy: 0.6168\n",
            "Epoch 9/100\n",
            "3367/3367 [==============================] - 4s 1ms/step - loss: 0.9911 - accuracy: 0.6285\n",
            "Epoch 10/100\n",
            "3367/3367 [==============================] - 4s 1ms/step - loss: 0.9712 - accuracy: 0.6401\n",
            "Epoch 11/100\n",
            "3367/3367 [==============================] - 4s 1ms/step - loss: 0.9569 - accuracy: 0.6501\n",
            "Epoch 12/100\n",
            "3367/3367 [==============================] - 4s 1ms/step - loss: 0.9451 - accuracy: 0.6543\n",
            "Epoch 13/100\n",
            "3367/3367 [==============================] - 4s 1ms/step - loss: 0.9398 - accuracy: 0.6574\n",
            "Epoch 14/100\n",
            "3367/3367 [==============================] - 4s 1ms/step - loss: 0.9299 - accuracy: 0.6629\n",
            "Epoch 15/100\n",
            "3367/3367 [==============================] - 4s 1ms/step - loss: 0.9217 - accuracy: 0.6657\n",
            "Epoch 16/100\n",
            "3367/3367 [==============================] - 4s 1ms/step - loss: 0.9094 - accuracy: 0.6688\n",
            "Epoch 17/100\n",
            "3367/3367 [==============================] - 4s 1ms/step - loss: 0.9084 - accuracy: 0.6708\n",
            "Epoch 18/100\n",
            "3367/3367 [==============================] - 4s 1ms/step - loss: 0.8954 - accuracy: 0.6735\n",
            "Epoch 19/100\n",
            "3367/3367 [==============================] - 4s 1ms/step - loss: 0.8909 - accuracy: 0.6779\n",
            "Epoch 20/100\n",
            "3367/3367 [==============================] - 4s 1ms/step - loss: 0.8808 - accuracy: 0.6823\n",
            "Epoch 21/100\n",
            "3367/3367 [==============================] - 4s 1ms/step - loss: 0.8760 - accuracy: 0.6860\n",
            "Epoch 22/100\n",
            "3367/3367 [==============================] - 4s 1ms/step - loss: 0.8649 - accuracy: 0.6917\n",
            "Epoch 23/100\n",
            "3367/3367 [==============================] - 4s 1ms/step - loss: 0.8595 - accuracy: 0.6928\n",
            "Epoch 24/100\n",
            "3367/3367 [==============================] - 5s 1ms/step - loss: 0.8515 - accuracy: 0.6984\n",
            "Epoch 25/100\n",
            "3367/3367 [==============================] - 5s 1ms/step - loss: 0.8488 - accuracy: 0.6971\n",
            "Epoch 26/100\n",
            "3367/3367 [==============================] - 5s 1ms/step - loss: 0.8495 - accuracy: 0.7010\n",
            "Epoch 27/100\n",
            "3367/3367 [==============================] - 5s 1ms/step - loss: 0.8402 - accuracy: 0.7021\n",
            "Epoch 28/100\n",
            "3367/3367 [==============================] - 4s 1ms/step - loss: 0.8328 - accuracy: 0.7071\n",
            "Epoch 29/100\n",
            "3367/3367 [==============================] - 5s 1ms/step - loss: 0.8380 - accuracy: 0.7061\n",
            "Epoch 30/100\n",
            "3367/3367 [==============================] - 4s 1ms/step - loss: 0.8339 - accuracy: 0.7054\n",
            "Epoch 31/100\n",
            "3367/3367 [==============================] - 5s 1ms/step - loss: 0.8220 - accuracy: 0.7094\n",
            "Epoch 32/100\n",
            "3367/3367 [==============================] - 4s 1ms/step - loss: 0.8186 - accuracy: 0.7111\n",
            "Epoch 33/100\n",
            "3367/3367 [==============================] - 5s 1ms/step - loss: 0.8254 - accuracy: 0.7111\n",
            "Epoch 34/100\n",
            "3367/3367 [==============================] - 5s 1ms/step - loss: 0.8170 - accuracy: 0.7122\n",
            "Epoch 35/100\n",
            "3367/3367 [==============================] - 5s 1ms/step - loss: 0.8114 - accuracy: 0.7121\n",
            "Epoch 36/100\n",
            "3367/3367 [==============================] - 5s 1ms/step - loss: 0.8127 - accuracy: 0.7142\n",
            "Epoch 37/100\n",
            "3367/3367 [==============================] - 5s 1ms/step - loss: 0.8029 - accuracy: 0.7162\n",
            "Epoch 38/100\n",
            "3367/3367 [==============================] - 5s 1ms/step - loss: 0.8074 - accuracy: 0.7136\n",
            "Epoch 39/100\n",
            "3367/3367 [==============================] - 5s 1ms/step - loss: 0.8066 - accuracy: 0.7139\n",
            "Epoch 40/100\n",
            "3367/3367 [==============================] - 5s 1ms/step - loss: 0.8070 - accuracy: 0.7147\n",
            "Epoch 41/100\n",
            "3367/3367 [==============================] - 5s 1ms/step - loss: 0.8018 - accuracy: 0.7121\n",
            "Epoch 42/100\n",
            "3367/3367 [==============================] - 5s 1ms/step - loss: 0.7966 - accuracy: 0.7147\n",
            "Epoch 43/100\n",
            "3367/3367 [==============================] - 5s 1ms/step - loss: 0.8016 - accuracy: 0.7150\n",
            "Epoch 44/100\n",
            "3367/3367 [==============================] - 5s 1ms/step - loss: 0.7939 - accuracy: 0.7162\n",
            "Epoch 45/100\n",
            "3367/3367 [==============================] - 5s 1ms/step - loss: 0.7927 - accuracy: 0.7155\n",
            "Epoch 46/100\n",
            "3367/3367 [==============================] - 5s 1ms/step - loss: 0.7890 - accuracy: 0.7169\n",
            "Epoch 47/100\n",
            "3367/3367 [==============================] - 5s 1ms/step - loss: 0.7856 - accuracy: 0.7179\n",
            "Epoch 48/100\n",
            "3367/3367 [==============================] - 5s 1ms/step - loss: 0.7828 - accuracy: 0.7180\n",
            "Epoch 49/100\n",
            "3367/3367 [==============================] - 5s 1ms/step - loss: 0.7805 - accuracy: 0.7183\n",
            "Epoch 50/100\n",
            "3367/3367 [==============================] - 5s 1ms/step - loss: 0.7846 - accuracy: 0.7163\n",
            "Epoch 51/100\n",
            "3367/3367 [==============================] - 5s 1ms/step - loss: 0.7816 - accuracy: 0.7164\n",
            "Epoch 52/100\n",
            "3367/3367 [==============================] - 5s 1ms/step - loss: 0.7770 - accuracy: 0.7166\n",
            "Epoch 53/100\n",
            "3367/3367 [==============================] - 5s 1ms/step - loss: 0.7747 - accuracy: 0.7167\n",
            "Epoch 54/100\n",
            "3367/3367 [==============================] - 5s 1ms/step - loss: 0.7715 - accuracy: 0.7187\n",
            "Epoch 55/100\n",
            "3367/3367 [==============================] - 5s 1ms/step - loss: 0.7643 - accuracy: 0.7199\n",
            "Epoch 56/100\n",
            "3367/3367 [==============================] - 5s 1ms/step - loss: 0.7646 - accuracy: 0.7210\n",
            "Epoch 57/100\n",
            "3367/3367 [==============================] - 5s 1ms/step - loss: 0.7560 - accuracy: 0.7231\n",
            "Epoch 58/100\n",
            "3367/3367 [==============================] - 5s 2ms/step - loss: 0.7627 - accuracy: 0.7205\n",
            "Epoch 59/100\n",
            "3367/3367 [==============================] - 5s 2ms/step - loss: 0.7553 - accuracy: 0.7207\n",
            "Epoch 60/100\n",
            "3367/3367 [==============================] - 6s 2ms/step - loss: 0.7540 - accuracy: 0.7217\n",
            "Epoch 61/100\n",
            "3367/3367 [==============================] - 5s 1ms/step - loss: 0.7405 - accuracy: 0.7273\n",
            "Epoch 62/100\n",
            "3367/3367 [==============================] - 6s 2ms/step - loss: 0.7388 - accuracy: 0.7266\n",
            "Epoch 63/100\n",
            "3367/3367 [==============================] - 5s 2ms/step - loss: 0.7423 - accuracy: 0.7238\n",
            "Epoch 64/100\n",
            "3367/3367 [==============================] - 5s 1ms/step - loss: 0.7420 - accuracy: 0.7262\n",
            "Epoch 65/100\n",
            "3367/3367 [==============================] - 5s 2ms/step - loss: 0.7322 - accuracy: 0.7264\n",
            "Epoch 66/100\n",
            "3367/3367 [==============================] - 6s 2ms/step - loss: 0.7322 - accuracy: 0.7306\n",
            "Epoch 67/100\n",
            "3367/3367 [==============================] - 5s 2ms/step - loss: 0.7314 - accuracy: 0.7292\n",
            "Epoch 68/100\n",
            "3367/3367 [==============================] - 5s 1ms/step - loss: 0.7272 - accuracy: 0.7290\n",
            "Epoch 69/100\n",
            "3367/3367 [==============================] - 5s 2ms/step - loss: 0.7240 - accuracy: 0.7293\n",
            "Epoch 70/100\n",
            "3367/3367 [==============================] - 6s 2ms/step - loss: 0.7255 - accuracy: 0.7297\n",
            "Epoch 71/100\n",
            "3367/3367 [==============================] - 6s 2ms/step - loss: 0.7276 - accuracy: 0.7308\n",
            "Epoch 72/100\n",
            "3367/3367 [==============================] - 5s 2ms/step - loss: 0.7227 - accuracy: 0.7292\n",
            "Epoch 73/100\n",
            "3367/3367 [==============================] - 5s 1ms/step - loss: 0.7234 - accuracy: 0.7300\n",
            "Epoch 74/100\n",
            "3367/3367 [==============================] - 5s 2ms/step - loss: 0.7150 - accuracy: 0.7343\n",
            "Epoch 75/100\n",
            "3367/3367 [==============================] - 5s 1ms/step - loss: 0.7206 - accuracy: 0.7307\n",
            "Epoch 76/100\n",
            "3367/3367 [==============================] - 5s 1ms/step - loss: 0.7254 - accuracy: 0.7299\n",
            "Epoch 77/100\n",
            "3367/3367 [==============================] - 5s 1ms/step - loss: 0.7206 - accuracy: 0.7329\n",
            "Epoch 78/100\n",
            "3367/3367 [==============================] - 5s 1ms/step - loss: 0.7182 - accuracy: 0.7317\n",
            "Epoch 79/100\n",
            "3367/3367 [==============================] - 5s 1ms/step - loss: 0.7149 - accuracy: 0.7320\n",
            "Epoch 80/100\n",
            "3367/3367 [==============================] - 5s 1ms/step - loss: 0.7127 - accuracy: 0.7344\n",
            "Epoch 81/100\n",
            "3367/3367 [==============================] - 5s 2ms/step - loss: 0.7148 - accuracy: 0.7328\n",
            "Epoch 82/100\n",
            "3367/3367 [==============================] - 5s 1ms/step - loss: 0.7088 - accuracy: 0.7355\n",
            "Epoch 83/100\n",
            "3367/3367 [==============================] - 5s 1ms/step - loss: 0.7125 - accuracy: 0.7333\n",
            "Epoch 84/100\n",
            "3367/3367 [==============================] - 5s 1ms/step - loss: 0.7082 - accuracy: 0.7350\n",
            "Epoch 85/100\n",
            "3367/3367 [==============================] - 5s 1ms/step - loss: 0.7122 - accuracy: 0.7345\n",
            "Epoch 86/100\n",
            "3367/3367 [==============================] - 5s 1ms/step - loss: 0.7162 - accuracy: 0.7314\n",
            "Epoch 87/100\n",
            "3367/3367 [==============================] - 5s 1ms/step - loss: 0.7060 - accuracy: 0.7366\n",
            "Epoch 88/100\n",
            "3367/3367 [==============================] - 5s 1ms/step - loss: 0.7114 - accuracy: 0.7330\n",
            "Epoch 89/100\n",
            "3367/3367 [==============================] - 5s 2ms/step - loss: 0.7100 - accuracy: 0.7333\n",
            "Epoch 90/100\n",
            "3367/3367 [==============================] - 5s 1ms/step - loss: 0.7040 - accuracy: 0.7376\n",
            "Epoch 91/100\n",
            "3367/3367 [==============================] - 5s 2ms/step - loss: 0.7052 - accuracy: 0.7364\n",
            "Epoch 92/100\n",
            "3367/3367 [==============================] - 5s 1ms/step - loss: 0.7037 - accuracy: 0.7372\n",
            "Epoch 93/100\n",
            "3367/3367 [==============================] - 5s 2ms/step - loss: 0.7037 - accuracy: 0.7373\n",
            "Epoch 94/100\n",
            "3367/3367 [==============================] - 5s 1ms/step - loss: 0.7017 - accuracy: 0.7362\n",
            "Epoch 95/100\n",
            "3367/3367 [==============================] - 5s 1ms/step - loss: 0.7081 - accuracy: 0.7343\n",
            "Epoch 96/100\n",
            "3367/3367 [==============================] - 5s 1ms/step - loss: 0.6985 - accuracy: 0.7380\n",
            "Epoch 97/100\n",
            "3367/3367 [==============================] - 5s 1ms/step - loss: 0.6980 - accuracy: 0.7373\n",
            "Epoch 98/100\n",
            "3367/3367 [==============================] - 5s 1ms/step - loss: 0.7057 - accuracy: 0.7356\n",
            "Epoch 99/100\n",
            "3367/3367 [==============================] - 5s 2ms/step - loss: 0.7019 - accuracy: 0.7369\n",
            "Epoch 100/100\n",
            "3367/3367 [==============================] - 5s 1ms/step - loss: 0.6954 - accuracy: 0.7373\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R8Qt9oVSuEc-",
        "outputId": "28153fc3-d63d-4d8e-ea70-46cac2b68c23"
      },
      "source": [
        "loss, accNN10 = model.evaluate(X_train, y_train, verbose=True)\n",
        "print(\"Training Accuracy: {:.4f}\".format(accNN10))\n",
        "\n",
        "#loss, accuracy = model.evaluate(y_test, X_test, verbose=True)\n",
        "#print(\"Testing Accuracy:  {:.4f}\".format(accuracy))\n"
      ],
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3367/3367 [==============================] - 4s 1ms/step - loss: 0.7015 - accuracy: 0.7318\n",
            "Training Accuracy: 0.7318\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HxJQVfxJE0eF"
      },
      "source": [
        ""
      ],
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DjkKak0CuSwM"
      },
      "source": [
        "#CNN 1D\n",
        "from __future__ import print_function\n",
        "import numpy as np\n",
        "np.random.seed(1337)  # for reproducibility\n",
        "\n",
        "from keras.preprocessing import sequence\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Lambda\n",
        "from keras.layers import Embedding\n",
        "from keras.layers import Convolution1D,MaxPooling1D, Flatten\n",
        "from keras.datasets import imdb\n",
        "from keras import backend as K\n",
        "#from sklearn.cross_validation import train_test_split\n",
        "import pandas as pd\n",
        "from keras.utils.np_utils import to_categorical\n",
        "\n",
        "from sklearn.preprocessing import Normalizer\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Convolution1D, Dense, Dropout, Flatten, MaxPooling1D\n",
        "from keras.utils import np_utils\n",
        "import numpy as np\n",
        "import h5py\n",
        "from keras import callbacks\n",
        "from keras.layers import LSTM, GRU, SimpleRNN\n",
        "from keras.callbacks import CSVLogger\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, CSVLogger"
      ],
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "THg2erH1rxH1"
      },
      "source": [
        "X = df1_xtrain\n",
        "Y = df1_ytrain\n",
        "C = df3_ytest\n",
        "T = df1_xtest\n",
        "\n"
      ],
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KylIZNhHsADu",
        "outputId": "5aefda4e-b4d9-44c9-d38e-fcdbe1617bff"
      },
      "source": [
        "scaler = Normalizer().fit(X)\n",
        "trainX = scaler.transform(X)\n",
        "\n",
        "scaler = Normalizer().fit(T)\n",
        "testT = scaler.transform(T)\n",
        "\n",
        "y_train1 = np.array(Y)\n",
        "y_test1 = np.array(C)\n",
        "\n",
        "y_train= to_categorical(y_train1)\n",
        "y_test= to_categorical(y_test1)\n",
        "\n",
        "\n",
        "# reshape input to be [samples, time steps, features]\n",
        "X_train = np.reshape(trainX, (trainX.shape[0],trainX.shape[1],1))\n",
        "X_test = np.reshape(testT, (testT.shape[0],testT.shape[1],1))\n",
        "\n",
        "\n",
        "cnn = Sequential()\n",
        "cnn.add(Convolution1D(64, 1, activation=\"relu\",input_shape=(15, 1)))\n",
        "#cnn.add(MaxPooling1D(pool_length=(2)))\n",
        "cnn.add(Flatten())\n",
        "cnn.add(Dense(128, activation=\"relu\"))\n",
        "cnn.add(Dropout(0.5))\n",
        "cnn.add(Dense(10, activation=\"softmax\"))\n",
        "\n",
        "# define optimizer and objective, compile cnn\n",
        "\n",
        "cnn.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\",metrics=['accuracy'])\n",
        "\n",
        "# train\n",
        "checkpointer = callbacks.ModelCheckpoint(filepath=\"results/checkpoint-{epoch:02d}.hdf5\", verbose=1, save_best_only=True, monitor='val_acc',mode='max')\n",
        "csv_logger = CSVLogger('results/cnn1results/cnntrainanalysis1.csv',separator=',', append=False)\n",
        "historyCNN10=cnn.fit(X_train, y_train, batch_size=40 ,epochs=100)\n",
        "#cnn.save(\"results/cnn1results/cnn_model.hdf5\")\n",
        "#,validation_data=(X_test, y_test),callbacks=[checkpointer,csv_logger]\n",
        "\n",
        "loss, accCNN10 = cnn.evaluate(X_train, y_train, verbose=True)\n",
        "print(\"Training Accuracy: {:.4f}\".format(accCNN10))\n"
      ],
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "2694/2694 [==============================] - 11s 4ms/step - loss: 1.3833 - accuracy: 0.4974\n",
            "Epoch 2/100\n",
            "2694/2694 [==============================] - 10s 4ms/step - loss: 1.1875 - accuracy: 0.5397\n",
            "Epoch 3/100\n",
            "2694/2694 [==============================] - 10s 4ms/step - loss: 1.1451 - accuracy: 0.5558\n",
            "Epoch 4/100\n",
            "2694/2694 [==============================] - 10s 4ms/step - loss: 1.1082 - accuracy: 0.5775\n",
            "Epoch 5/100\n",
            "2694/2694 [==============================] - 10s 4ms/step - loss: 1.0737 - accuracy: 0.5889\n",
            "Epoch 6/100\n",
            "2694/2694 [==============================] - 10s 4ms/step - loss: 1.0714 - accuracy: 0.5907\n",
            "Epoch 7/100\n",
            "2694/2694 [==============================] - 10s 4ms/step - loss: 1.0582 - accuracy: 0.5989\n",
            "Epoch 8/100\n",
            "2694/2694 [==============================] - 11s 4ms/step - loss: 1.0480 - accuracy: 0.6016\n",
            "Epoch 9/100\n",
            "2694/2694 [==============================] - 10s 4ms/step - loss: 1.0381 - accuracy: 0.6040\n",
            "Epoch 10/100\n",
            "2694/2694 [==============================] - 10s 4ms/step - loss: 1.0369 - accuracy: 0.6066\n",
            "Epoch 11/100\n",
            "2694/2694 [==============================] - 10s 4ms/step - loss: 1.0365 - accuracy: 0.6068\n",
            "Epoch 12/100\n",
            "2694/2694 [==============================] - 11s 4ms/step - loss: 1.0306 - accuracy: 0.6086\n",
            "Epoch 13/100\n",
            "2694/2694 [==============================] - 10s 4ms/step - loss: 1.0267 - accuracy: 0.6110\n",
            "Epoch 14/100\n",
            "2694/2694 [==============================] - 10s 4ms/step - loss: 1.0220 - accuracy: 0.6146\n",
            "Epoch 15/100\n",
            "2694/2694 [==============================] - 10s 4ms/step - loss: 1.0093 - accuracy: 0.6174\n",
            "Epoch 16/100\n",
            "2694/2694 [==============================] - 10s 4ms/step - loss: 1.0082 - accuracy: 0.6191\n",
            "Epoch 17/100\n",
            "2694/2694 [==============================] - 10s 4ms/step - loss: 1.0162 - accuracy: 0.6155\n",
            "Epoch 18/100\n",
            "2694/2694 [==============================] - 10s 4ms/step - loss: 1.0098 - accuracy: 0.6194\n",
            "Epoch 19/100\n",
            "2694/2694 [==============================] - 10s 4ms/step - loss: 1.0071 - accuracy: 0.6223\n",
            "Epoch 20/100\n",
            "2694/2694 [==============================] - 11s 4ms/step - loss: 1.0091 - accuracy: 0.6192\n",
            "Epoch 21/100\n",
            "2694/2694 [==============================] - 10s 4ms/step - loss: 0.9940 - accuracy: 0.6256\n",
            "Epoch 22/100\n",
            "2694/2694 [==============================] - 10s 4ms/step - loss: 0.9987 - accuracy: 0.6242\n",
            "Epoch 23/100\n",
            "2694/2694 [==============================] - 10s 4ms/step - loss: 1.0058 - accuracy: 0.6237\n",
            "Epoch 24/100\n",
            "2694/2694 [==============================] - 10s 4ms/step - loss: 0.9971 - accuracy: 0.6286\n",
            "Epoch 25/100\n",
            "2694/2694 [==============================] - 10s 4ms/step - loss: 0.9947 - accuracy: 0.6277\n",
            "Epoch 26/100\n",
            "2694/2694 [==============================] - 10s 4ms/step - loss: 0.9891 - accuracy: 0.6286\n",
            "Epoch 27/100\n",
            "2694/2694 [==============================] - 10s 4ms/step - loss: 0.9838 - accuracy: 0.6345\n",
            "Epoch 28/100\n",
            "2694/2694 [==============================] - 10s 4ms/step - loss: 0.9786 - accuracy: 0.6364\n",
            "Epoch 29/100\n",
            "2694/2694 [==============================] - 9s 3ms/step - loss: 0.9797 - accuracy: 0.6340\n",
            "Epoch 30/100\n",
            "2694/2694 [==============================] - 10s 4ms/step - loss: 0.9763 - accuracy: 0.6365\n",
            "Epoch 31/100\n",
            "2694/2694 [==============================] - 9s 4ms/step - loss: 0.9637 - accuracy: 0.6394\n",
            "Epoch 32/100\n",
            "2694/2694 [==============================] - 10s 4ms/step - loss: 0.9583 - accuracy: 0.6422\n",
            "Epoch 33/100\n",
            "2694/2694 [==============================] - 9s 4ms/step - loss: 0.9588 - accuracy: 0.6426\n",
            "Epoch 34/100\n",
            "2694/2694 [==============================] - 9s 4ms/step - loss: 0.9505 - accuracy: 0.6472\n",
            "Epoch 35/100\n",
            "2694/2694 [==============================] - 10s 4ms/step - loss: 0.9522 - accuracy: 0.6417\n",
            "Epoch 36/100\n",
            "2694/2694 [==============================] - 10s 4ms/step - loss: 0.9470 - accuracy: 0.6481\n",
            "Epoch 37/100\n",
            "2694/2694 [==============================] - 10s 4ms/step - loss: 0.9452 - accuracy: 0.6500\n",
            "Epoch 38/100\n",
            "2694/2694 [==============================] - 10s 4ms/step - loss: 0.9376 - accuracy: 0.6504\n",
            "Epoch 39/100\n",
            "2694/2694 [==============================] - 10s 4ms/step - loss: 0.9428 - accuracy: 0.6492\n",
            "Epoch 40/100\n",
            "2694/2694 [==============================] - 9s 4ms/step - loss: 0.9319 - accuracy: 0.6514\n",
            "Epoch 41/100\n",
            "2694/2694 [==============================] - 10s 4ms/step - loss: 0.9332 - accuracy: 0.6535\n",
            "Epoch 42/100\n",
            "2694/2694 [==============================] - 10s 4ms/step - loss: 0.9334 - accuracy: 0.6539\n",
            "Epoch 43/100\n",
            "2694/2694 [==============================] - 9s 4ms/step - loss: 0.9336 - accuracy: 0.6514\n",
            "Epoch 44/100\n",
            "2694/2694 [==============================] - 10s 4ms/step - loss: 0.9325 - accuracy: 0.6517\n",
            "Epoch 45/100\n",
            "2694/2694 [==============================] - 10s 4ms/step - loss: 0.9301 - accuracy: 0.6548\n",
            "Epoch 46/100\n",
            "2694/2694 [==============================] - 9s 4ms/step - loss: 0.9226 - accuracy: 0.6547\n",
            "Epoch 47/100\n",
            "2694/2694 [==============================] - 10s 4ms/step - loss: 0.9315 - accuracy: 0.6516\n",
            "Epoch 48/100\n",
            "2694/2694 [==============================] - 10s 4ms/step - loss: 0.9215 - accuracy: 0.6541\n",
            "Epoch 49/100\n",
            "2694/2694 [==============================] - 10s 4ms/step - loss: 0.9240 - accuracy: 0.6544\n",
            "Epoch 50/100\n",
            "2694/2694 [==============================] - 10s 4ms/step - loss: 0.9259 - accuracy: 0.6491\n",
            "Epoch 51/100\n",
            "2694/2694 [==============================] - 10s 4ms/step - loss: 0.9228 - accuracy: 0.6494\n",
            "Epoch 52/100\n",
            "2694/2694 [==============================] - 10s 4ms/step - loss: 0.9244 - accuracy: 0.6499\n",
            "Epoch 53/100\n",
            "2694/2694 [==============================] - 9s 3ms/step - loss: 0.9216 - accuracy: 0.6500\n",
            "Epoch 54/100\n",
            "2694/2694 [==============================] - 9s 3ms/step - loss: 0.9184 - accuracy: 0.6496\n",
            "Epoch 55/100\n",
            "2694/2694 [==============================] - 9s 3ms/step - loss: 0.9164 - accuracy: 0.6513\n",
            "Epoch 56/100\n",
            "2694/2694 [==============================] - 10s 4ms/step - loss: 0.9175 - accuracy: 0.6488\n",
            "Epoch 57/100\n",
            "2694/2694 [==============================] - 10s 4ms/step - loss: 0.9213 - accuracy: 0.6479\n",
            "Epoch 58/100\n",
            "2694/2694 [==============================] - 11s 4ms/step - loss: 0.9218 - accuracy: 0.6471\n",
            "Epoch 59/100\n",
            "2694/2694 [==============================] - 19s 7ms/step - loss: 0.9152 - accuracy: 0.6506\n",
            "Epoch 60/100\n",
            "2694/2694 [==============================] - 16s 6ms/step - loss: 0.9167 - accuracy: 0.6525\n",
            "Epoch 61/100\n",
            "2694/2694 [==============================] - 13s 5ms/step - loss: 0.9109 - accuracy: 0.6555\n",
            "Epoch 62/100\n",
            "2694/2694 [==============================] - 14s 5ms/step - loss: 0.9092 - accuracy: 0.6511\n",
            "Epoch 63/100\n",
            "2694/2694 [==============================] - 12s 5ms/step - loss: 0.9099 - accuracy: 0.6510\n",
            "Epoch 64/100\n",
            "2694/2694 [==============================] - 15s 5ms/step - loss: 0.9110 - accuracy: 0.6537\n",
            "Epoch 65/100\n",
            "2694/2694 [==============================] - 13s 5ms/step - loss: 0.9169 - accuracy: 0.6524\n",
            "Epoch 66/100\n",
            "2694/2694 [==============================] - 10s 4ms/step - loss: 0.9147 - accuracy: 0.6542\n",
            "Epoch 67/100\n",
            "2694/2694 [==============================] - 10s 4ms/step - loss: 0.9155 - accuracy: 0.6538\n",
            "Epoch 68/100\n",
            "2694/2694 [==============================] - 9s 4ms/step - loss: 0.9114 - accuracy: 0.6562\n",
            "Epoch 69/100\n",
            "2694/2694 [==============================] - 9s 3ms/step - loss: 0.9112 - accuracy: 0.6570\n",
            "Epoch 70/100\n",
            "2694/2694 [==============================] - 10s 4ms/step - loss: 0.9029 - accuracy: 0.6594\n",
            "Epoch 71/100\n",
            "2694/2694 [==============================] - 10s 4ms/step - loss: 0.9070 - accuracy: 0.6533\n",
            "Epoch 72/100\n",
            "2694/2694 [==============================] - 10s 4ms/step - loss: 0.9087 - accuracy: 0.6561\n",
            "Epoch 73/100\n",
            "2694/2694 [==============================] - 10s 4ms/step - loss: 0.9014 - accuracy: 0.6584\n",
            "Epoch 74/100\n",
            "2694/2694 [==============================] - 11s 4ms/step - loss: 0.9017 - accuracy: 0.6587\n",
            "Epoch 75/100\n",
            "2694/2694 [==============================] - 11s 4ms/step - loss: 0.8985 - accuracy: 0.6608\n",
            "Epoch 76/100\n",
            "2694/2694 [==============================] - 11s 4ms/step - loss: 0.9012 - accuracy: 0.6610\n",
            "Epoch 77/100\n",
            "2694/2694 [==============================] - 11s 4ms/step - loss: 0.9077 - accuracy: 0.6573\n",
            "Epoch 78/100\n",
            "2694/2694 [==============================] - 11s 4ms/step - loss: 0.8953 - accuracy: 0.6624\n",
            "Epoch 79/100\n",
            "2694/2694 [==============================] - 11s 4ms/step - loss: 0.8905 - accuracy: 0.6651\n",
            "Epoch 80/100\n",
            "2694/2694 [==============================] - 12s 4ms/step - loss: 0.9011 - accuracy: 0.6622\n",
            "Epoch 81/100\n",
            "2694/2694 [==============================] - 13s 5ms/step - loss: 0.8995 - accuracy: 0.6623\n",
            "Epoch 82/100\n",
            "2694/2694 [==============================] - 13s 5ms/step - loss: 0.8984 - accuracy: 0.6632\n",
            "Epoch 83/100\n",
            "2694/2694 [==============================] - 12s 5ms/step - loss: 0.8977 - accuracy: 0.6664\n",
            "Epoch 84/100\n",
            "2694/2694 [==============================] - 13s 5ms/step - loss: 0.9028 - accuracy: 0.6609\n",
            "Epoch 85/100\n",
            "2694/2694 [==============================] - 13s 5ms/step - loss: 0.8956 - accuracy: 0.6620\n",
            "Epoch 86/100\n",
            "2694/2694 [==============================] - 13s 5ms/step - loss: 0.9005 - accuracy: 0.6614\n",
            "Epoch 87/100\n",
            "2694/2694 [==============================] - 13s 5ms/step - loss: 0.9056 - accuracy: 0.6621\n",
            "Epoch 88/100\n",
            "2694/2694 [==============================] - 12s 5ms/step - loss: 0.8991 - accuracy: 0.6616\n",
            "Epoch 89/100\n",
            "2694/2694 [==============================] - 12s 4ms/step - loss: 0.8996 - accuracy: 0.6594\n",
            "Epoch 90/100\n",
            "2694/2694 [==============================] - 12s 4ms/step - loss: 0.9075 - accuracy: 0.6573\n",
            "Epoch 91/100\n",
            "2694/2694 [==============================] - 13s 5ms/step - loss: 0.9001 - accuracy: 0.6612\n",
            "Epoch 92/100\n",
            "2694/2694 [==============================] - 12s 4ms/step - loss: 0.8885 - accuracy: 0.6664\n",
            "Epoch 93/100\n",
            "2694/2694 [==============================] - 12s 4ms/step - loss: 0.8962 - accuracy: 0.6616\n",
            "Epoch 94/100\n",
            "2694/2694 [==============================] - 11s 4ms/step - loss: 0.8915 - accuracy: 0.6670\n",
            "Epoch 95/100\n",
            "2694/2694 [==============================] - 11s 4ms/step - loss: 0.8947 - accuracy: 0.6645\n",
            "Epoch 96/100\n",
            "2694/2694 [==============================] - 12s 4ms/step - loss: 0.8948 - accuracy: 0.6631\n",
            "Epoch 97/100\n",
            "2694/2694 [==============================] - 12s 4ms/step - loss: 0.8981 - accuracy: 0.6621\n",
            "Epoch 98/100\n",
            "2694/2694 [==============================] - 11s 4ms/step - loss: 0.8851 - accuracy: 0.6658\n",
            "Epoch 99/100\n",
            "2694/2694 [==============================] - 11s 4ms/step - loss: 0.8884 - accuracy: 0.6658\n",
            "Epoch 100/100\n",
            "2694/2694 [==============================] - 11s 4ms/step - loss: 0.8872 - accuracy: 0.6656\n",
            "3367/3367 [==============================] - 6s 2ms/step - loss: 0.7829 - accuracy: 0.7119\n",
            "Training Accuracy: 0.7119\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CS0Gt8XauZ5P"
      },
      "source": [
        "#Ada Boost with DT\n",
        "from sklearn.ensemble import AdaBoostClassifier\n"
      ],
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6tc7MPIluZ9m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "74fe14b0-3aa7-42e9-eaa1-5818a34eb984"
      },
      "source": [
        "print (\"\\t\\tAdaBoost using Decision Tree Analysis of UNSW NB15\\n\\n\\t\\tTop 10 Features \")\n",
        "\n",
        "\n",
        "\n",
        "abc10 = AdaBoostClassifier(DecisionTreeClassifier(max_depth=3), algorithm=\"SAMME\", n_estimators=500)\n",
        "abc10.fit(df1_xtrain, df1_ytrain)\n",
        "\n",
        "#Predict the response for test dataset\n",
        "y_pred_Ada10 = abc10.predict(df1_xtest)\n",
        "\n",
        "\n",
        "results_Ada10 = confusion_matrix(df1_ytest, y_pred_Ada10) \n",
        "print ('Confusion Matrix :')\n",
        "print(results_Ada10) \n",
        "\n",
        "accabc10=accuracy_score(df1_ytest, y_pred_Ada10)\n",
        "preabc10=precision_score(df1_ytest, y_pred_Ada10, average='macro')\n",
        "f1abc10=f1_score(df1_ytest, y_pred_Ada10, average='macro')\n",
        "reabc10=recall_score(df1_ytest, y_pred_Ada10, average='macro')\n",
        "\n",
        "print ('Accuracy Score :', accabc10)\n",
        "print(\"Precision Score: \",preabc10)\n",
        "print(\"F1 Score: \",f1abc10)\n",
        "print(\"Recall: \",reabc10)\n"
      ],
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\t\tAdaBoost using Decision Tree Analysis of UNSW NB15\n",
            "\n",
            "\t\tTop 10 Features \n",
            "Confusion Matrix :\n",
            "[[  281     4    60    51   206     0    62    13     0     0]\n",
            " [  179     6    61    97   214     1     8    13     4     0]\n",
            " [ 1862   134   237   854   525    69   168   200    38     2]\n",
            " [ 1854   155   390  6189   859   253   868   517    44     3]\n",
            " [  539    12   134   370  1076     2  3825    66    36     2]\n",
            " [   12     2    49   804    41 17849    89    15    10     0]\n",
            " [  440    23   170   908  3039    18 32249    20   127     6]\n",
            " [  216    28    22   196    78     7    87  2842    20     0]\n",
            " [    0     0    25    50    44     0    45    15   199     0]\n",
            " [    0     1     0    31     4     3     1     0     2     2]]\n",
            "Accuracy Score : 0.7400524704853519\n",
            "Precision Score:  0.4258598142157197\n",
            "F1 Score:  0.41227831822646416\n",
            "Recall:  0.4419058463727786\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qWHpLmjVuaML",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fdca37e7-5ccd-41dd-e2c8-74d6fd05e576"
      },
      "source": [
        "print (\"\\t\\tAdaBoost using DT Analysis of UNSW-NB15\\n\\n\\t\\tTop 20 Features \")\n",
        "\n",
        "abc20 = AdaBoostClassifier(DecisionTreeClassifier(max_depth=3), algorithm=\"SAMME\",n_estimators=500)\n",
        "abc20.fit(df2_xtrain, df2_ytrain)\n",
        "\n",
        "y_pred_Ada20 = abc20.predict(df2_xtest)\n",
        "\n",
        "\n",
        "\n",
        "results_Ada10 = confusion_matrix(df2_ytest, y_pred_Ada20) \n",
        "print ('Confusion Matrix :')\n",
        "print(results_Ada10) \n",
        "\n",
        "accabc20=accuracy_score(df2_ytest, y_pred_Ada20)\n",
        "preabc20=precision_score(df2_ytest, y_pred_Ada20, average='macro')\n",
        "f1abc20=f1_score(df2_ytest, y_pred_Ada20, average='macro')\n",
        "reabc20=recall_score(df2_ytest, y_pred_Ada20, average='macro')\n",
        "\n",
        "print ('Accuracy Score :', accabc20)\n",
        "print(\"Precision Score: \",preabc20)\n",
        "print(\"F1 Score: \",f1abc20)\n",
        "print(\"Recall: \",reabc20)\n"
      ],
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\t\tAdaBoost using DT Analysis of UNSW-NB15\n",
            "\n",
            "\t\tTop 20 Features \n",
            "Confusion Matrix :\n",
            "[[  424    57     3    18    44     0    55    76     0     0]\n",
            " [  359    45    15    24    51    11     4    71     3     0]\n",
            " [ 1378   689   331   926   328    32   108   252    39     6]\n",
            " [ 1640   687  1031  6096   478   219   363   553    40    25]\n",
            " [  826   133    82   151  1658    11  2933   194    53    21]\n",
            " [   13     6   260   370    56 18059    87     7    12     1]\n",
            " [  658     6   307   638  5201    27 30030    14   101    18]\n",
            " [  133   110    59   241    86     7    34  2820     5     1]\n",
            " [    0     2    36    54    45     0    36    12   193     0]\n",
            " [    0     0     5    31     2     2     2     0     0     2]]\n",
            "Accuracy Score : 0.7246028275761551\n",
            "Precision Score:  0.42216095049288327\n",
            "F1 Score:  0.42151037141227066\n",
            "Recall:  0.4736811250635452\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0EdgdNfGuaUk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b4877197-87d9-4fcd-89c2-89ba04b5d6a6"
      },
      "source": [
        "print (\"\\t\\tAdaBoost using DT Analysis of UNSW-NB15\\n\\n\\t\\tAll Features \")\n",
        "\n",
        "abcall = AdaBoostClassifier(DecisionTreeClassifier(max_depth=3),\n",
        "                         algorithm=\"SAMME\",\n",
        "                         n_estimators=500)\n",
        "\n",
        "abcall.fit(df3_xtrain,df3_ytrain)\n",
        "\n",
        "y_pred_Adaall = abcall.predict(df3_xtest)\n",
        "\n",
        "results_Adaall = confusion_matrix(df3_ytest, y_pred_Adaall) \n",
        "print ('Confusion Matrix :')\n",
        "print(results_Adaall)\n",
        "\n",
        "accabcall=accuracy_score(df3_ytest, y_pred_Adaall)\n",
        "preabcall=precision_score(df3_ytest, y_pred_Adaall, average='macro')\n",
        "f1abcall=f1_score(df3_ytest, y_pred_Adaall, average='macro')\n",
        "reabcall=recall_score(df3_ytest, y_pred_Adaall, average='macro')\n",
        "\n",
        "print ('Accuracy Score :', accabcall)\n",
        "print(\"Precision Score: \",preabcall)\n",
        "print(\"F1 Score: \",f1abcall)\n",
        "print(\"Recall: \",reabcall)"
      ],
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\t\tAdaBoost using DT Analysis of UNSW-NB15\n",
            "\n",
            "\t\tAll Features \n",
            "Confusion Matrix :\n",
            "[[  249    47   164    14    21    34    26   122     0     0]\n",
            " [  187    89   159    23    26    10     0    89     0     0]\n",
            " [  977   503   493   591   129   142   139  1115     0     0]\n",
            " [ 1516   832   956  3556   150   892  1299  1930     0     1]\n",
            " [  441   648   724  1154  1237   999   233   626     0     0]\n",
            " [   17    42    75   356     6 14065    41  4269     0     0]\n",
            " [ 2178  1236  1812  4189  5753  1274 15575  4983     0     0]\n",
            " [   85   129    52    69    20    14     2  3125     0     0]\n",
            " [    0    67    72   168     6     0     0    65     0     0]\n",
            " [    0     0     5    11     0     1     0    27     0     0]]\n",
            "Accuracy Score : 0.4662707088373901\n",
            "Precision Score:  0.2594977036850702\n",
            "F1 Score:  0.24182434495918598\n",
            "Recall:  0.32246708489366177\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning:\n",
            "\n",
            "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fbwdx6KnI4wX"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i_Sou9aPI9np",
        "outputId": "115254d9-84ce-49de-c020-a8877541fe5d"
      },
      "source": [
        "!pip install vecstack\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from vecstack import stacking"
      ],
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting vecstack\n",
            "  Downloading https://files.pythonhosted.org/packages/d0/a1/b9a1e9e9e5a12078da1ab9788c7885e4c745358f7e57d5f94d9db6a4e898/vecstack-0.4.0.tar.gz\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from vecstack) (1.19.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from vecstack) (1.4.1)\n",
            "Requirement already satisfied: scikit-learn>=0.18 in /usr/local/lib/python3.7/dist-packages (from vecstack) (0.22.2.post1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.18->vecstack) (1.0.1)\n",
            "Building wheels for collected packages: vecstack\n",
            "  Building wheel for vecstack (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for vecstack: filename=vecstack-0.4.0-cp37-none-any.whl size=19877 sha256=0a50b6bd99fce7e7649241f7e3c71a8b09b3bbfc22252bc3d7bbf2b44a445065\n",
            "  Stored in directory: /root/.cache/pip/wheels/5f/bb/4e/f6488433d53bc0684673d6845e5bf11a25240577c8151c140e\n",
            "Successfully built vecstack\n",
            "Installing collected packages: vecstack\n",
            "Successfully installed vecstack-0.4.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fqd-w6geI40E"
      },
      "source": [
        "models = [\n",
        "    KNeighborsClassifier(),\n",
        "        \n",
        "    RandomForestClassifier(n_estimators=500, max_depth=3),\n",
        "        \n",
        "    XGBClassifier(random_state=0, n_jobs=-1, learning_rate=0.1, \n",
        "                  n_estimators=100, max_depth=3)\n",
        "]"
      ],
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yjUmiwr-I43Z",
        "outputId": "f703b3b1-6eb8-4389-a459-88583a71cdeb"
      },
      "source": [
        "S_train, S_test = stacking(models, df1_xtrain, df1_ytrain, df1_xtest, regression=False, mode='oof_pred_bag', needs_proba=False, save_dir=None,  metric=accuracy_score, \n",
        "                               n_folds=5, stratified=True, shuffle=True,  random_state=0, verbose=2)"
      ],
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "task:         [classification]\n",
            "n_classes:    [10]\n",
            "metric:       [accuracy_score]\n",
            "mode:         [oof_pred_bag]\n",
            "n_models:     [3]\n",
            "\n",
            "model  0:     [KNeighborsClassifier]\n",
            "    fold  0:  [0.73357156]\n",
            "    fold  1:  [0.74108966]\n",
            "    fold  2:  [0.73417487]\n",
            "    fold  3:  [0.73937256]\n",
            "    fold  4:  [0.74043995]\n",
            "    ----\n",
            "    MEAN:     [0.73772972] + [0.00320190]\n",
            "    FULL:     [0.73772972]\n",
            "\n",
            "model  1:     [RandomForestClassifier]\n",
            "    fold  0:  [0.72558938]\n",
            "    fold  1:  [0.73208650]\n",
            "    fold  2:  [0.72647113]\n",
            "    fold  3:  [0.73454613]\n",
            "    fold  4:  [0.72985892]\n",
            "    ----\n",
            "    MEAN:     [0.72971041] + [0.00336238]\n",
            "    FULL:     [0.72971041]\n",
            "\n",
            "model  2:     [XGBClassifier]\n",
            "    fold  0:  [0.78893633]\n",
            "    fold  1:  [0.79547986]\n",
            "    fold  2:  [0.79650084]\n",
            "    fold  3:  [0.79961017]\n",
            "    fold  4:  [0.79520141]\n",
            "    ----\n",
            "    MEAN:     [0.79514572] + [0.00347675]\n",
            "    FULL:     [0.79514572]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NQFZA7MAI473",
        "outputId": "71e5a8b4-08ef-402e-b684-cb6fa09d2583"
      },
      "source": [
        "XGB10 = XGBClassifier(random_state=1, n_jobs=-1, learning_rate=0.1, \n",
        "                      n_estimators=300, max_depth=3)\n",
        "    \n",
        "XGB10 = XGB10.fit(S_train, df1_ytrain)\n",
        "\n",
        "y_pred_XGB1 = XGB10.predict(S_test)\n",
        "\n",
        "print('Final prediction score: [%.5f]' % accuracy_score(df1_ytest, y_pred_XGB1))\n",
        "\n",
        "results_XGB1 = confusion_matrix(df1_ytest, y_pred_XGB1) \n",
        "print ('Confusion Matrix :')\n",
        "print(results_XGB1) \n",
        "\n",
        "accXGB10=accuracy_score(df1_ytest, y_pred_XGB1)\n",
        "preXGB10=precision_score(df1_ytest, y_pred_XGB1, average='macro')\n",
        "f1XGB10=f1_score(df1_ytest, y_pred_XGB1, average='macro')\n",
        "reXGB10=recall_score(df1_ytest, y_pred_XGB1, average='macro')\n",
        "\n",
        "print ('Accuracy Score :', accXGB10)\n",
        "print(\"Precision Score: \",preXGB10)\n",
        "print(\"F1 Score: \",f1XGB10)\n",
        "print(\"Recall: \",reXGB10)"
      ],
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Final prediction score: [0.73414]\n",
            "Confusion Matrix :\n",
            "[[    1     0     0     8   613     0    52     3     0     0]\n",
            " [    1    21     1    32   513     0     7     4     4     0]\n",
            " [    8    46    70  1026  2786     2    44    45    62     0]\n",
            " [    7    29    32  7274  3233     0   307   182    66     2]\n",
            " [    1     7     1   138  4825     0   941    54    95     0]\n",
            " [    0     4    13   495   163 18159    18     8    10     1]\n",
            " [    1     0    17  1076  8764     0 27035    33    73     1]\n",
            " [    2     6     2   291   348     0     6  2828    13     0]\n",
            " [    0     1     2    55    65     0    10    30   215     0]\n",
            " [    0     0     1    22     5     0     1     0     0    15]]\n",
            "Accuracy Score : 0.7341373949375698\n",
            "Precision Score:  0.5687654692981967\n",
            "F1 Score:  0.47229960499373336\n",
            "Recall:  0.49155527405923394\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8i1KC2CdTWm8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab8b6d76-e09a-471a-fb56-824643110180"
      },
      "source": [
        "S_train2, S_test2 = stacking(models, df2_xtrain, df2_ytrain, df2_xtest, regression=False, mode='oof_pred_bag', needs_proba=False, save_dir=None,  metric=accuracy_score, \n",
        "                               n_folds=5, stratified=True, shuffle=True,  random_state=0, verbose=2)\n",
        "\n",
        "XGB20 = XGBClassifier(random_state=0, n_jobs=-1, learning_rate=0.1, n_estimators=300, max_depth=3)\n",
        "    \n",
        "XGB20 = XGB20.fit(S_train2, df2_ytrain)\n",
        "\n",
        "y_pred_XGB2 = XGB20.predict(S_test2)\n",
        "\n",
        "print('Final prediction score: [%.5f]' % accuracy_score(df2_ytest, y_pred_XGB2))\n",
        "\n",
        "\n",
        "results_XGB2 = confusion_matrix(df2_ytest, y_pred_XGB2) \n",
        "print ('Confusion Matrix :')\n",
        "print(results_XGB2) \n",
        "\n",
        "accXGB20=accuracy_score(df2_ytest, y_pred_XGB2)\n",
        "preXGB20=precision_score(df2_ytest, y_pred_XGB2, average='macro')\n",
        "f1XGB20=f1_score(df2_ytest, y_pred_XGB2, average='macro')\n",
        "reXGB20=recall_score(df2_ytest, y_pred_XGB2, average='macro')\n",
        "\n",
        "print ('Accuracy Score :',accXGB20 )\n",
        "print(\"Precision Score: \",preXGB20)\n",
        "print(\"F1 Score: \",f1XGB20)\n",
        "print(\"Recall: \",reXGB20)\n"
      ],
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "task:         [classification]\n",
            "n_classes:    [10]\n",
            "metric:       [accuracy_score]\n",
            "mode:         [oof_pred_bag]\n",
            "n_models:     [3]\n",
            "\n",
            "model  0:     [KNeighborsClassifier]\n",
            "    fold  0:  [0.56775571]\n",
            "    fold  1:  [0.56798775]\n",
            "    fold  2:  [0.56993689]\n",
            "    fold  3:  [0.56432151]\n",
            "    fold  4:  [0.57156117]\n",
            "    ----\n",
            "    MEAN:     [0.56831260] + [0.00243047]\n",
            "    FULL:     [0.56831260]\n",
            "\n",
            "model  1:     [RandomForestClassifier]\n",
            "    fold  0:  [0.69932244]\n",
            "    fold  1:  [0.70642287]\n",
            "    fold  2:  [0.71111008]\n",
            "    fold  3:  [0.71802487]\n",
            "    fold  4:  [0.73087990]\n",
            "    ----\n",
            "    MEAN:     [0.71315203] + [0.01075854]\n",
            "    FULL:     [0.71315203]\n",
            "\n",
            "model  2:     [XGBClassifier]\n",
            "    fold  0:  [0.79394839]\n",
            "    fold  1:  [0.80165213]\n",
            "    fold  2:  [0.79974940]\n",
            "    fold  3:  [0.80466865]\n",
            "    fold  4:  [0.80230184]\n",
            "    ----\n",
            "    MEAN:     [0.80046408] + [0.00361752]\n",
            "    FULL:     [0.80046408]\n",
            "\n",
            "Final prediction score: [0.73310]\n",
            "Confusion Matrix :\n",
            "[[   77   215     0     1   322     0    57     2     3     0]\n",
            " [   25   229     1    23   284     6     5     3     7     0]\n",
            " [  874   675    79  1012  1229    23    47    60    90     0]\n",
            " [  798   801    50  7380  1597    12   201   196    95     2]\n",
            " [  160   457     2   119  4116     0  1047    58   103     0]\n",
            " [    5     4     6   506   126 18173    22    14    14     1]\n",
            " [  412     0    15   950  8254     0 27221    30   117     1]\n",
            " [  112    62     7   298   159     0    10  2829    19     0]\n",
            " [    4     1     0    45    41     0    17    36   234     0]\n",
            " [    0     0     0    19     4     0     1     0     0    20]]\n",
            "Accuracy Score : 0.7331049895544867\n",
            "Precision Score:  0.5588079951403392\n",
            "F1 Score:  0.4976209718548666\n",
            "Recall:  0.5449308898377174\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dSyC9ob1TWqP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e5ca0e11-5343-4090-e662-412a03c143d5"
      },
      "source": [
        "\n",
        "S_train3, S_test3 = stacking(models, df3_xtrain, df3_ytrain, df3_xtest, regression=False, mode='oof_pred_bag', needs_proba=False, save_dir=None,  metric=accuracy_score, \n",
        "                               n_folds=5, stratified=True, shuffle=True,  random_state=0, verbose=2)\n",
        "\n",
        "\n",
        "XGBall = XGBClassifier(random_state=0, n_jobs=-1, learning_rate=0.1, n_estimators=300, max_depth=3)\n",
        "    \n",
        "XGBall = XGBall.fit(S_train3, df3_ytrain)\n",
        "\n",
        "y_pred_XGB3 = XGBall.predict(S_test)\n",
        "\n",
        "print('Final prediction score: [%.5f]' % accuracy_score(df3_ytest, y_pred_XGB3))\n",
        "\n",
        "results_XGB3 = confusion_matrix(df3_ytest, y_pred_XGB3) \n",
        "print ('Confusion Matrix :')\n",
        "print(results_XGB3) \n",
        "\n",
        "accXGBall=accuracy_score(df3_ytest, y_pred_XGB3)\n",
        "preXGBall=precision_score(df3_ytest, y_pred_XGB3, average='macro')\n",
        "f1XGBall=f1_score(df3_ytest, y_pred_XGB3, average='macro')\n",
        "reXGBall=recall_score(df3_ytest, y_pred_XGB3, average='macro')\n",
        "\n",
        "print ('Accuracy Score :', accXGBall)\n",
        "print(\"Precision Score: \",preXGBall)\n",
        "print(\"F1 Score: \",f1XGBall)\n",
        "print(\"Recall: \",reXGBall)\n"
      ],
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "task:         [classification]\n",
            "n_classes:    [10]\n",
            "metric:       [accuracy_score]\n",
            "mode:         [oof_pred_bag]\n",
            "n_models:     [3]\n",
            "\n",
            "model  0:     [KNeighborsClassifier]\n",
            "    fold  0:  [0.56682755]\n",
            "    fold  1:  [0.56585298]\n",
            "    fold  2:  [0.56835901]\n",
            "    fold  3:  [0.56283646]\n",
            "    fold  4:  [0.57040097]\n",
            "    ----\n",
            "    MEAN:     [0.56685539] + [0.00252940]\n",
            "    FULL:     [0.56685539]\n",
            "\n",
            "model  1:     [RandomForestClassifier]\n",
            "    fold  0:  [0.69811583]\n",
            "    fold  1:  [0.70405606]\n",
            "    fold  2:  [0.70470577]\n",
            "    fold  3:  [0.70591238]\n",
            "    fold  4:  [0.70572675]\n",
            "    ----\n",
            "    MEAN:     [0.70370336] + [0.00287484]\n",
            "    FULL:     [0.70370336]\n",
            "\n",
            "model  2:     [XGBClassifier]\n",
            "    fold  0:  [0.79227771]\n",
            "    fold  1:  [0.79956376]\n",
            "    fold  2:  [0.79942454]\n",
            "    fold  3:  [0.80517913]\n",
            "    fold  4:  [0.79933172]\n",
            "    ----\n",
            "    MEAN:     [0.79915537] + [0.00409532]\n",
            "    FULL:     [0.79915537]\n",
            "\n",
            "Final prediction score: [0.71095]\n",
            "Confusion Matrix :\n",
            "[[  138     0     0     8   479     0    49     3     0     0]\n",
            " [   91    20     1    31   424     0     8     4     4     0]\n",
            " [  701    67    72  1016  2058     2    78    33    62     0]\n",
            " [  711    39    60  7252  2484     0   336   181    67     2]\n",
            " [  267     8     4   138  4519     0   981    51    94     0]\n",
            " [    9     5     8   496   150 18159    25     8    10     1]\n",
            " [  412    10    33  1057  8596     0 26808    28    55     1]\n",
            " [   83    10     5   288   255     0  1456  1384    15     0]\n",
            " [    2     3    43    40    56     0    43    24   167     0]\n",
            " [    0     1     0    22     5     0     1     0     0    15]]\n",
            "Accuracy Score : 0.7109507846280911\n",
            "Precision Score:  0.5285040219502108\n",
            "F1 Score:  0.4394593195526658\n",
            "Recall:  0.45180725447333814\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hwgf1CnikmZa"
      },
      "source": [
        "from sklearn.datasets import make_classification\n",
        "from sklearn.ensemble import StackingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier,AdaBoostClassifier,GradientBoostingClassifier"
      ],
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vPtKiX1VTWtA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5dcda99b-82a2-4c5c-9089-cdc8179ae295"
      },
      "source": [
        "level0 = list()\n",
        "level0.append(('rf', RandomForestClassifier()))\n",
        "#level0.append(('knn', KNeighborsClassifier()))\n",
        "level0.append(('cart', DecisionTreeClassifier()))\n",
        "# define meta learner model\n",
        "print(\"Proceeding with: \",level0)\n",
        "level1 = GradientBoostingClassifier(n_estimators=200)\n",
        "# define the stacking ensemble\n",
        "model = StackingClassifier(estimators=level0, final_estimator=level1, cv=2)\n",
        "# fit the model on all available data\n",
        "model.fit(df1_xtrain, df1_ytrain)\n",
        "# make a prediction for one example\n",
        "\n",
        "yhat = model.predict(df1_xtest)\n",
        "#print('Predicted Class: %d' % (yhat))\n",
        "\n",
        "print('Final prediction score: [%.5f]' % accuracy_score(df1_ytest, yhat))\n",
        "\n",
        "results_sc1 = confusion_matrix(df1_ytest, yhat) \n",
        "print ('Confusion Matrix :')\n",
        "print(results_sc1) \n",
        "\n",
        "accensemble10=accuracy_score(df1_ytest, yhat)\n",
        "preensemble10=precision_score(df1_ytest, yhat, average='macro')\n",
        "f1ensemble10=f1_score(df1_ytest, yhat, average='macro')\n",
        "reensemble10=recall_score(df1_ytest, yhat, average='macro')\n",
        "\n",
        "print ('Accuracy Score :',accensemble10 )\n",
        "print(\"Precision Score: \",preensemble10)\n",
        "print(\"F1 Score: \",f1ensemble10)\n",
        "print(\"Recall: \",reensemble10)\n"
      ],
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Proceeding with:  [('rf', RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
            "                       n_jobs=None, oob_score=False, random_state=None,\n",
            "                       verbose=0, warm_start=False)), ('cart', DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
            "                       max_depth=None, max_features=None, max_leaf_nodes=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
            "                       random_state=None, splitter='best'))]\n",
            "Final prediction score: [0.67485]\n",
            "Confusion Matrix :\n",
            "[[  137    41    32   251   172    28     2    12     2     0]\n",
            " [   64    78    40   200   151    29     2    11     8     0]\n",
            " [  895   147   569  1316   786    40    31   241    63     1]\n",
            " [  888   158   320  8123   955    82    45   418   120    23]\n",
            " [  199    89   106   854  3989    62   383    46   329     5]\n",
            " [    8    19    52   345    69 18309    24     3    38     4]\n",
            " [ 1552     3    69   911 12138     8 21237     5  1074     3]\n",
            " [  109    16    34   367   103     0    10  2811    44     2]\n",
            " [    1     3    10    40    37     0     3     1   282     1]\n",
            " [    0     0     0    14     2     1     0     0     0    27]]\n",
            "Accuracy Score : 0.6748530340572317\n",
            "Precision Score:  0.48177176004704175\n",
            "F1 Score:  0.46591286019848893\n",
            "Recall:  0.557096147427512\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        },
        "id": "qQULcI5MJs8o",
        "outputId": "3c4be2bd-c295-4c39-90b6-1d852a0d246f"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "fig = plt.figure()\n",
        "ax = fig.add_axes([0,0,1,1])\n",
        "algo = ['accKNN10', 'accDT10', 'accbayes_10', 'accclfRF_10',\"accabc10\",\"accXGB10\",\"accensemble10\",\"accNN10\",\"accCNN10\"]\n",
        "acc = [accKNN10,accDT10,accbayes_10,accclfRF_10,accabc10,accXGB10,accensemble10,accNN10,accCNN10]\n",
        "ax.bar(algo,acc)\n",
        "plt.show()"
      ],
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "joLjhR5TJtJ_"
      },
      "source": [
        "[accKNN10,preKNN10,f1KNN10,reKNN10][accDT10,preDT10,f1DT10,reDT10]\n",
        "[accbayes_10,prebayes_10,f1bayes_10,rebayes_10][accclfRF_10,preclfRF_10,f1clfRF_10,reclfRF_10]\n",
        "[acclogisticRegr_10,prelogisticRegr_10,f1logisticRegr_10,relogisticRegr_10]\n",
        "[accabc10,preabc10,f1abc10,reabc10][accXGB10,preXGB10,f1XGB10,reXGB10]\n",
        "[accensemble10,preensemble10,f1ensemble10,reensemble10]\n",
        "\n",
        "[accNN10,historyNN10][accCNN10,historyCNN10]\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}